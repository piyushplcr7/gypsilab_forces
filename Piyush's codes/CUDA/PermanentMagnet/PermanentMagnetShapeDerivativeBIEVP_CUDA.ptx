//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31057947
// Cuda compilation tools, release 11.6, V11.6.124
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .func  (.param .b64 func_retval0) malloc
(
	.param .b64 malloc_param_0
)
;
.extern .func free
(
	.param .b64 free_param_0
)
;
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.global .align 1 .b8 $str[24] = {78, 117, 109, 98, 101, 114, 32, 111, 102, 32, 98, 108, 111, 99, 107, 115, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$1[25] = {84, 104, 114, 101, 97, 100, 115, 32, 112, 101, 114, 32, 98, 108, 111, 99, 107, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$2[56] = {84, 111, 116, 97, 108, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 58, 32, 37, 100, 32, 44, 32, 73, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 32, 112, 101, 114, 32, 116, 104, 114, 101, 97, 100, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$3[54] = {73, 110, 32, 98, 108, 111, 99, 107, 32, 48, 32, 116, 104, 114, 101, 97, 100, 32, 48, 32, 99, 111, 109, 112, 117, 116, 105, 110, 103, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 32, 110, 111, 46, 32, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii(
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_0,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_1,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_2,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_3,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_4,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_5,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_6,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_7,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_8,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_9,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_10,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_11,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_12,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_13,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_14,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_15,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_16,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_17,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_18,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_19,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_20,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_21,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_22,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_23,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_24,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_25,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_26,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_27,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_28,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_29,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_30,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_31,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_32,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_33,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_34,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_35,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_36,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_37,
	.param .f64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_38,
	.param .f64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_39,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_40,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_41,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_42,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_43,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_44,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_45,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_46,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_47,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_48,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_49,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_50,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_51
)
{
	.local .align 8 .b8 	__local_depot0[488];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<142>;
	.reg .b32 	%r<447>;
	.reg .f64 	%fd<720>;
	.reg .b64 	%rd<266>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r167, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_4];
	ld.param.u32 	%r172, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_5];
	ld.param.u64 	%rd62, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_6];
	ld.param.u64 	%rd63, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_7];
	ld.param.u64 	%rd64, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_8];
	ld.param.u64 	%rd80, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_34];
	ld.param.u64 	%rd73, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_35];
	ld.param.u64 	%rd74, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_36];
	ld.param.u64 	%rd75, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_37];
	ld.param.f64 	%fd177, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_38];
	ld.param.f64 	%fd178, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_39];
	ld.param.u64 	%rd76, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_40];
	ld.param.u64 	%rd77, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_41];
	ld.param.u64 	%rd78, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_44];
	ld.param.u64 	%rd79, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_45];
	cvta.to.global.u64 	%rd1, %rd80;
	add.u64 	%rd81, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	add.u64 	%rd91, %SP, 8;
	add.u64 	%rd26, %SPL, 8;
	add.u64 	%rd12, %SPL, 16;
	add.u64 	%rd13, %SPL, 28;
	add.u64 	%rd14, %SPL, 40;
	add.u64 	%rd15, %SPL, 52;
	add.u64 	%rd16, %SPL, 64;
	add.u64 	%rd17, %SPL, 76;
	add.u64 	%rd18, %SPL, 88;
	add.u64 	%rd19, %SPL, 100;
	add.u64 	%rd20, %SPL, 112;
	add.u64 	%rd21, %SPL, 128;
	add.u64 	%rd22, %SPL, 200;
	add.u64 	%rd23, %SPL, 272;
	add.u64 	%rd24, %SPL, 344;
	add.u64 	%rd25, %SPL, 416;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	cvt.rn.f64.s32 	%fd179, %r172;
	cvt.rn.f64.s32 	%fd180, %r167;
	div.rn.f64 	%fd181, %fd180, %fd179;
	cvt.rpi.f64.f64 	%fd182, %fd181;
	cvt.rzi.s32.f64 	%r4, %fd182;
	or.b32  	%r5, %r2, %r3;
	setp.ne.s32 	%p19, %r5, 0;
	@%p19 bra 	$L__BB0_2;

	mov.u32 	%r173, %nctaid.x;
	st.local.u32 	[%rd26], %r173;
	mov.u64 	%rd106, $str;
	cvta.global.u64 	%rd107, %rd106;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd107;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd91;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r174, [retval0+0];
	} // callseq 0
	st.local.u32 	[%rd26], %r1;
	mov.u64 	%rd109, $str$1;
	cvta.global.u64 	%rd110, %rd109;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd110;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd91;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r175, [retval0+0];
	} // callseq 1
	st.local.u32 	[%rd26], %r167;
	st.local.u32 	[%rd26+4], %r4;
	mov.u64 	%rd111, $str$2;
	cvta.global.u64 	%rd112, %rd111;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd112;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd91;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r176, [retval0+0];
	} // callseq 2

$L__BB0_2:
	setp.lt.s32 	%p20, %r4, 1;
	mad.lo.s32 	%r6, %r2, %r1, %r3;
	@%p20 bra 	$L__BB0_175;

	cvta.to.global.u64 	%rd27, %rd75;
	cvta.to.global.u64 	%rd28, %rd73;
	cvta.to.global.u64 	%rd29, %rd74;
	cvta.to.global.u64 	%rd30, %rd77;
	cvta.to.global.u64 	%rd31, %rd64;
	cvta.to.global.u64 	%rd32, %rd79;
	cvta.to.global.u64 	%rd33, %rd78;
	cvta.to.global.u64 	%rd34, %rd76;
	cvta.to.global.u64 	%rd35, %rd63;
	cvta.to.global.u64 	%rd36, %rd62;
	mul.lo.s32 	%r7, %r4, %r6;
	add.f64 	%fd183, %fd178, %fd178;
	rcp.rn.f64 	%fd1, %fd183;
	div.rn.f64 	%fd184, %fd177, %fd178;
	add.f64 	%fd2, %fd184, 0d3FF0000000000000;
	div.rn.f64 	%fd185, %fd178, %fd177;
	add.f64 	%fd3, %fd185, 0d3FF0000000000000;
	mul.f64 	%fd4, %fd177, 0d3FE0000000000000;
	mov.u32 	%r9, 0;

$L__BB0_4:
	@%p19 bra 	$L__BB0_6;

	add.u64 	%rd257, %SP, 8;
	add.u64 	%rd256, %SP, 8;
	add.u64 	%rd255, %SPL, 8;
	st.local.u32 	[%rd255], %r9;
	mov.u64 	%rd113, $str$3;
	cvta.global.u64 	%rd114, %rd113;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd114;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd256;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r179, [retval0+0];
	} // callseq 3

$L__BB0_6:
	add.s32 	%r10, %r9, %r7;
	mov.u64 	%rd116, 0;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd116;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 4
	mov.u64 	%rd117, 48;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd38, [retval0+0];
	} // callseq 5
	setp.ne.s64 	%p22, %rd38, 0;
	@%p22 bra 	$L__BB0_8;

	mov.u64 	%rd118, -1;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd118;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd119, [retval0+0];
	} // callseq 6

$L__BB0_8:
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd116;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd39, [retval0+0];
	} // callseq 8
	setp.ne.s64 	%p23, %rd39, 0;
	@%p23 bra 	$L__BB0_10;

	mov.u64 	%rd122, -1;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd122;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd123, [retval0+0];
	} // callseq 9

$L__BB0_10:
	ld.param.u32 	%r355, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_4];
	setp.lt.s32 	%p24, %r10, %r355;
	@%p24 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	ld.param.u32 	%r422, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_11];
	ld.param.u64 	%rd264, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_10];
	ld.param.u64 	%rd263, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_9];
	mul.wide.s32 	%rd124, %r10, 4;
	add.s64 	%rd125, %rd36, %rd124;
	add.s64 	%rd126, %rd35, %rd124;
	ld.global.u32 	%r181, [%rd125];
	mul.lo.s32 	%r182, %r181, 3;
	mul.wide.s32 	%rd127, %r182, 4;
	add.s64 	%rd128, %rd34, %rd127;
	ld.global.u32 	%r11, [%rd128];
	ld.global.u32 	%r12, [%rd128+4];
	ld.global.u32 	%r13, [%rd128+8];
	ld.global.u32 	%r183, [%rd126];
	mul.lo.s32 	%r184, %r183, 3;
	mul.wide.s32 	%rd129, %r184, 4;
	add.s64 	%rd130, %rd34, %rd129;
	ld.global.u32 	%r421, [%rd130];
	ld.global.u32 	%r15, [%rd130+4];
	ld.global.u32 	%r16, [%rd130+8];
	st.local.u32 	[%rd15], %r11;
	st.local.u32 	[%rd15+4], %r12;
	st.local.u32 	[%rd15+8], %r13;
	st.local.u32 	[%rd16], %r421;
	st.local.u32 	[%rd16+4], %r15;
	st.local.u32 	[%rd16+8], %r16;
	add.s64 	%rd131, %rd33, %rd127;
	ld.global.u32 	%r185, [%rd131];
	st.local.u32 	[%rd17], %r185;
	ld.global.u32 	%r186, [%rd131+4];
	st.local.u32 	[%rd17+4], %r186;
	ld.global.u32 	%r187, [%rd131+8];
	st.local.u32 	[%rd17+8], %r187;
	add.s64 	%rd132, %rd32, %rd129;
	ld.global.u32 	%r188, [%rd132];
	st.local.u32 	[%rd18], %r188;
	ld.global.u32 	%r189, [%rd132+4];
	st.local.u32 	[%rd18+4], %r189;
	ld.global.u32 	%r190, [%rd132+8];
	st.local.u32 	[%rd18+8], %r190;
	mov.u32 	%r372, 1;
	st.local.u32 	[%rd19+4], %r372;
	mov.u32 	%r386, 2;
	st.local.u32 	[%rd19+8], %r386;
	mov.u32 	%r415, 0;
	st.local.u32 	[%rd20], %r415;
	st.local.u32 	[%rd20+4], %r372;
	st.local.u32 	[%rd20+8], %r386;
	add.s64 	%rd133, %rd31, %rd124;
	ld.global.u32 	%r17, [%rd133];
	setp.eq.s32 	%p25, %r17, 0;
	mov.u32 	%r416, %r13;
	mov.u32 	%r417, %r12;
	mov.u32 	%r418, %r11;
	mov.u32 	%r419, %r16;
	mov.u32 	%r420, %r15;
	@%p25 bra 	$L__BB0_83;

	setp.eq.s32 	%p26, %r17, 1;
	@%p26 bra 	$L__BB0_49;
	bra.uni 	$L__BB0_14;

$L__BB0_49:
	setp.eq.s32 	%p9, %r11, %r421;
	setp.eq.s32 	%p10, %r11, %r15;
	or.pred  	%p59, %p10, %p9;
	setp.eq.s32 	%p11, %r11, %r16;
	or.pred  	%p60, %p11, %p59;
	@%p60 bra 	$L__BB0_51;
	bra.uni 	$L__BB0_50;

$L__BB0_51:
	st.local.u32 	[%rd12], %r11;
	mov.u32 	%r394, 0;
	mov.u32 	%r396, 1;
	bra.uni 	$L__BB0_52;

$L__BB0_14:
	ld.param.u32 	%r422, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_20];
	ld.param.u64 	%rd264, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_19];
	ld.param.u64 	%rd263, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_18];
	mov.u32 	%r415, 0;
	setp.ne.s32 	%p27, %r17, 2;
	mov.u32 	%r416, %r13;
	mov.u32 	%r417, %r12;
	mov.u32 	%r418, %r11;
	mov.u32 	%r419, %r16;
	mov.u32 	%r420, %r15;
	@%p27 bra 	$L__BB0_83;

	setp.eq.s32 	%p1, %r11, %r421;
	setp.eq.s32 	%p2, %r11, %r15;
	or.pred  	%p28, %p2, %p1;
	setp.eq.s32 	%p3, %r11, %r16;
	or.pred  	%p29, %p3, %p28;
	@%p29 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_16;

$L__BB0_17:
	st.local.u32 	[%rd12], %r11;
	mov.u32 	%r372, 0;
	mov.u32 	%r374, 1;
	bra.uni 	$L__BB0_18;

$L__BB0_50:
	st.local.u32 	[%rd13], %r11;
	mov.u32 	%r394, 1;
	mov.u32 	%r396, 0;

$L__BB0_52:
	setp.eq.s32 	%p12, %r12, %r421;
	setp.eq.s32 	%p13, %r13, %r421;
	or.pred  	%p61, %p12, %p9;
	or.pred  	%p62, %p13, %p61;
	mov.u32 	%r398, 0;
	@%p62 bra 	$L__BB0_54;

	st.local.u32 	[%rd14], %r421;
	mov.u32 	%r398, 1;

$L__BB0_54:
	setp.eq.s32 	%p63, %r12, %r15;
	setp.eq.s32 	%p64, %r12, %r16;
	setp.eq.s32 	%p65, %r13, %r15;
	setp.eq.s32 	%p66, %r13, %r16;
	or.pred  	%p67, %p63, %p12;
	or.pred  	%p68, %p64, %p67;
	or.pred  	%p69, %p63, %p10;
	or.pred  	%p14, %p65, %p69;
	or.pred  	%p70, %p65, %p13;
	or.pred  	%p15, %p66, %p70;
	or.pred  	%p71, %p64, %p11;
	or.pred  	%p16, %p66, %p71;
	@%p68 bra 	$L__BB0_56;
	bra.uni 	$L__BB0_55;

$L__BB0_56:
	add.s32 	%r57, %r396, 1;
	mul.wide.u32 	%rd148, %r396, 4;
	add.s64 	%rd149, %rd12, %rd148;
	st.local.u32 	[%rd149], %r12;
	mov.u32 	%r396, %r57;
	mov.u32 	%r397, %r394;
	bra.uni 	$L__BB0_57;

$L__BB0_55:
	add.s32 	%r397, %r394, 1;
	mul.wide.u32 	%rd146, %r394, 4;
	add.s64 	%rd147, %rd13, %rd146;
	st.local.u32 	[%rd147], %r12;

$L__BB0_57:
	@%p14 bra 	$L__BB0_59;

	add.s32 	%r60, %r398, 1;
	mul.wide.u32 	%rd150, %r398, 4;
	add.s64 	%rd151, %rd14, %rd150;
	st.local.u32 	[%rd151], %r15;
	mov.u32 	%r398, %r60;

$L__BB0_59:
	@%p15 bra 	$L__BB0_61;
	bra.uni 	$L__BB0_60;

$L__BB0_61:
	mul.wide.u32 	%rd154, %r396, 4;
	add.s64 	%rd155, %rd12, %rd154;
	st.local.u32 	[%rd155], %r13;
	bra.uni 	$L__BB0_62;

$L__BB0_60:
	mul.wide.u32 	%rd152, %r397, 4;
	add.s64 	%rd153, %rd13, %rd152;
	st.local.u32 	[%rd153], %r13;

$L__BB0_62:
	@%p16 bra 	$L__BB0_64;

	mul.wide.u32 	%rd156, %r398, 4;
	add.s64 	%rd157, %rd14, %rd156;
	st.local.u32 	[%rd157], %r16;

$L__BB0_64:
	ld.local.u32 	%r418, [%rd12];
	ld.local.u32 	%r417, [%rd13];
	ld.local.u32 	%r420, [%rd14];
	ld.local.u32 	%r416, [%rd13+4];
	ld.local.u32 	%r419, [%rd14+4];
	setp.eq.s32 	%p72, %r11, %r418;
	mov.u32 	%r408, 2;
	mov.u32 	%r406, 1;
	mov.u32 	%r399, %r406;
	mov.u32 	%r405, %r408;
	@%p72 bra 	$L__BB0_67;

	setp.eq.s32 	%p73, %r11, %r417;
	mov.u32 	%r399, 0;
	@%p73 bra 	$L__BB0_67;

	setp.eq.s32 	%p74, %r11, %r416;
	selp.b32 	%r405, 0, 2, %p74;
	mov.u32 	%r399, %r406;

$L__BB0_67:
	setp.eq.s32 	%p75, %r421, %r418;
	mov.u32 	%r401, %r406;
	@%p75 bra 	$L__BB0_70;

	setp.eq.s32 	%p76, %r421, %r420;
	mov.u32 	%r401, 0;
	@%p76 bra 	$L__BB0_70;

	setp.eq.s32 	%p77, %r421, %r419;
	selp.b32 	%r408, 0, 2, %p77;
	mov.u32 	%r401, %r406;

$L__BB0_70:
	setp.eq.s32 	%p78, %r12, %r418;
	mov.u32 	%r403, %r406;
	mov.u32 	%r404, %r399;
	@%p78 bra 	$L__BB0_73;

	setp.eq.s32 	%p79, %r12, %r417;
	mov.u32 	%r404, 1;
	mov.u32 	%r403, 0;
	@%p79 bra 	$L__BB0_73;

	setp.eq.s32 	%p80, %r12, %r416;
	selp.b32 	%r405, 1, %r405, %p80;
	mov.u32 	%r404, %r399;

$L__BB0_73:
	setp.eq.s32 	%p81, %r15, %r418;
	mov.u32 	%r407, %r401;
	@%p81 bra 	$L__BB0_76;

	setp.eq.s32 	%p82, %r15, %r420;
	mov.u32 	%r407, 1;
	mov.u32 	%r406, 0;
	@%p82 bra 	$L__BB0_76;

	setp.eq.s32 	%p83, %r15, %r419;
	selp.b32 	%r408, 1, %r408, %p83;
	mov.u32 	%r407, %r401;

$L__BB0_76:
	setp.eq.s32 	%p84, %r13, %r418;
	mov.u32 	%r412, 2;
	mov.u32 	%r415, %r412;
	mov.u32 	%r410, %r404;
	@%p84 bra 	$L__BB0_79;

	setp.eq.s32 	%p85, %r13, %r417;
	mov.u32 	%r410, 2;
	mov.u32 	%r415, %r403;
	@%p85 bra 	$L__BB0_79;

	setp.eq.s32 	%p86, %r13, %r416;
	selp.b32 	%r405, 2, %r405, %p86;
	mov.u32 	%r415, %r403;
	mov.u32 	%r410, %r404;

$L__BB0_79:
	setp.eq.s32 	%p87, %r16, %r418;
	mov.u32 	%r413, %r407;
	@%p87 bra 	$L__BB0_82;

	setp.eq.s32 	%p88, %r16, %r420;
	mov.u32 	%r413, 2;
	mov.u32 	%r412, %r406;
	@%p88 bra 	$L__BB0_82;

	setp.eq.s32 	%p89, %r16, %r419;
	selp.b32 	%r408, 2, %r408, %p89;
	mov.u32 	%r412, %r406;
	mov.u32 	%r413, %r407;

$L__BB0_82:
	ld.param.u32 	%r422, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_14];
	ld.param.u64 	%rd264, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_13];
	ld.param.u64 	%rd263, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_12];
	st.local.u32 	[%rd19+8], %r405;
	st.local.u32 	[%rd19+4], %r410;
	st.local.u32 	[%rd20+8], %r408;
	st.local.u32 	[%rd20+4], %r413;
	st.local.u32 	[%rd20], %r412;
	mov.u32 	%r421, %r418;
	bra.uni 	$L__BB0_83;

$L__BB0_16:
	st.local.u32 	[%rd13], %r11;
	mov.u32 	%r374, 0;

$L__BB0_18:
	setp.eq.s32 	%p4, %r12, %r421;
	setp.eq.s32 	%p5, %r13, %r421;
	or.pred  	%p30, %p4, %p1;
	or.pred  	%p31, %p5, %p30;
	mov.u32 	%r376, 0;
	@%p31 bra 	$L__BB0_20;

	st.local.u32 	[%rd14], %r421;
	mov.u32 	%r376, 1;

$L__BB0_20:
	setp.eq.s32 	%p32, %r12, %r15;
	setp.eq.s32 	%p33, %r12, %r16;
	setp.eq.s32 	%p34, %r13, %r15;
	setp.eq.s32 	%p35, %r13, %r16;
	or.pred  	%p36, %p32, %p4;
	or.pred  	%p37, %p33, %p36;
	or.pred  	%p38, %p32, %p2;
	or.pred  	%p6, %p34, %p38;
	or.pred  	%p39, %p34, %p5;
	or.pred  	%p7, %p35, %p39;
	or.pred  	%p40, %p33, %p3;
	or.pred  	%p8, %p35, %p40;
	@%p37 bra 	$L__BB0_22;
	bra.uni 	$L__BB0_21;

$L__BB0_22:
	add.s32 	%r22, %r374, 1;
	mul.wide.u32 	%rd136, %r374, 4;
	add.s64 	%rd137, %rd12, %rd136;
	st.local.u32 	[%rd137], %r12;
	mov.u32 	%r374, %r22;
	mov.u32 	%r375, %r372;
	bra.uni 	$L__BB0_23;

$L__BB0_21:
	add.s32 	%r375, %r372, 1;
	mul.wide.u32 	%rd134, %r372, 4;
	add.s64 	%rd135, %rd13, %rd134;
	st.local.u32 	[%rd135], %r12;

$L__BB0_23:
	@%p6 bra 	$L__BB0_25;

	add.s32 	%r25, %r376, 1;
	mul.wide.u32 	%rd138, %r376, 4;
	add.s64 	%rd139, %rd14, %rd138;
	st.local.u32 	[%rd139], %r15;
	mov.u32 	%r376, %r25;

$L__BB0_25:
	@%p7 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	mul.wide.u32 	%rd142, %r374, 4;
	add.s64 	%rd143, %rd12, %rd142;
	st.local.u32 	[%rd143], %r13;
	bra.uni 	$L__BB0_28;

$L__BB0_26:
	mul.wide.u32 	%rd140, %r375, 4;
	add.s64 	%rd141, %rd13, %rd140;
	st.local.u32 	[%rd141], %r13;

$L__BB0_28:
	@%p8 bra 	$L__BB0_30;

	mul.wide.u32 	%rd144, %r376, 4;
	add.s64 	%rd145, %rd14, %rd144;
	st.local.u32 	[%rd145], %r16;

$L__BB0_30:
	ld.local.u32 	%r418, [%rd12];
	ld.local.u32 	%r417, [%rd12+4];
	ld.local.u32 	%r416, [%rd13];
	ld.local.u32 	%r419, [%rd14];
	setp.eq.s32 	%p41, %r11, %r418;
	mov.u32 	%r384, 1;
	mov.u32 	%r377, %r384;
	mov.u32 	%r383, %r386;
	@%p41 bra 	$L__BB0_33;

	setp.eq.s32 	%p42, %r11, %r417;
	mov.u32 	%r377, 0;
	mov.u32 	%r383, %r386;
	@%p42 bra 	$L__BB0_33;

	setp.eq.s32 	%p43, %r11, %r416;
	selp.b32 	%r383, 0, 2, %p43;
	mov.u32 	%r377, %r384;

$L__BB0_33:
	setp.eq.s32 	%p44, %r421, %r418;
	mov.u32 	%r379, %r384;
	@%p44 bra 	$L__BB0_36;

	setp.eq.s32 	%p45, %r421, %r417;
	mov.u32 	%r379, 0;
	@%p45 bra 	$L__BB0_36;

	setp.eq.s32 	%p46, %r421, %r419;
	selp.b32 	%r386, 0, 2, %p46;
	mov.u32 	%r379, %r384;

$L__BB0_36:
	setp.eq.s32 	%p47, %r12, %r418;
	mov.u32 	%r381, %r384;
	mov.u32 	%r382, %r377;
	@%p47 bra 	$L__BB0_39;

	setp.eq.s32 	%p48, %r12, %r417;
	mov.u32 	%r382, 1;
	mov.u32 	%r381, 0;
	@%p48 bra 	$L__BB0_39;

	setp.eq.s32 	%p49, %r12, %r416;
	selp.b32 	%r383, 1, %r383, %p49;
	mov.u32 	%r382, %r377;

$L__BB0_39:
	setp.eq.s32 	%p50, %r15, %r418;
	mov.u32 	%r385, %r379;
	@%p50 bra 	$L__BB0_42;

	setp.eq.s32 	%p51, %r15, %r417;
	mov.u32 	%r385, 1;
	mov.u32 	%r384, 0;
	@%p51 bra 	$L__BB0_42;

	setp.eq.s32 	%p52, %r15, %r419;
	selp.b32 	%r386, 1, %r386, %p52;
	mov.u32 	%r385, %r379;

$L__BB0_42:
	setp.eq.s32 	%p53, %r13, %r418;
	mov.u32 	%r390, 2;
	mov.u32 	%r415, %r390;
	mov.u32 	%r388, %r382;
	@%p53 bra 	$L__BB0_45;

	setp.eq.s32 	%p54, %r13, %r417;
	mov.u32 	%r388, 2;
	mov.u32 	%r415, %r381;
	@%p54 bra 	$L__BB0_45;

	setp.eq.s32 	%p55, %r13, %r416;
	selp.b32 	%r383, 2, %r383, %p55;
	mov.u32 	%r415, %r381;
	mov.u32 	%r388, %r382;

$L__BB0_45:
	setp.eq.s32 	%p56, %r16, %r418;
	mov.u32 	%r391, %r385;
	@%p56 bra 	$L__BB0_48;

	setp.eq.s32 	%p57, %r16, %r417;
	mov.u32 	%r391, 2;
	mov.u32 	%r390, %r384;
	@%p57 bra 	$L__BB0_48;

	setp.eq.s32 	%p58, %r16, %r419;
	selp.b32 	%r386, 2, %r386, %p58;
	mov.u32 	%r390, %r384;
	mov.u32 	%r391, %r385;

$L__BB0_48:
	ld.param.u32 	%r422, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_17];
	ld.param.u64 	%rd264, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_16];
	ld.param.u64 	%rd263, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_15];
	st.local.u32 	[%rd19+8], %r383;
	st.local.u32 	[%rd19+4], %r388;
	st.local.u32 	[%rd20+8], %r386;
	st.local.u32 	[%rd20+4], %r391;
	st.local.u32 	[%rd20], %r390;
	mov.u32 	%r420, %r417;
	mov.u32 	%r421, %r418;

$L__BB0_83:
	mov.u32 	%r424, 0;
	cvta.to.global.u64 	%rd47, %rd264;
	mul.lo.s32 	%r251, %r418, 3;
	mul.wide.s32 	%rd158, %r251, 8;
	add.s64 	%rd159, %rd30, %rd158;
	ld.global.f64 	%fd5, [%rd159+8];
	ld.global.f64 	%fd6, [%rd159+16];
	mul.lo.s32 	%r252, %r417, 3;
	mul.wide.s32 	%rd160, %r252, 8;
	add.s64 	%rd161, %rd30, %rd160;
	ld.global.f64 	%fd186, [%rd161+8];
	ld.global.f64 	%fd187, [%rd161+16];
	mul.lo.s32 	%r253, %r416, 3;
	mul.wide.s32 	%rd162, %r253, 8;
	add.s64 	%rd163, %rd30, %rd162;
	ld.global.f64 	%fd188, [%rd163];
	ld.global.f64 	%fd189, [%rd163+8];
	ld.global.f64 	%fd190, [%rd163+16];
	mul.lo.s32 	%r254, %r421, 3;
	mul.wide.s32 	%rd164, %r254, 8;
	add.s64 	%rd165, %rd30, %rd164;
	ld.global.f64 	%fd7, [%rd165];
	ld.global.f64 	%fd8, [%rd165+8];
	ld.global.f64 	%fd9, [%rd165+16];
	mul.lo.s32 	%r255, %r420, 3;
	mul.wide.s32 	%rd166, %r255, 8;
	add.s64 	%rd167, %rd30, %rd166;
	ld.global.f64 	%fd191, [%rd167];
	ld.global.f64 	%fd192, [%rd167+8];
	ld.global.f64 	%fd193, [%rd167+16];
	mul.lo.s32 	%r256, %r419, 3;
	mul.wide.s32 	%rd168, %r256, 8;
	add.s64 	%rd169, %rd30, %rd168;
	ld.global.f64 	%fd194, [%rd169];
	ld.global.f64 	%fd195, [%rd169+8];
	ld.global.f64 	%fd196, [%rd169+16];
	ld.global.f64 	%fd197, [%rd161];
	ld.global.f64 	%fd10, [%rd159];
	sub.f64 	%fd198, %fd197, %fd10;
	st.f64 	[%rd38], %fd198;
	sub.f64 	%fd199, %fd186, %fd5;
	st.f64 	[%rd38+8], %fd199;
	sub.f64 	%fd200, %fd187, %fd6;
	st.f64 	[%rd38+16], %fd200;
	sub.f64 	%fd201, %fd188, %fd10;
	st.f64 	[%rd38+24], %fd201;
	sub.f64 	%fd202, %fd189, %fd5;
	st.f64 	[%rd38+32], %fd202;
	sub.f64 	%fd203, %fd190, %fd6;
	st.f64 	[%rd38+40], %fd203;
	sub.f64 	%fd204, %fd191, %fd7;
	st.f64 	[%rd39], %fd204;
	sub.f64 	%fd205, %fd192, %fd8;
	st.f64 	[%rd39+8], %fd205;
	sub.f64 	%fd206, %fd193, %fd9;
	st.f64 	[%rd39+16], %fd206;
	sub.f64 	%fd207, %fd194, %fd7;
	st.f64 	[%rd39+24], %fd207;
	sub.f64 	%fd208, %fd195, %fd8;
	st.f64 	[%rd39+32], %fd208;
	sub.f64 	%fd209, %fd196, %fd9;
	st.f64 	[%rd39+40], %fd209;
	st.local.u64 	[%rd21], %rd116;
	st.local.u64 	[%rd21+8], %rd116;
	st.local.u64 	[%rd21+16], %rd116;
	st.local.u64 	[%rd21+24], %rd116;
	st.local.u64 	[%rd21+32], %rd116;
	st.local.u64 	[%rd21+40], %rd116;
	st.local.u64 	[%rd21+48], %rd116;
	st.local.u64 	[%rd21+56], %rd116;
	st.local.u64 	[%rd21+64], %rd116;
	st.local.u64 	[%rd22], %rd116;
	st.local.u64 	[%rd22+8], %rd116;
	st.local.u64 	[%rd22+16], %rd116;
	st.local.u64 	[%rd22+24], %rd116;
	st.local.u64 	[%rd22+32], %rd116;
	st.local.u64 	[%rd22+40], %rd116;
	st.local.u64 	[%rd22+48], %rd116;
	st.local.u64 	[%rd22+56], %rd116;
	st.local.u64 	[%rd22+64], %rd116;
	st.local.u64 	[%rd23], %rd116;
	st.local.u64 	[%rd23+8], %rd116;
	st.local.u64 	[%rd23+16], %rd116;
	st.local.u64 	[%rd23+24], %rd116;
	st.local.u64 	[%rd23+32], %rd116;
	st.local.u64 	[%rd23+40], %rd116;
	st.local.u64 	[%rd23+48], %rd116;
	st.local.u64 	[%rd23+56], %rd116;
	st.local.u64 	[%rd23+64], %rd116;
	st.local.u64 	[%rd24], %rd116;
	st.local.u64 	[%rd24+8], %rd116;
	st.local.u64 	[%rd24+16], %rd116;
	st.local.u64 	[%rd24+24], %rd116;
	st.local.u64 	[%rd24+32], %rd116;
	st.local.u64 	[%rd24+40], %rd116;
	st.local.u64 	[%rd24+48], %rd116;
	st.local.u64 	[%rd24+56], %rd116;
	st.local.u64 	[%rd24+64], %rd116;
	st.local.u64 	[%rd25], %rd116;
	st.local.u64 	[%rd25+8], %rd116;
	st.local.u64 	[%rd25+16], %rd116;
	st.local.u64 	[%rd25+24], %rd116;
	st.local.u64 	[%rd25+32], %rd116;
	st.local.u64 	[%rd25+40], %rd116;
	st.local.u64 	[%rd25+48], %rd116;
	st.local.u64 	[%rd25+56], %rd116;
	st.local.u64 	[%rd25+64], %rd116;
	mov.u32 	%r423, %r415;
	bra.uni 	$L__BB0_84;

$L__BB0_176:
	add.s64 	%rd258, %rd19, 4;
	shl.b64 	%rd239, %rd51, 2;
	add.s64 	%rd240, %rd258, %rd239;
	ld.local.u32 	%r423, [%rd240];

$L__BB0_84:
	mov.u32 	%r425, 0;
	cvt.s64.s32 	%rd51, %r424;
	add.s32 	%r258, %r423, 1;
	mul.hi.s32 	%r259, %r258, 1431655766;
	shr.u32 	%r260, %r259, 31;
	add.s32 	%r261, %r259, %r260;
	mul.lo.s32 	%r262, %r261, 3;
	sub.s32 	%r263, %r258, %r262;
	add.s32 	%r264, %r263, 1;
	mul.hi.s32 	%r265, %r264, 1431655766;
	shr.u32 	%r266, %r265, 31;
	add.s32 	%r267, %r265, %r266;
	mul.lo.s32 	%r268, %r267, 3;
	sub.s32 	%r269, %r264, %r268;
	mul.wide.s32 	%rd171, %r263, 4;
	add.s64 	%rd172, %rd15, %rd171;
	mul.wide.s32 	%rd173, %r269, 4;
	add.s64 	%rd174, %rd15, %rd173;
	ld.local.u32 	%r270, [%rd174];
	ld.local.u32 	%r271, [%rd172];
	setp.lt.s32 	%p90, %r271, %r270;
	selp.f64 	%fd11, 0d3FF0000000000000, 0dBFF0000000000000, %p90;
	mul.wide.s32 	%rd175, %r423, 4;
	add.s64 	%rd52, %rd17, %rd175;

$L__BB0_85:
	mul.wide.s32 	%rd176, %r425, 4;
	add.s64 	%rd177, %rd20, %rd176;
	ld.local.u32 	%r100, [%rd177];
	add.s32 	%r274, %r100, 1;
	mul.hi.s32 	%r275, %r274, 1431655766;
	shr.u32 	%r276, %r275, 31;
	add.s32 	%r277, %r275, %r276;
	mul.lo.s32 	%r278, %r277, 3;
	sub.s32 	%r279, %r274, %r278;
	add.s32 	%r280, %r279, 1;
	mul.hi.s32 	%r281, %r280, 1431655766;
	shr.u32 	%r282, %r281, 31;
	add.s32 	%r283, %r281, %r282;
	mul.lo.s32 	%r284, %r283, 3;
	sub.s32 	%r285, %r280, %r284;
	mul.wide.s32 	%rd178, %r279, 4;
	add.s64 	%rd179, %rd16, %rd178;
	mul.wide.s32 	%rd180, %r285, 4;
	add.s64 	%rd181, %rd16, %rd180;
	ld.local.u32 	%r286, [%rd181];
	ld.local.u32 	%r287, [%rd179];
	setp.lt.s32 	%p91, %r287, %r286;
	selp.f64 	%fd14, 0d3FF0000000000000, 0dBFF0000000000000, %p91;
	mul.wide.s32 	%rd182, %r425, 3;
	add.s64 	%rd183, %rd182, %rd51;
	shl.b64 	%rd184, %rd183, 3;
	add.s64 	%rd53, %rd21, %rd184;
	add.s64 	%rd54, %rd22, %rd184;
	add.s64 	%rd55, %rd23, %rd184;
	add.s64 	%rd56, %rd24, %rd184;
	add.s64 	%rd57, %rd25, %rd184;
	setp.gt.s32 	%p92, %r422, 0;
	@%p92 bra 	$L__BB0_87;
	bra.uni 	$L__BB0_86;

$L__BB0_87:
	mov.u32 	%r426, 0;

$L__BB0_88:
	cvta.to.global.u64 	%rd259, %rd263;
	shr.u32 	%r366, %r424, 1;
	cvt.rn.f64.s32 	%fd660, %r366;
	and.b32  	%r365, %r424, 1;
	cvt.rn.f64.s32 	%fd659, %r365;
	shr.u32 	%r364, %r425, 1;
	cvt.rn.f64.s32 	%fd658, %r364;
	and.b32  	%r363, %r425, 1;
	cvt.rn.f64.s32 	%fd657, %r363;
	shl.b32 	%r291, %r426, 2;
	mul.wide.s32 	%rd185, %r291, 8;
	add.s64 	%rd186, %rd47, %rd185;
	ld.global.f64 	%fd210, [%rd186];
	sub.f64 	%fd211, %fd210, %fd659;
	ld.global.f64 	%fd212, [%rd186+8];
	sub.f64 	%fd213, %fd212, %fd660;
	ld.global.f64 	%fd214, [%rd186+16];
	sub.f64 	%fd215, %fd214, %fd657;
	ld.global.f64 	%fd216, [%rd186+24];
	sub.f64 	%fd217, %fd216, %fd658;
	ld.f64 	%fd218, [%rd38];
	ld.f64 	%fd219, [%rd38+24];
	mul.f64 	%fd220, %fd213, %fd219;
	fma.rn.f64 	%fd221, %fd211, %fd218, %fd220;
	mul.f64 	%fd22, %fd11, %fd221;
	ld.f64 	%fd222, [%rd38+8];
	ld.f64 	%fd223, [%rd38+32];
	mul.f64 	%fd224, %fd213, %fd223;
	fma.rn.f64 	%fd225, %fd211, %fd222, %fd224;
	mul.f64 	%fd23, %fd11, %fd225;
	ld.f64 	%fd226, [%rd38+16];
	ld.f64 	%fd227, [%rd38+40];
	mul.f64 	%fd228, %fd213, %fd227;
	fma.rn.f64 	%fd229, %fd211, %fd226, %fd228;
	mul.f64 	%fd24, %fd11, %fd229;
	ld.f64 	%fd230, [%rd39];
	ld.f64 	%fd231, [%rd39+24];
	mul.f64 	%fd232, %fd217, %fd231;
	fma.rn.f64 	%fd233, %fd215, %fd230, %fd232;
	mul.f64 	%fd25, %fd14, %fd233;
	ld.f64 	%fd234, [%rd39+8];
	ld.f64 	%fd235, [%rd39+32];
	mul.f64 	%fd236, %fd217, %fd235;
	fma.rn.f64 	%fd237, %fd215, %fd234, %fd236;
	mul.f64 	%fd26, %fd14, %fd237;
	ld.f64 	%fd238, [%rd39+16];
	ld.f64 	%fd239, [%rd39+40];
	mul.f64 	%fd240, %fd217, %fd239;
	fma.rn.f64 	%fd241, %fd215, %fd238, %fd240;
	mul.f64 	%fd27, %fd14, %fd241;
	fma.rn.f64 	%fd242, %fd210, %fd218, %fd10;
	fma.rn.f64 	%fd243, %fd212, %fd219, %fd242;
	fma.rn.f64 	%fd244, %fd210, %fd222, %fd5;
	fma.rn.f64 	%fd28, %fd212, %fd223, %fd244;
	fma.rn.f64 	%fd245, %fd210, %fd226, %fd6;
	fma.rn.f64 	%fd246, %fd212, %fd227, %fd245;
	fma.rn.f64 	%fd247, %fd214, %fd230, %fd7;
	fma.rn.f64 	%fd248, %fd216, %fd231, %fd247;
	fma.rn.f64 	%fd249, %fd214, %fd234, %fd8;
	fma.rn.f64 	%fd29, %fd216, %fd235, %fd249;
	fma.rn.f64 	%fd250, %fd214, %fd238, %fd9;
	fma.rn.f64 	%fd251, %fd216, %fd239, %fd250;
	mul.wide.s32 	%rd187, %r426, 8;
	add.s64 	%rd58, %rd259, %rd187;
	ld.global.f64 	%fd30, [%rd58];
	sub.f64 	%fd31, %fd248, %fd243;
	sub.f64 	%fd32, %fd29, %fd28;
	sub.f64 	%fd33, %fd251, %fd246;
	mul.f64 	%fd252, %fd33, %fd33;
	fma.rn.f64 	%fd253, %fd32, %fd32, %fd252;
	fma.rn.f64 	%fd254, %fd31, %fd31, %fd253;
	sqrt.rn.f64 	%fd34, %fd254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd28;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r427}, %fd28;
	}
	and.b32  	%r293, %r427, 2147483647;
	setp.eq.s32 	%p93, %r293, 2146435072;
	setp.eq.s32 	%p94, %r292, 0;
	and.pred  	%p17, %p94, %p93;
	not.pred 	%p95, %p17;
	mov.f64 	%fd675, %fd28;
	@%p95 bra 	$L__BB0_90;

	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd675, %fd28, %fd255;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r427}, %fd675;
	}

$L__BB0_90:
	mul.f64 	%fd256, %fd675, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r428, %fd256;
	st.local.u32 	[%rd2], %r428;
	cvt.rn.f64.s32 	%fd257, %r428;
	neg.f64 	%fd258, %fd257;
	mov.f64 	%fd259, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd260, %fd258, %fd259, %fd675;
	mov.f64 	%fd261, 0d3C91A62633145C00;
	fma.rn.f64 	%fd262, %fd258, %fd261, %fd260;
	mov.f64 	%fd263, 0d397B839A252049C0;
	fma.rn.f64 	%fd676, %fd258, %fd263, %fd262;
	and.b32  	%r294, %r427, 2145386496;
	setp.lt.u32 	%p96, %r294, 1105199104;
	@%p96 bra 	$L__BB0_92;

	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd675;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd676, [retval0+0];
	} // callseq 12
	ld.local.u32 	%r428, [%rd2];

$L__BB0_92:
	add.s32 	%r108, %r428, 1;
	and.b32  	%r295, %r108, 1;
	shl.b32 	%r296, %r108, 3;
	and.b32  	%r297, %r296, 8;
	setp.eq.s32 	%p97, %r295, 0;
	selp.f64 	%fd264, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p97;
	mul.wide.s32 	%rd189, %r297, 8;
	mov.u64 	%rd190, __cudart_sin_cos_coeffs;
	add.s64 	%rd191, %rd190, %rd189;
	ld.global.nc.f64 	%fd265, [%rd191+8];
	mul.rn.f64 	%fd40, %fd676, %fd676;
	fma.rn.f64 	%fd266, %fd264, %fd40, %fd265;
	ld.global.nc.f64 	%fd267, [%rd191+16];
	fma.rn.f64 	%fd268, %fd266, %fd40, %fd267;
	ld.global.nc.f64 	%fd269, [%rd191+24];
	fma.rn.f64 	%fd270, %fd268, %fd40, %fd269;
	ld.global.nc.f64 	%fd271, [%rd191+32];
	fma.rn.f64 	%fd272, %fd270, %fd40, %fd271;
	ld.global.nc.f64 	%fd273, [%rd191+40];
	fma.rn.f64 	%fd274, %fd272, %fd40, %fd273;
	ld.global.nc.f64 	%fd275, [%rd191+48];
	fma.rn.f64 	%fd41, %fd274, %fd40, %fd275;
	fma.rn.f64 	%fd678, %fd41, %fd676, %fd676;
	@%p97 bra 	$L__BB0_94;

	mov.f64 	%fd276, 0d3FF0000000000000;
	fma.rn.f64 	%fd678, %fd41, %fd40, %fd276;

$L__BB0_94:
	and.b32  	%r298, %r108, 2;
	setp.eq.s32 	%p98, %r298, 0;
	@%p98 bra 	$L__BB0_96;

	mov.f64 	%fd277, 0d0000000000000000;
	mov.f64 	%fd278, 0dBFF0000000000000;
	fma.rn.f64 	%fd678, %fd678, %fd278, %fd277;

$L__BB0_96:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r429}, %fd29;
	}
	and.b32  	%r299, %r429, 2147483647;
	setp.eq.s32 	%p99, %r299, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r300, %temp}, %fd29;
	}
	setp.eq.s32 	%p100, %r300, 0;
	and.pred  	%p18, %p100, %p99;
	not.pred 	%p101, %p18;
	mov.f64 	%fd679, %fd29;
	@%p101 bra 	$L__BB0_98;

	mov.f64 	%fd279, 0d0000000000000000;
	mul.rn.f64 	%fd679, %fd29, %fd279;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r429}, %fd679;
	}

$L__BB0_98:
	mov.f64 	%fd663, 0d397B839A252049C0;
	mov.f64 	%fd662, 0d3C91A62633145C00;
	mov.f64 	%fd661, 0d3FF921FB54442D18;
	mul.f64 	%fd280, %fd679, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r430, %fd280;
	st.local.u32 	[%rd2], %r430;
	cvt.rn.f64.s32 	%fd281, %r430;
	neg.f64 	%fd282, %fd281;
	fma.rn.f64 	%fd284, %fd282, %fd661, %fd679;
	fma.rn.f64 	%fd286, %fd282, %fd662, %fd284;
	fma.rn.f64 	%fd680, %fd282, %fd663, %fd286;
	and.b32  	%r301, %r429, 2145386496;
	setp.lt.u32 	%p102, %r301, 1105199104;
	@%p102 bra 	$L__BB0_100;

	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd679;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd680, [retval0+0];
	} // callseq 13
	ld.local.u32 	%r430, [%rd2];

$L__BB0_100:
	mov.u64 	%rd260, __cudart_sin_cos_coeffs;
	add.s32 	%r115, %r430, 1;
	and.b32  	%r302, %r115, 1;
	shl.b32 	%r303, %r115, 3;
	and.b32  	%r304, %r303, 8;
	setp.eq.s32 	%p103, %r302, 0;
	selp.f64 	%fd288, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p103;
	mul.wide.s32 	%rd193, %r304, 8;
	add.s64 	%rd195, %rd260, %rd193;
	ld.global.nc.f64 	%fd289, [%rd195+8];
	mul.rn.f64 	%fd52, %fd680, %fd680;
	fma.rn.f64 	%fd290, %fd288, %fd52, %fd289;
	ld.global.nc.f64 	%fd291, [%rd195+16];
	fma.rn.f64 	%fd292, %fd290, %fd52, %fd291;
	ld.global.nc.f64 	%fd293, [%rd195+24];
	fma.rn.f64 	%fd294, %fd292, %fd52, %fd293;
	ld.global.nc.f64 	%fd295, [%rd195+32];
	fma.rn.f64 	%fd296, %fd294, %fd52, %fd295;
	ld.global.nc.f64 	%fd297, [%rd195+40];
	fma.rn.f64 	%fd298, %fd296, %fd52, %fd297;
	ld.global.nc.f64 	%fd299, [%rd195+48];
	fma.rn.f64 	%fd53, %fd298, %fd52, %fd299;
	fma.rn.f64 	%fd682, %fd53, %fd680, %fd680;
	@%p103 bra 	$L__BB0_102;

	mov.f64 	%fd300, 0d3FF0000000000000;
	fma.rn.f64 	%fd682, %fd53, %fd52, %fd300;

$L__BB0_102:
	and.b32  	%r305, %r115, 2;
	setp.eq.s32 	%p104, %r305, 0;
	@%p104 bra 	$L__BB0_104;

	mov.f64 	%fd301, 0d0000000000000000;
	mov.f64 	%fd302, 0dBFF0000000000000;
	fma.rn.f64 	%fd682, %fd682, %fd302, %fd301;

$L__BB0_104:
	sub.f64 	%fd672, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd29;
	}
	sub.f64 	%fd303, %fd678, %fd682;
	mul.f64 	%fd59, %fd33, 0d0000000000000000;
	fma.rn.f64 	%fd304, %fd672, %fd303, %fd59;
	mul.f64 	%fd60, %fd31, 0d0000000000000000;
	add.f64 	%fd305, %fd60, %fd304;
	div.rn.f64 	%fd306, %fd305, 0d402921FB54442D18;
	mul.f64 	%fd307, %fd34, %fd34;
	mul.f64 	%fd61, %fd34, %fd307;
	div.rn.f64 	%fd308, %fd306, %fd61;
	mul.f64 	%fd309, %fd30, %fd308;
	mul.f64 	%fd310, %fd27, %fd24;
	fma.rn.f64 	%fd311, %fd26, %fd23, %fd310;
	fma.rn.f64 	%fd312, %fd25, %fd22, %fd311;
	ld.local.f64 	%fd313, [%rd53];
	fma.rn.f64 	%fd719, %fd309, %fd312, %fd313;
	st.local.f64 	[%rd53], %fd719;
	ld.global.f64 	%fd63, [%rd58];
	mov.f64 	%fd683, %fd29;
	@%p101 bra 	$L__BB0_106;

	mov.f64 	%fd314, 0d0000000000000000;
	mul.rn.f64 	%fd683, %fd29, %fd314;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd683;
	}

$L__BB0_106:
	mov.f64 	%fd666, 0d397B839A252049C0;
	mov.f64 	%fd665, 0d3C91A62633145C00;
	mov.f64 	%fd664, 0d3FF921FB54442D18;
	mul.f64 	%fd315, %fd683, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r432, %fd315;
	st.local.u32 	[%rd2], %r432;
	cvt.rn.f64.s32 	%fd316, %r432;
	neg.f64 	%fd317, %fd316;
	fma.rn.f64 	%fd319, %fd317, %fd664, %fd683;
	fma.rn.f64 	%fd321, %fd317, %fd665, %fd319;
	fma.rn.f64 	%fd684, %fd317, %fd666, %fd321;
	and.b32  	%r306, %r431, 2145386496;
	setp.lt.u32 	%p106, %r306, 1105199104;
	@%p106 bra 	$L__BB0_108;

	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd683;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd684, [retval0+0];
	} // callseq 14
	ld.local.u32 	%r432, [%rd2];

$L__BB0_108:
	mov.u64 	%rd261, __cudart_sin_cos_coeffs;
	and.b32  	%r307, %r432, 1;
	shl.b32 	%r308, %r432, 3;
	and.b32  	%r309, %r308, 8;
	setp.eq.s32 	%p107, %r307, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p107;
	mul.wide.s32 	%rd197, %r309, 8;
	add.s64 	%rd199, %rd261, %rd197;
	ld.global.nc.f64 	%fd324, [%rd199+8];
	mul.rn.f64 	%fd69, %fd684, %fd684;
	fma.rn.f64 	%fd325, %fd323, %fd69, %fd324;
	ld.global.nc.f64 	%fd326, [%rd199+16];
	fma.rn.f64 	%fd327, %fd325, %fd69, %fd326;
	ld.global.nc.f64 	%fd328, [%rd199+24];
	fma.rn.f64 	%fd329, %fd327, %fd69, %fd328;
	ld.global.nc.f64 	%fd330, [%rd199+32];
	fma.rn.f64 	%fd331, %fd329, %fd69, %fd330;
	ld.global.nc.f64 	%fd332, [%rd199+40];
	fma.rn.f64 	%fd333, %fd331, %fd69, %fd332;
	ld.global.nc.f64 	%fd334, [%rd199+48];
	fma.rn.f64 	%fd70, %fd333, %fd69, %fd334;
	fma.rn.f64 	%fd686, %fd70, %fd684, %fd684;
	@%p107 bra 	$L__BB0_110;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd686, %fd70, %fd69, %fd335;

$L__BB0_110:
	and.b32  	%r310, %r432, 2;
	setp.eq.s32 	%p108, %r310, 0;
	@%p108 bra 	$L__BB0_112;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd686, %fd686, %fd337, %fd336;

$L__BB0_112:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r433}, %fd29;
	}
	mul.f64 	%fd76, %fd27, 0d0000000000000000;
	fma.rn.f64 	%fd338, %fd26, 0d0000000000000000, %fd76;
	mul.f64 	%fd77, %fd25, 0d0000000000000000;
	add.f64 	%fd78, %fd77, %fd338;
	mul.f64 	%fd339, %fd686, %fd26;
	sub.f64 	%fd340, %fd76, %fd339;
	add.f64 	%fd341, %fd77, %fd340;
	mul.f64 	%fd342, %fd78, %fd24;
	fma.rn.f64 	%fd343, %fd341, %fd23, %fd342;
	fma.rn.f64 	%fd344, %fd78, %fd22, %fd343;
	mov.f64 	%fd345, 0d3FB45F306DC9C883;
	div.rn.f64 	%fd346, %fd345, %fd34;
	mul.f64 	%fd347, %fd63, %fd346;
	ld.local.f64 	%fd348, [%rd54];
	fma.rn.f64 	%fd718, %fd347, %fd344, %fd348;
	st.local.f64 	[%rd54], %fd718;
	ld.global.f64 	%fd80, [%rd58];
	mov.f64 	%fd687, %fd29;
	@%p101 bra 	$L__BB0_114;

	mov.f64 	%fd349, 0d0000000000000000;
	mul.rn.f64 	%fd687, %fd29, %fd349;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r433}, %fd687;
	}

$L__BB0_114:
	mov.f64 	%fd669, 0d397B839A252049C0;
	mov.f64 	%fd668, 0d3C91A62633145C00;
	mov.f64 	%fd667, 0d3FF921FB54442D18;
	mul.f64 	%fd350, %fd687, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r434, %fd350;
	st.local.u32 	[%rd2], %r434;
	cvt.rn.f64.s32 	%fd351, %r434;
	neg.f64 	%fd352, %fd351;
	fma.rn.f64 	%fd354, %fd352, %fd667, %fd687;
	fma.rn.f64 	%fd356, %fd352, %fd668, %fd354;
	fma.rn.f64 	%fd688, %fd352, %fd669, %fd356;
	and.b32  	%r311, %r433, 2145386496;
	setp.lt.u32 	%p110, %r311, 1105199104;
	@%p110 bra 	$L__BB0_116;

	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd687;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd688, [retval0+0];
	} // callseq 15
	ld.local.u32 	%r434, [%rd2];

$L__BB0_116:
	mov.u64 	%rd262, __cudart_sin_cos_coeffs;
	and.b32  	%r312, %r434, 1;
	shl.b32 	%r313, %r434, 3;
	and.b32  	%r314, %r313, 8;
	setp.eq.s32 	%p111, %r312, 0;
	selp.f64 	%fd358, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p111;
	mul.wide.s32 	%rd201, %r314, 8;
	add.s64 	%rd203, %rd262, %rd201;
	ld.global.nc.f64 	%fd359, [%rd203+8];
	mul.rn.f64 	%fd86, %fd688, %fd688;
	fma.rn.f64 	%fd360, %fd358, %fd86, %fd359;
	ld.global.nc.f64 	%fd361, [%rd203+16];
	fma.rn.f64 	%fd362, %fd360, %fd86, %fd361;
	ld.global.nc.f64 	%fd363, [%rd203+24];
	fma.rn.f64 	%fd364, %fd362, %fd86, %fd363;
	ld.global.nc.f64 	%fd365, [%rd203+32];
	fma.rn.f64 	%fd366, %fd364, %fd86, %fd365;
	ld.global.nc.f64 	%fd367, [%rd203+40];
	fma.rn.f64 	%fd368, %fd366, %fd86, %fd367;
	ld.global.nc.f64 	%fd369, [%rd203+48];
	fma.rn.f64 	%fd87, %fd368, %fd86, %fd369;
	fma.rn.f64 	%fd690, %fd87, %fd688, %fd688;
	@%p111 bra 	$L__BB0_118;

	mov.f64 	%fd370, 0d3FF0000000000000;
	fma.rn.f64 	%fd690, %fd87, %fd86, %fd370;

$L__BB0_118:
	and.b32  	%r315, %r434, 2;
	setp.eq.s32 	%p112, %r315, 0;
	@%p112 bra 	$L__BB0_120;

	mov.f64 	%fd371, 0d0000000000000000;
	mov.f64 	%fd372, 0dBFF0000000000000;
	fma.rn.f64 	%fd690, %fd690, %fd372, %fd371;

$L__BB0_120:
	sub.f64 	%fd673, %fd29, %fd28;
	mul.f64 	%fd632, %fd25, 0d0000000000000000;
	mul.f64 	%fd631, %fd27, 0d0000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r435}, %fd29;
	}
	div.rn.f64 	%fd373, %fd31, 0d402921FB54442D18;
	div.rn.f64 	%fd374, %fd373, %fd61;
	div.rn.f64 	%fd375, %fd33, 0d402921FB54442D18;
	div.rn.f64 	%fd376, %fd375, %fd61;
	mul.f64 	%fd377, %fd690, %fd26;
	sub.f64 	%fd378, %fd631, %fd377;
	add.f64 	%fd379, %fd632, %fd378;
	mul.f64 	%fd380, %fd376, %fd379;
	div.rn.f64 	%fd381, %fd673, 0d402921FB54442D18;
	div.rn.f64 	%fd382, %fd381, %fd61;
	mul.f64 	%fd383, %fd382, %fd78;
	sub.f64 	%fd384, %fd383, %fd380;
	mul.f64 	%fd385, %fd374, %fd78;
	mul.f64 	%fd386, %fd376, %fd78;
	sub.f64 	%fd387, %fd386, %fd385;
	mul.f64 	%fd388, %fd374, %fd379;
	sub.f64 	%fd389, %fd388, %fd383;
	mul.f64 	%fd390, %fd23, %fd387;
	fma.rn.f64 	%fd391, %fd389, %fd24, %fd390;
	fma.rn.f64 	%fd392, %fd22, %fd384, %fd391;
	ld.local.f64 	%fd393, [%rd55];
	fma.rn.f64 	%fd717, %fd80, %fd392, %fd393;
	st.local.f64 	[%rd55], %fd717;
	ld.global.f64 	%fd94, [%rd58];
	mov.f64 	%fd691, %fd29;
	@%p101 bra 	$L__BB0_122;

	mov.f64 	%fd394, 0d0000000000000000;
	mul.rn.f64 	%fd691, %fd29, %fd394;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r435}, %fd691;
	}

$L__BB0_122:
	mov.f64 	%fd635, 0d397B839A252049C0;
	mov.f64 	%fd634, 0d3C91A62633145C00;
	mov.f64 	%fd633, 0d3FF921FB54442D18;
	mul.f64 	%fd395, %fd691, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r436, %fd395;
	st.local.u32 	[%rd2], %r436;
	cvt.rn.f64.s32 	%fd396, %r436;
	neg.f64 	%fd397, %fd396;
	fma.rn.f64 	%fd399, %fd397, %fd633, %fd691;
	fma.rn.f64 	%fd401, %fd397, %fd634, %fd399;
	fma.rn.f64 	%fd692, %fd397, %fd635, %fd401;
	and.b32  	%r316, %r435, 2145386496;
	setp.lt.u32 	%p114, %r316, 1105199104;
	@%p114 bra 	$L__BB0_124;

	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd691;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd692, [retval0+0];
	} // callseq 16
	ld.local.u32 	%r436, [%rd2];

$L__BB0_124:
	mov.u64 	%rd241, __cudart_sin_cos_coeffs;
	add.s32 	%r131, %r436, 1;
	and.b32  	%r317, %r131, 1;
	shl.b32 	%r318, %r131, 3;
	and.b32  	%r319, %r318, 8;
	setp.eq.s32 	%p115, %r317, 0;
	selp.f64 	%fd403, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p115;
	mul.wide.s32 	%rd205, %r319, 8;
	add.s64 	%rd207, %rd241, %rd205;
	ld.global.nc.f64 	%fd404, [%rd207+8];
	mul.rn.f64 	%fd100, %fd692, %fd692;
	fma.rn.f64 	%fd405, %fd403, %fd100, %fd404;
	ld.global.nc.f64 	%fd406, [%rd207+16];
	fma.rn.f64 	%fd407, %fd405, %fd100, %fd406;
	ld.global.nc.f64 	%fd408, [%rd207+24];
	fma.rn.f64 	%fd409, %fd407, %fd100, %fd408;
	ld.global.nc.f64 	%fd410, [%rd207+32];
	fma.rn.f64 	%fd411, %fd409, %fd100, %fd410;
	ld.global.nc.f64 	%fd412, [%rd207+40];
	fma.rn.f64 	%fd413, %fd411, %fd100, %fd412;
	ld.global.nc.f64 	%fd414, [%rd207+48];
	fma.rn.f64 	%fd101, %fd413, %fd100, %fd414;
	fma.rn.f64 	%fd694, %fd101, %fd692, %fd692;
	@%p115 bra 	$L__BB0_126;

	mov.f64 	%fd415, 0d3FF0000000000000;
	fma.rn.f64 	%fd694, %fd101, %fd100, %fd415;

$L__BB0_126:
	and.b32  	%r320, %r131, 2;
	setp.eq.s32 	%p116, %r320, 0;
	@%p116 bra 	$L__BB0_128;

	mov.f64 	%fd416, 0d0000000000000000;
	mov.f64 	%fd417, 0dBFF0000000000000;
	fma.rn.f64 	%fd694, %fd694, %fd417, %fd416;

$L__BB0_128:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r437}, %fd28;
	}
	mov.f64 	%fd695, %fd28;
	@%p95 bra 	$L__BB0_130;

	mov.f64 	%fd418, 0d0000000000000000;
	mul.rn.f64 	%fd695, %fd28, %fd418;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r437}, %fd695;
	}

$L__BB0_130:
	mov.f64 	%fd638, 0d397B839A252049C0;
	mov.f64 	%fd637, 0d3C91A62633145C00;
	mov.f64 	%fd636, 0d3FF921FB54442D18;
	mul.f64 	%fd419, %fd695, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r438, %fd419;
	st.local.u32 	[%rd2], %r438;
	cvt.rn.f64.s32 	%fd420, %r438;
	neg.f64 	%fd421, %fd420;
	fma.rn.f64 	%fd423, %fd421, %fd636, %fd695;
	fma.rn.f64 	%fd425, %fd421, %fd637, %fd423;
	fma.rn.f64 	%fd696, %fd421, %fd638, %fd425;
	and.b32  	%r321, %r437, 2145386496;
	setp.lt.u32 	%p118, %r321, 1105199104;
	@%p118 bra 	$L__BB0_132;

	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd695;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd696, [retval0+0];
	} // callseq 17
	ld.local.u32 	%r438, [%rd2];

$L__BB0_132:
	mov.u64 	%rd242, __cudart_sin_cos_coeffs;
	add.s32 	%r137, %r438, 1;
	and.b32  	%r322, %r137, 1;
	shl.b32 	%r323, %r137, 3;
	and.b32  	%r324, %r323, 8;
	setp.eq.s32 	%p119, %r322, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p119;
	mul.wide.s32 	%rd209, %r324, 8;
	add.s64 	%rd211, %rd242, %rd209;
	ld.global.nc.f64 	%fd428, [%rd211+8];
	mul.rn.f64 	%fd112, %fd696, %fd696;
	fma.rn.f64 	%fd429, %fd427, %fd112, %fd428;
	ld.global.nc.f64 	%fd430, [%rd211+16];
	fma.rn.f64 	%fd431, %fd429, %fd112, %fd430;
	ld.global.nc.f64 	%fd432, [%rd211+24];
	fma.rn.f64 	%fd433, %fd431, %fd112, %fd432;
	ld.global.nc.f64 	%fd434, [%rd211+32];
	fma.rn.f64 	%fd435, %fd433, %fd112, %fd434;
	ld.global.nc.f64 	%fd436, [%rd211+40];
	fma.rn.f64 	%fd437, %fd435, %fd112, %fd436;
	ld.global.nc.f64 	%fd438, [%rd211+48];
	fma.rn.f64 	%fd113, %fd437, %fd112, %fd438;
	fma.rn.f64 	%fd698, %fd113, %fd696, %fd696;
	@%p119 bra 	$L__BB0_134;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd698, %fd113, %fd112, %fd439;

$L__BB0_134:
	and.b32  	%r325, %r137, 2;
	setp.eq.s32 	%p120, %r325, 0;
	@%p120 bra 	$L__BB0_136;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd698, %fd698, %fd441, %fd440;

$L__BB0_136:
	sub.f64 	%fd674, %fd29, %fd28;
	mul.f64 	%fd640, %fd31, 0d0000000000000000;
	mul.f64 	%fd639, %fd33, 0d0000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r439}, %fd29;
	}
	sub.f64 	%fd442, %fd694, %fd698;
	fma.rn.f64 	%fd443, %fd674, %fd442, %fd639;
	add.f64 	%fd119, %fd640, %fd443;
	mov.f64 	%fd699, %fd29;
	@%p101 bra 	$L__BB0_138;

	mov.f64 	%fd444, 0d0000000000000000;
	mul.rn.f64 	%fd699, %fd29, %fd444;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r439}, %fd699;
	}

$L__BB0_138:
	mov.f64 	%fd643, 0d397B839A252049C0;
	mov.f64 	%fd642, 0d3C91A62633145C00;
	mov.f64 	%fd641, 0d3FF921FB54442D18;
	mul.f64 	%fd445, %fd699, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r440, %fd445;
	st.local.u32 	[%rd2], %r440;
	cvt.rn.f64.s32 	%fd446, %r440;
	neg.f64 	%fd447, %fd446;
	fma.rn.f64 	%fd449, %fd447, %fd641, %fd699;
	fma.rn.f64 	%fd451, %fd447, %fd642, %fd449;
	fma.rn.f64 	%fd700, %fd447, %fd643, %fd451;
	and.b32  	%r326, %r439, 2145386496;
	setp.lt.u32 	%p122, %r326, 1105199104;
	@%p122 bra 	$L__BB0_140;

	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd699;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd700, [retval0+0];
	} // callseq 18
	ld.local.u32 	%r440, [%rd2];

$L__BB0_140:
	mov.u64 	%rd243, __cudart_sin_cos_coeffs;
	add.s32 	%r143, %r440, 1;
	and.b32  	%r327, %r143, 1;
	shl.b32 	%r328, %r143, 3;
	and.b32  	%r329, %r328, 8;
	setp.eq.s32 	%p123, %r327, 0;
	selp.f64 	%fd453, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p123;
	mul.wide.s32 	%rd213, %r329, 8;
	add.s64 	%rd215, %rd243, %rd213;
	ld.global.nc.f64 	%fd454, [%rd215+8];
	mul.rn.f64 	%fd125, %fd700, %fd700;
	fma.rn.f64 	%fd455, %fd453, %fd125, %fd454;
	ld.global.nc.f64 	%fd456, [%rd215+16];
	fma.rn.f64 	%fd457, %fd455, %fd125, %fd456;
	ld.global.nc.f64 	%fd458, [%rd215+24];
	fma.rn.f64 	%fd459, %fd457, %fd125, %fd458;
	ld.global.nc.f64 	%fd460, [%rd215+32];
	fma.rn.f64 	%fd461, %fd459, %fd125, %fd460;
	ld.global.nc.f64 	%fd462, [%rd215+40];
	fma.rn.f64 	%fd463, %fd461, %fd125, %fd462;
	ld.global.nc.f64 	%fd464, [%rd215+48];
	fma.rn.f64 	%fd126, %fd463, %fd125, %fd464;
	fma.rn.f64 	%fd702, %fd126, %fd700, %fd700;
	@%p123 bra 	$L__BB0_142;

	mov.f64 	%fd465, 0d3FF0000000000000;
	fma.rn.f64 	%fd702, %fd126, %fd125, %fd465;

$L__BB0_142:
	and.b32  	%r330, %r143, 2;
	setp.eq.s32 	%p124, %r330, 0;
	@%p124 bra 	$L__BB0_144;

	mov.f64 	%fd466, 0d0000000000000000;
	mov.f64 	%fd467, 0dBFF0000000000000;
	fma.rn.f64 	%fd702, %fd702, %fd467, %fd466;

$L__BB0_144:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r441}, %fd28;
	}
	mov.f64 	%fd703, %fd28;
	@%p95 bra 	$L__BB0_146;

	mov.f64 	%fd468, 0d0000000000000000;
	mul.rn.f64 	%fd703, %fd28, %fd468;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r441}, %fd703;
	}

$L__BB0_146:
	mov.f64 	%fd646, 0d397B839A252049C0;
	mov.f64 	%fd645, 0d3C91A62633145C00;
	mov.f64 	%fd644, 0d3FF921FB54442D18;
	mul.f64 	%fd469, %fd703, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r442, %fd469;
	st.local.u32 	[%rd2], %r442;
	cvt.rn.f64.s32 	%fd470, %r442;
	neg.f64 	%fd471, %fd470;
	fma.rn.f64 	%fd473, %fd471, %fd644, %fd703;
	fma.rn.f64 	%fd475, %fd471, %fd645, %fd473;
	fma.rn.f64 	%fd704, %fd471, %fd646, %fd475;
	and.b32  	%r331, %r441, 2145386496;
	setp.lt.u32 	%p126, %r331, 1105199104;
	@%p126 bra 	$L__BB0_148;

	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd703;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd704, [retval0+0];
	} // callseq 19
	ld.local.u32 	%r442, [%rd2];

$L__BB0_148:
	mov.u64 	%rd244, __cudart_sin_cos_coeffs;
	add.s32 	%r149, %r442, 1;
	and.b32  	%r332, %r149, 1;
	shl.b32 	%r333, %r149, 3;
	and.b32  	%r334, %r333, 8;
	setp.eq.s32 	%p127, %r332, 0;
	selp.f64 	%fd477, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p127;
	mul.wide.s32 	%rd217, %r334, 8;
	add.s64 	%rd219, %rd244, %rd217;
	ld.global.nc.f64 	%fd478, [%rd219+8];
	mul.rn.f64 	%fd137, %fd704, %fd704;
	fma.rn.f64 	%fd479, %fd477, %fd137, %fd478;
	ld.global.nc.f64 	%fd480, [%rd219+16];
	fma.rn.f64 	%fd481, %fd479, %fd137, %fd480;
	ld.global.nc.f64 	%fd482, [%rd219+24];
	fma.rn.f64 	%fd483, %fd481, %fd137, %fd482;
	ld.global.nc.f64 	%fd484, [%rd219+32];
	fma.rn.f64 	%fd485, %fd483, %fd137, %fd484;
	ld.global.nc.f64 	%fd486, [%rd219+40];
	fma.rn.f64 	%fd487, %fd485, %fd137, %fd486;
	ld.global.nc.f64 	%fd488, [%rd219+48];
	fma.rn.f64 	%fd138, %fd487, %fd137, %fd488;
	fma.rn.f64 	%fd706, %fd138, %fd704, %fd704;
	@%p127 bra 	$L__BB0_150;

	mov.f64 	%fd489, 0d3FF0000000000000;
	fma.rn.f64 	%fd706, %fd138, %fd137, %fd489;

$L__BB0_150:
	and.b32  	%r335, %r149, 2;
	setp.eq.s32 	%p128, %r335, 0;
	@%p128 bra 	$L__BB0_152;

	mov.f64 	%fd490, 0d0000000000000000;
	mov.f64 	%fd491, 0dBFF0000000000000;
	fma.rn.f64 	%fd706, %fd706, %fd491, %fd490;

$L__BB0_152:
	sub.f64 	%fd670, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r443}, %fd28;
	}
	mul.f64 	%fd492, %fd34, %fd61;
	mul.f64 	%fd493, %fd34, %fd492;
	mul.f64 	%fd494, %fd31, 0dBFCE8EC8A4AEACC4;
	mul.f64 	%fd495, %fd494, %fd119;
	div.rn.f64 	%fd496, %fd495, %fd493;
	mov.f64 	%fd497, 0d0000000000000000;
	div.rn.f64 	%fd498, %fd497, %fd61;
	add.f64 	%fd499, %fd498, %fd496;
	mul.f64 	%fd500, %fd670, 0dBFCE8EC8A4AEACC4;
	mul.f64 	%fd501, %fd500, %fd119;
	div.rn.f64 	%fd502, %fd501, %fd493;
	sub.f64 	%fd503, %fd702, %fd706;
	mul.f64 	%fd504, %fd503, 0d3FB45F306DC9C883;
	div.rn.f64 	%fd505, %fd504, %fd61;
	add.f64 	%fd506, %fd502, %fd505;
	mul.f64 	%fd507, %fd33, 0dBFCE8EC8A4AEACC4;
	mul.f64 	%fd508, %fd507, %fd119;
	div.rn.f64 	%fd509, %fd508, %fd493;
	add.f64 	%fd510, %fd498, %fd509;
	mul.f64 	%fd511, %fd27, %fd506;
	mul.f64 	%fd512, %fd510, %fd26;
	sub.f64 	%fd513, %fd511, %fd512;
	mul.f64 	%fd514, %fd510, %fd25;
	mul.f64 	%fd515, %fd499, %fd27;
	sub.f64 	%fd516, %fd514, %fd515;
	mul.f64 	%fd517, %fd499, %fd26;
	mul.f64 	%fd518, %fd506, %fd25;
	sub.f64 	%fd519, %fd517, %fd518;
	mul.f64 	%fd520, %fd519, %fd24;
	fma.rn.f64 	%fd521, %fd516, %fd23, %fd520;
	fma.rn.f64 	%fd522, %fd513, %fd22, %fd521;
	ld.local.f64 	%fd523, [%rd56];
	fma.rn.f64 	%fd716, %fd94, %fd522, %fd523;
	st.local.f64 	[%rd56], %fd716;
	ld.global.f64 	%fd145, [%rd58];
	mov.f64 	%fd707, %fd28;
	@%p95 bra 	$L__BB0_154;

	mul.rn.f64 	%fd707, %fd28, %fd497;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r443}, %fd707;
	}

$L__BB0_154:
	mov.f64 	%fd649, 0d397B839A252049C0;
	mov.f64 	%fd648, 0d3C91A62633145C00;
	mov.f64 	%fd647, 0d3FF921FB54442D18;
	mul.f64 	%fd525, %fd707, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r444, %fd525;
	st.local.u32 	[%rd2], %r444;
	cvt.rn.f64.s32 	%fd526, %r444;
	neg.f64 	%fd527, %fd526;
	fma.rn.f64 	%fd529, %fd527, %fd647, %fd707;
	fma.rn.f64 	%fd531, %fd527, %fd648, %fd529;
	fma.rn.f64 	%fd708, %fd527, %fd649, %fd531;
	and.b32  	%r336, %r443, 2145386496;
	setp.lt.u32 	%p130, %r336, 1105199104;
	@%p130 bra 	$L__BB0_156;

	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd707;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd708, [retval0+0];
	} // callseq 20
	ld.local.u32 	%r444, [%rd2];

$L__BB0_156:
	mov.u64 	%rd245, __cudart_sin_cos_coeffs;
	add.s32 	%r155, %r444, 1;
	and.b32  	%r337, %r155, 1;
	shl.b32 	%r338, %r155, 3;
	and.b32  	%r339, %r338, 8;
	setp.eq.s32 	%p131, %r337, 0;
	selp.f64 	%fd533, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p131;
	mul.wide.s32 	%rd221, %r339, 8;
	add.s64 	%rd223, %rd245, %rd221;
	ld.global.nc.f64 	%fd534, [%rd223+8];
	mul.rn.f64 	%fd151, %fd708, %fd708;
	fma.rn.f64 	%fd535, %fd533, %fd151, %fd534;
	ld.global.nc.f64 	%fd536, [%rd223+16];
	fma.rn.f64 	%fd537, %fd535, %fd151, %fd536;
	ld.global.nc.f64 	%fd538, [%rd223+24];
	fma.rn.f64 	%fd539, %fd537, %fd151, %fd538;
	ld.global.nc.f64 	%fd540, [%rd223+32];
	fma.rn.f64 	%fd541, %fd539, %fd151, %fd540;
	ld.global.nc.f64 	%fd542, [%rd223+40];
	fma.rn.f64 	%fd543, %fd541, %fd151, %fd542;
	ld.global.nc.f64 	%fd544, [%rd223+48];
	fma.rn.f64 	%fd152, %fd543, %fd151, %fd544;
	fma.rn.f64 	%fd710, %fd152, %fd708, %fd708;
	@%p131 bra 	$L__BB0_158;

	mov.f64 	%fd545, 0d3FF0000000000000;
	fma.rn.f64 	%fd710, %fd152, %fd151, %fd545;

$L__BB0_158:
	and.b32  	%r340, %r155, 2;
	setp.eq.s32 	%p132, %r340, 0;
	@%p132 bra 	$L__BB0_160;

	mov.f64 	%fd547, 0dBFF0000000000000;
	fma.rn.f64 	%fd710, %fd710, %fd547, %fd497;

$L__BB0_160:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r445}, %fd29;
	}
	mov.f64 	%fd711, %fd29;
	@%p101 bra 	$L__BB0_162;

	mul.rn.f64 	%fd711, %fd29, %fd497;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r445}, %fd711;
	}

$L__BB0_162:
	mov.f64 	%fd652, 0d397B839A252049C0;
	mov.f64 	%fd651, 0d3C91A62633145C00;
	mov.f64 	%fd650, 0d3FF921FB54442D18;
	mul.f64 	%fd549, %fd711, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r446, %fd549;
	st.local.u32 	[%rd2], %r446;
	cvt.rn.f64.s32 	%fd550, %r446;
	neg.f64 	%fd551, %fd550;
	fma.rn.f64 	%fd553, %fd551, %fd650, %fd711;
	fma.rn.f64 	%fd555, %fd551, %fd651, %fd553;
	fma.rn.f64 	%fd712, %fd551, %fd652, %fd555;
	and.b32  	%r341, %r445, 2145386496;
	setp.lt.u32 	%p134, %r341, 1105199104;
	@%p134 bra 	$L__BB0_164;

	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd711;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd712, [retval0+0];
	} // callseq 21
	ld.local.u32 	%r446, [%rd2];

$L__BB0_164:
	mov.u64 	%rd246, __cudart_sin_cos_coeffs;
	add.s32 	%r161, %r446, 1;
	and.b32  	%r342, %r161, 1;
	shl.b32 	%r343, %r161, 3;
	and.b32  	%r344, %r343, 8;
	setp.eq.s32 	%p135, %r342, 0;
	selp.f64 	%fd557, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p135;
	mul.wide.s32 	%rd225, %r344, 8;
	add.s64 	%rd227, %rd246, %rd225;
	ld.global.nc.f64 	%fd558, [%rd227+8];
	mul.rn.f64 	%fd163, %fd712, %fd712;
	fma.rn.f64 	%fd559, %fd557, %fd163, %fd558;
	ld.global.nc.f64 	%fd560, [%rd227+16];
	fma.rn.f64 	%fd561, %fd559, %fd163, %fd560;
	ld.global.nc.f64 	%fd562, [%rd227+24];
	fma.rn.f64 	%fd563, %fd561, %fd163, %fd562;
	ld.global.nc.f64 	%fd564, [%rd227+32];
	fma.rn.f64 	%fd565, %fd563, %fd163, %fd564;
	ld.global.nc.f64 	%fd566, [%rd227+40];
	fma.rn.f64 	%fd567, %fd565, %fd163, %fd566;
	ld.global.nc.f64 	%fd568, [%rd227+48];
	fma.rn.f64 	%fd164, %fd567, %fd163, %fd568;
	fma.rn.f64 	%fd714, %fd164, %fd712, %fd712;
	@%p135 bra 	$L__BB0_166;

	mov.f64 	%fd569, 0d3FF0000000000000;
	fma.rn.f64 	%fd714, %fd164, %fd163, %fd569;

$L__BB0_166:
	and.b32  	%r345, %r161, 2;
	setp.eq.s32 	%p136, %r345, 0;
	@%p136 bra 	$L__BB0_168;

	mov.f64 	%fd571, 0dBFF0000000000000;
	fma.rn.f64 	%fd714, %fd714, %fd571, %fd497;

$L__BB0_168:
	sub.f64 	%fd671, %fd29, %fd28;
	mul.f64 	%fd654, %fd31, 0d0000000000000000;
	mul.f64 	%fd653, %fd33, 0d0000000000000000;
	sub.f64 	%fd572, %fd710, %fd714;
	fma.rn.f64 	%fd573, %fd671, %fd572, %fd653;
	add.f64 	%fd574, %fd654, %fd573;
	div.rn.f64 	%fd575, %fd574, 0d402921FB54442D18;
	div.rn.f64 	%fd576, %fd575, %fd61;
	mul.f64 	%fd577, %fd145, %fd576;
	mul.f64 	%fd578, %fd577, 0d4010000000000000;
	mul.f64 	%fd579, %fd11, %fd578;
	ld.local.f64 	%fd580, [%rd57];
	fma.rn.f64 	%fd715, %fd14, %fd579, %fd580;
	st.local.f64 	[%rd57], %fd715;
	add.s32 	%r426, %r426, 1;
	setp.lt.s32 	%p137, %r426, %r422;
	@%p137 bra 	$L__BB0_88;
	bra.uni 	$L__BB0_169;

$L__BB0_86:
	ld.local.f64 	%fd719, [%rd53];
	ld.local.f64 	%fd718, [%rd54];
	ld.local.f64 	%fd717, [%rd55];
	ld.local.f64 	%fd716, [%rd56];
	ld.local.f64 	%fd715, [%rd57];

$L__BB0_169:
	ld.param.f64 	%fd656, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_38];
	ld.param.f64 	%fd655, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S2_S2_S2_ddS0_S2_S2_S2_S0_S0_iiiiii_param_39];
	ld.local.u32 	%r346, [%rd52];
	mul.wide.s32 	%rd228, %r346, 8;
	add.s64 	%rd229, %rd29, %rd228;
	ld.global.f64 	%fd581, [%rd229];
	mul.f64 	%fd582, %fd581, %fd719;
	mul.wide.s32 	%rd230, %r100, 4;
	add.s64 	%rd231, %rd18, %rd230;
	ld.local.u32 	%r347, [%rd231];
	mul.wide.s32 	%rd232, %r347, 8;
	add.s64 	%rd233, %rd29, %rd232;
	ld.global.f64 	%fd583, [%rd233];
	add.f64 	%fd584, %fd581, %fd581;
	mul.f64 	%fd585, %fd584, %fd718;
	mul.f64 	%fd586, %fd585, %fd583;
	fma.rn.f64 	%fd587, %fd582, %fd583, %fd586;
	mul.f64 	%fd588, %fd581, %fd717;
	add.s64 	%rd234, %rd28, %rd232;
	ld.global.f64 	%fd589, [%rd234];
	add.s64 	%rd235, %rd28, %rd228;
	ld.global.f64 	%fd590, [%rd235];
	mul.f64 	%fd591, %fd590, %fd717;
	mul.f64 	%fd592, %fd591, %fd583;
	fma.rn.f64 	%fd593, %fd588, %fd589, %fd592;
	mul.f64 	%fd594, %fd581, %fd716;
	fma.rn.f64 	%fd595, %fd594, %fd589, %fd593;
	mul.f64 	%fd596, %fd595, 0dC010000000000000;
	fma.rn.f64 	%fd597, %fd2, %fd587, %fd596;
	mul.f64 	%fd598, %fd3, %fd590;
	mul.f64 	%fd599, %fd598, %fd715;
	mul.f64 	%fd600, %fd599, %fd589;
	sub.f64 	%fd601, %fd597, %fd600;
	add.s64 	%rd236, %rd27, %rd228;
	ld.global.f64 	%fd602, [%rd236];
	mul.f64 	%fd603, %fd4, %fd602;
	mul.f64 	%fd604, %fd603, %fd719;
	add.s64 	%rd237, %rd27, %rd232;
	ld.global.f64 	%fd605, [%rd237];
	mul.f64 	%fd606, %fd604, %fd605;
	fma.rn.f64 	%fd607, %fd1, %fd601, %fd606;
	mul.f64 	%fd608, %fd581, %fd656;
	mul.f64 	%fd609, %fd608, %fd719;
	fma.rn.f64 	%fd610, %fd609, %fd605, %fd607;
	mul.f64 	%fd611, %fd602, %fd656;
	mul.f64 	%fd612, %fd611, %fd718;
	fma.rn.f64 	%fd613, %fd612, %fd605, %fd610;
	mul.f64 	%fd614, %fd602, %fd718;
	mul.f64 	%fd615, %fd581, %fd718;
	mul.f64 	%fd616, %fd615, %fd605;
	fma.rn.f64 	%fd617, %fd614, %fd583, %fd616;
	fma.rn.f64 	%fd618, %fd617, %fd656, %fd613;
	mul.f64 	%fd619, %fd602, %fd655;
	mul.f64 	%fd620, %fd619, %fd717;
	mul.f64 	%fd621, %fd620, %fd589;
	sub.f64 	%fd622, %fd618, %fd621;
	mul.f64 	%fd623, %fd590, %fd655;
	mul.f64 	%fd624, %fd623, %fd717;
	mul.f64 	%fd625, %fd624, %fd605;
	sub.f64 	%fd626, %fd622, %fd625;
	mul.f64 	%fd627, %fd619, %fd716;
	mul.f64 	%fd628, %fd627, %fd589;
	sub.f64 	%fd176, %fd626, %fd628;
	ld.global.u64 	%rd265, [%rd1];

$L__BB0_170:
	mov.b64 	%fd629, %rd265;
	add.f64 	%fd630, %fd176, %fd629;
	mov.b64 	%rd238, %fd630;
	atom.global.cas.b64 	%rd61, [%rd1], %rd265, %rd238;
	setp.ne.s64 	%p138, %rd265, %rd61;
	mov.u64 	%rd265, %rd61;
	@%p138 bra 	$L__BB0_170;

	add.s32 	%r425, %r425, 1;
	setp.lt.u32 	%p139, %r425, 3;
	@%p139 bra 	$L__BB0_85;

	cvt.u32.u64 	%r348, %rd51;
	add.s32 	%r424, %r348, 1;
	setp.lt.u32 	%p140, %r424, 3;
	@%p140 bra 	$L__BB0_176;

	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd39;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 22
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 23
	add.s32 	%r9, %r9, 1;
	setp.lt.s32 	%p141, %r9, %r4;
	@%p141 bra 	$L__BB0_4;

	st.local.u32 	[%rd19], %r415;
	bra.uni 	$L__BB0_175;

$L__BB0_11:
	st.local.u32 	[%rd19], %r415;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd39;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 10
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 11

$L__BB0_175:
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot1[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB1_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r4, %r11, %r10;
	mov.u32 	%r12, 19;
	sub.s32 	%r13, %r12, %r10;
	setp.gt.s32 	%p2, %r4, 14;
	selp.b32 	%r5, 18, %r13, %p2;
	setp.gt.s32 	%p3, %r4, %r5;
	mov.u64 	%rd75, 0;
	mov.u64 	%rd76, %rd1;
	@%p3 bra 	$L__BB1_4;

	add.s32 	%r6, %r4, -1;
	mov.b64 	%rd22, %fd4;
	shl.b64 	%rd23, %rd22, 11;
	or.b64  	%rd4, %rd23, -9223372036854775808;
	mov.u64 	%rd25, __cudart_i2opi_d;
	mov.u64 	%rd76, %rd1;
	mov.u32 	%r28, %r6;

$L__BB1_3:
	.pragma "nounroll";
	mul.wide.s32 	%rd24, %r28, 8;
	add.s64 	%rd26, %rd25, %rd24;
	ld.global.nc.u64 	%rd27, [%rd26];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd27;
	mov.b64 	{%blo,%bhi}, %rd4;
	mov.b64 	{%clo,%chi}, %rd75;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd28, {%r0,%r1};
	mov.b64 	%rd75, {%r2,%r3};
	}
	st.local.u64 	[%rd76], %rd28;
	add.s32 	%r28, %r28, 1;
	sub.s32 	%r14, %r28, %r6;
	mul.wide.s32 	%rd29, %r14, 8;
	add.s64 	%rd76, %rd1, %rd29;
	setp.lt.s32 	%p4, %r28, %r5;
	@%p4 bra 	$L__BB1_3;

$L__BB1_4:
	st.local.u64 	[%rd76], %rd75;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB1_6;

	mov.u32 	%r15, 64;
	sub.s32 	%r16, %r15, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r16;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r16;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB1_6:
	and.b32  	%r17, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r18, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r19, %rd39;
	and.b32  	%r20, %r19, 1;
	add.s32 	%r21, %r20, %r18;
	neg.s32 	%r22, %r21;
	setp.eq.s32 	%p6, %r17, 0;
	selp.b32 	%r23, %r21, %r22, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r23;
	setp.eq.s32 	%p7, %r20, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r24, %r17, -2147483648;
	selp.b32 	%r25, %r17, %r24, %p7;
	clz.b64 	%r26, %rd45;
	cvt.u64.u32 	%rd47, %r26;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r26;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r27, %rd50;
	shr.u64 	%rd51, %rd46, %r27;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r25;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB1_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}

