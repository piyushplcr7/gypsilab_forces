//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31057947
// Cuda compilation tools, release 11.6, V11.6.124
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .func  (.param .b64 func_retval0) malloc
(
	.param .b64 malloc_param_0
)
;
.extern .func free
(
	.param .b64 free_param_0
)
;
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.global .align 1 .b8 $str[24] = {78, 117, 109, 98, 101, 114, 32, 111, 102, 32, 98, 108, 111, 99, 107, 115, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$1[25] = {84, 104, 114, 101, 97, 100, 115, 32, 112, 101, 114, 32, 98, 108, 111, 99, 107, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$2[56] = {84, 111, 116, 97, 108, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 58, 32, 37, 100, 32, 44, 32, 73, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 32, 112, 101, 114, 32, 116, 104, 114, 101, 97, 100, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$3[54] = {73, 110, 32, 98, 108, 111, 99, 107, 32, 48, 32, 116, 104, 114, 101, 97, 100, 32, 48, 32, 99, 111, 109, 112, 117, 116, 105, 110, 103, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 32, 110, 111, 46, 32, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii(
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_0,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_1,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_2,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_3,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_4,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_5,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_6,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_7,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_8,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_9,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_10,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_11,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_12,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_13,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_14,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_15,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_16,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_17,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_18,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_19,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_20,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_21,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_22,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_23,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_24,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_25,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_26,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_27,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_28,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_29,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_30,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_31,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_32,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_33,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_34,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_35,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_36
)
{
	.local .align 8 .b8 	__local_depot0[272];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<185>;
	.reg .b32 	%r<519>;
	.reg .f64 	%fd<841>;
	.reg .b64 	%rd<370>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r199, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_4];
	ld.param.u32 	%r204, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_5];
	ld.param.u64 	%rd92, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_6];
	ld.param.u64 	%rd93, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_7];
	ld.param.u64 	%rd94, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_8];
	ld.param.u64 	%rd108, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_23];
	ld.param.u64 	%rd103, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_24];
	ld.param.u64 	%rd104, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_25];
	ld.param.u64 	%rd105, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_26];
	ld.param.u64 	%rd106, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_29];
	ld.param.u64 	%rd107, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_30];
	cvta.to.global.u64 	%rd1, %rd108;
	add.u64 	%rd109, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	add.u64 	%rd124, %SP, 8;
	add.u64 	%rd28, %SPL, 8;
	add.u64 	%rd17, %SPL, 16;
	add.u64 	%rd18, %SPL, 28;
	add.u64 	%rd19, %SPL, 40;
	add.u64 	%rd20, %SPL, 52;
	add.u64 	%rd21, %SPL, 64;
	add.u64 	%rd22, %SPL, 76;
	add.u64 	%rd23, %SPL, 88;
	add.u64 	%rd24, %SPL, 100;
	add.u64 	%rd25, %SPL, 112;
	add.u64 	%rd26, %SPL, 128;
	add.u64 	%rd27, %SPL, 200;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	cvt.rn.f64.s32 	%fd229, %r204;
	cvt.rn.f64.s32 	%fd230, %r199;
	div.rn.f64 	%fd231, %fd230, %fd229;
	cvt.rpi.f64.f64 	%fd232, %fd231;
	cvt.rzi.s32.f64 	%r4, %fd232;
	or.b32  	%r5, %r2, %r3;
	setp.ne.s32 	%p20, %r5, 0;
	@%p20 bra 	$L__BB0_2;

	mov.u32 	%r205, %nctaid.x;
	st.local.u32 	[%rd28], %r205;
	mov.u64 	%rd136, $str;
	cvta.global.u64 	%rd137, %rd136;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd137;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r206, [retval0+0];
	} // callseq 0
	st.local.u32 	[%rd28], %r1;
	mov.u64 	%rd139, $str$1;
	cvta.global.u64 	%rd140, %rd139;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd140;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r207, [retval0+0];
	} // callseq 1
	st.local.u32 	[%rd28], %r199;
	st.local.u32 	[%rd28+4], %r4;
	mov.u64 	%rd141, $str$2;
	cvta.global.u64 	%rd142, %rd141;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd142;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r208, [retval0+0];
	} // callseq 2

$L__BB0_2:
	setp.lt.s32 	%p21, %r4, 1;
	mad.lo.s32 	%r6, %r2, %r1, %r3;
	@%p21 bra 	$L__BB0_242;

	cvta.to.global.u64 	%rd29, %rd103;
	cvta.to.global.u64 	%rd30, %rd105;
	cvta.to.global.u64 	%rd31, %rd94;
	cvta.to.global.u64 	%rd32, %rd107;
	cvta.to.global.u64 	%rd33, %rd106;
	cvta.to.global.u64 	%rd34, %rd104;
	cvta.to.global.u64 	%rd35, %rd93;
	cvta.to.global.u64 	%rd36, %rd92;
	mul.lo.s32 	%r7, %r4, %r6;
	mov.u32 	%r8, 0;

$L__BB0_4:
	@%p20 bra 	$L__BB0_6;

	add.u64 	%rd356, %SP, 8;
	add.u64 	%rd355, %SP, 8;
	add.u64 	%rd354, %SPL, 8;
	st.local.u32 	[%rd354], %r8;
	mov.u64 	%rd143, $str$3;
	cvta.global.u64 	%rd144, %rd143;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd144;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd355;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r210, [retval0+0];
	} // callseq 3

$L__BB0_6:
	add.s32 	%r9, %r8, %r7;
	mov.u64 	%rd146, 0;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd146;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 4
	mov.u64 	%rd147, 48;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd38, [retval0+0];
	} // callseq 5
	setp.ne.s64 	%p23, %rd38, 0;
	@%p23 bra 	$L__BB0_8;

	mov.u64 	%rd148, -1;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd148;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd149, [retval0+0];
	} // callseq 6

$L__BB0_8:
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd146;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd39, [retval0+0];
	} // callseq 8
	setp.ne.s64 	%p24, %rd39, 0;
	@%p24 bra 	$L__BB0_10;

	mov.u64 	%rd152, -1;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd152;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd153, [retval0+0];
	} // callseq 9

$L__BB0_10:
	ld.param.u32 	%r422, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_4];
	setp.lt.s32 	%p25, %r9, %r422;
	@%p25 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	ld.param.u32 	%r484, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_11];
	ld.param.u64 	%rd360, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_10];
	ld.param.u64 	%rd359, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_9];
	mul.wide.s32 	%rd154, %r9, 4;
	add.s64 	%rd155, %rd36, %rd154;
	add.s64 	%rd156, %rd35, %rd154;
	ld.global.u32 	%r212, [%rd155];
	mul.lo.s32 	%r213, %r212, 3;
	ld.global.u32 	%r214, [%rd156];
	mul.lo.s32 	%r215, %r214, 3;
	mul.wide.s32 	%rd157, %r213, 4;
	add.s64 	%rd158, %rd34, %rd157;
	ld.global.u32 	%r10, [%rd158];
	ld.global.u32 	%r11, [%rd158+4];
	ld.global.u32 	%r12, [%rd158+8];
	mul.wide.s32 	%rd159, %r215, 4;
	add.s64 	%rd160, %rd34, %rd159;
	ld.global.u32 	%r483, [%rd160];
	ld.global.u32 	%r14, [%rd160+4];
	ld.global.u32 	%r15, [%rd160+8];
	st.local.u32 	[%rd20], %r10;
	st.local.u32 	[%rd20+4], %r11;
	st.local.u32 	[%rd20+8], %r12;
	st.local.u32 	[%rd21], %r483;
	st.local.u32 	[%rd21+4], %r14;
	st.local.u32 	[%rd21+8], %r15;
	add.s64 	%rd161, %rd33, %rd157;
	ld.global.u32 	%r216, [%rd161];
	st.local.u32 	[%rd22], %r216;
	ld.global.u32 	%r217, [%rd161+4];
	st.local.u32 	[%rd22+4], %r217;
	ld.global.u32 	%r218, [%rd161+8];
	st.local.u32 	[%rd22+8], %r218;
	add.s64 	%rd162, %rd32, %rd159;
	ld.global.u32 	%r219, [%rd162];
	st.local.u32 	[%rd23], %r219;
	ld.global.u32 	%r220, [%rd162+4];
	st.local.u32 	[%rd23+4], %r220;
	ld.global.u32 	%r221, [%rd162+8];
	st.local.u32 	[%rd23+8], %r221;
	mov.u32 	%r477, 0;
	st.local.u32 	[%rd24], %r477;
	mov.u32 	%r434, 1;
	st.local.u32 	[%rd24+4], %r434;
	mov.u32 	%r448, 2;
	st.local.u32 	[%rd24+8], %r448;
	st.local.u32 	[%rd25], %r477;
	st.local.u32 	[%rd25+4], %r434;
	st.local.u32 	[%rd25+8], %r448;
	add.s64 	%rd163, %rd31, %rd154;
	ld.global.u32 	%r16, [%rd163];
	setp.eq.s32 	%p26, %r16, 0;
	mov.u32 	%r478, %r12;
	mov.u32 	%r479, %r11;
	mov.u32 	%r480, %r10;
	mov.u32 	%r481, %r15;
	mov.u32 	%r482, %r14;
	@%p26 bra 	$L__BB0_83;

	setp.eq.s32 	%p27, %r16, 1;
	@%p27 bra 	$L__BB0_49;
	bra.uni 	$L__BB0_14;

$L__BB0_49:
	setp.eq.s32 	%p9, %r10, %r483;
	setp.eq.s32 	%p10, %r10, %r14;
	or.pred  	%p60, %p10, %p9;
	setp.eq.s32 	%p11, %r10, %r15;
	or.pred  	%p61, %p11, %p60;
	@%p61 bra 	$L__BB0_51;
	bra.uni 	$L__BB0_50;

$L__BB0_51:
	st.local.u32 	[%rd17], %r10;
	mov.u32 	%r456, 0;
	mov.u32 	%r458, 1;
	bra.uni 	$L__BB0_52;

$L__BB0_14:
	ld.param.u32 	%r484, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_20];
	ld.param.u64 	%rd360, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_19];
	ld.param.u64 	%rd359, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_18];
	setp.ne.s32 	%p28, %r16, 2;
	mov.u32 	%r478, %r12;
	mov.u32 	%r479, %r11;
	mov.u32 	%r480, %r10;
	mov.u32 	%r481, %r15;
	mov.u32 	%r482, %r14;
	@%p28 bra 	$L__BB0_83;

	setp.eq.s32 	%p1, %r10, %r483;
	setp.eq.s32 	%p2, %r10, %r14;
	or.pred  	%p29, %p2, %p1;
	setp.eq.s32 	%p3, %r10, %r15;
	or.pred  	%p30, %p3, %p29;
	@%p30 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_16;

$L__BB0_17:
	st.local.u32 	[%rd17], %r10;
	mov.u32 	%r434, 0;
	mov.u32 	%r436, 1;
	bra.uni 	$L__BB0_18;

$L__BB0_50:
	st.local.u32 	[%rd18], %r10;
	mov.u32 	%r456, 1;
	mov.u32 	%r458, 0;

$L__BB0_52:
	setp.eq.s32 	%p12, %r11, %r483;
	setp.eq.s32 	%p13, %r12, %r483;
	or.pred  	%p62, %p12, %p9;
	or.pred  	%p63, %p13, %p62;
	mov.u32 	%r460, 0;
	@%p63 bra 	$L__BB0_54;

	st.local.u32 	[%rd19], %r483;
	mov.u32 	%r460, 1;

$L__BB0_54:
	setp.eq.s32 	%p64, %r11, %r14;
	setp.eq.s32 	%p65, %r11, %r15;
	setp.eq.s32 	%p66, %r12, %r14;
	setp.eq.s32 	%p67, %r12, %r15;
	or.pred  	%p68, %p64, %p12;
	or.pred  	%p69, %p65, %p68;
	or.pred  	%p70, %p64, %p10;
	or.pred  	%p14, %p66, %p70;
	or.pred  	%p71, %p66, %p13;
	or.pred  	%p15, %p67, %p71;
	or.pred  	%p72, %p65, %p11;
	or.pred  	%p16, %p67, %p72;
	@%p69 bra 	$L__BB0_56;
	bra.uni 	$L__BB0_55;

$L__BB0_56:
	add.s32 	%r56, %r458, 1;
	mul.wide.u32 	%rd178, %r458, 4;
	add.s64 	%rd179, %rd17, %rd178;
	st.local.u32 	[%rd179], %r11;
	mov.u32 	%r458, %r56;
	mov.u32 	%r459, %r456;
	bra.uni 	$L__BB0_57;

$L__BB0_55:
	add.s32 	%r459, %r456, 1;
	mul.wide.u32 	%rd176, %r456, 4;
	add.s64 	%rd177, %rd18, %rd176;
	st.local.u32 	[%rd177], %r11;

$L__BB0_57:
	@%p14 bra 	$L__BB0_59;

	add.s32 	%r59, %r460, 1;
	mul.wide.u32 	%rd180, %r460, 4;
	add.s64 	%rd181, %rd19, %rd180;
	st.local.u32 	[%rd181], %r14;
	mov.u32 	%r460, %r59;

$L__BB0_59:
	@%p15 bra 	$L__BB0_61;
	bra.uni 	$L__BB0_60;

$L__BB0_61:
	mul.wide.u32 	%rd184, %r458, 4;
	add.s64 	%rd185, %rd17, %rd184;
	st.local.u32 	[%rd185], %r12;
	bra.uni 	$L__BB0_62;

$L__BB0_60:
	mul.wide.u32 	%rd182, %r459, 4;
	add.s64 	%rd183, %rd18, %rd182;
	st.local.u32 	[%rd183], %r12;

$L__BB0_62:
	@%p16 bra 	$L__BB0_64;

	mul.wide.u32 	%rd186, %r460, 4;
	add.s64 	%rd187, %rd19, %rd186;
	st.local.u32 	[%rd187], %r15;

$L__BB0_64:
	ld.local.u32 	%r480, [%rd17];
	ld.local.u32 	%r479, [%rd18];
	ld.local.u32 	%r482, [%rd19];
	ld.local.u32 	%r478, [%rd18+4];
	ld.local.u32 	%r481, [%rd19+4];
	setp.eq.s32 	%p73, %r10, %r480;
	mov.u32 	%r470, 2;
	mov.u32 	%r468, 1;
	mov.u32 	%r461, %r468;
	mov.u32 	%r467, %r470;
	@%p73 bra 	$L__BB0_67;

	setp.eq.s32 	%p74, %r10, %r479;
	mov.u32 	%r461, 0;
	@%p74 bra 	$L__BB0_67;

	setp.eq.s32 	%p75, %r10, %r478;
	selp.b32 	%r467, 0, 2, %p75;
	mov.u32 	%r461, %r468;

$L__BB0_67:
	setp.eq.s32 	%p76, %r483, %r480;
	mov.u32 	%r463, %r468;
	@%p76 bra 	$L__BB0_70;

	setp.eq.s32 	%p77, %r483, %r482;
	mov.u32 	%r463, 0;
	@%p77 bra 	$L__BB0_70;

	setp.eq.s32 	%p78, %r483, %r481;
	selp.b32 	%r470, 0, 2, %p78;
	mov.u32 	%r463, %r468;

$L__BB0_70:
	setp.eq.s32 	%p79, %r11, %r480;
	mov.u32 	%r465, %r468;
	mov.u32 	%r466, %r461;
	@%p79 bra 	$L__BB0_73;

	setp.eq.s32 	%p80, %r11, %r479;
	mov.u32 	%r466, 1;
	mov.u32 	%r465, 0;
	@%p80 bra 	$L__BB0_73;

	setp.eq.s32 	%p81, %r11, %r478;
	selp.b32 	%r467, 1, %r467, %p81;
	mov.u32 	%r466, %r461;

$L__BB0_73:
	setp.eq.s32 	%p82, %r14, %r480;
	mov.u32 	%r469, %r463;
	@%p82 bra 	$L__BB0_76;

	setp.eq.s32 	%p83, %r14, %r482;
	mov.u32 	%r469, 1;
	mov.u32 	%r468, 0;
	@%p83 bra 	$L__BB0_76;

	setp.eq.s32 	%p84, %r14, %r481;
	selp.b32 	%r470, 1, %r470, %p84;
	mov.u32 	%r469, %r463;

$L__BB0_76:
	setp.eq.s32 	%p85, %r12, %r480;
	mov.u32 	%r474, 2;
	mov.u32 	%r477, %r474;
	mov.u32 	%r472, %r466;
	@%p85 bra 	$L__BB0_79;

	setp.eq.s32 	%p86, %r12, %r479;
	mov.u32 	%r472, 2;
	mov.u32 	%r477, %r465;
	@%p86 bra 	$L__BB0_79;

	setp.eq.s32 	%p87, %r12, %r478;
	selp.b32 	%r467, 2, %r467, %p87;
	mov.u32 	%r477, %r465;
	mov.u32 	%r472, %r466;

$L__BB0_79:
	setp.eq.s32 	%p88, %r15, %r480;
	mov.u32 	%r475, %r469;
	@%p88 bra 	$L__BB0_82;

	setp.eq.s32 	%p89, %r15, %r482;
	mov.u32 	%r475, 2;
	mov.u32 	%r474, %r468;
	@%p89 bra 	$L__BB0_82;

	setp.eq.s32 	%p90, %r15, %r481;
	selp.b32 	%r470, 2, %r470, %p90;
	mov.u32 	%r474, %r468;
	mov.u32 	%r475, %r469;

$L__BB0_82:
	ld.param.u32 	%r484, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_14];
	ld.param.u64 	%rd360, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_13];
	ld.param.u64 	%rd359, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_12];
	st.local.u32 	[%rd24+8], %r467;
	st.local.u32 	[%rd24+4], %r472;
	st.local.u32 	[%rd24], %r477;
	st.local.u32 	[%rd25+8], %r470;
	st.local.u32 	[%rd25+4], %r475;
	st.local.u32 	[%rd25], %r474;
	mov.u32 	%r483, %r480;
	bra.uni 	$L__BB0_83;

$L__BB0_16:
	st.local.u32 	[%rd18], %r10;
	mov.u32 	%r436, 0;

$L__BB0_18:
	setp.eq.s32 	%p4, %r11, %r483;
	setp.eq.s32 	%p5, %r12, %r483;
	or.pred  	%p31, %p4, %p1;
	or.pred  	%p32, %p5, %p31;
	mov.u32 	%r438, 0;
	@%p32 bra 	$L__BB0_20;

	st.local.u32 	[%rd19], %r483;
	mov.u32 	%r438, 1;

$L__BB0_20:
	setp.eq.s32 	%p33, %r11, %r14;
	setp.eq.s32 	%p34, %r11, %r15;
	setp.eq.s32 	%p35, %r12, %r14;
	setp.eq.s32 	%p36, %r12, %r15;
	or.pred  	%p37, %p33, %p4;
	or.pred  	%p38, %p34, %p37;
	or.pred  	%p39, %p33, %p2;
	or.pred  	%p6, %p35, %p39;
	or.pred  	%p40, %p35, %p5;
	or.pred  	%p7, %p36, %p40;
	or.pred  	%p41, %p34, %p3;
	or.pred  	%p8, %p36, %p41;
	@%p38 bra 	$L__BB0_22;
	bra.uni 	$L__BB0_21;

$L__BB0_22:
	add.s32 	%r21, %r436, 1;
	mul.wide.u32 	%rd166, %r436, 4;
	add.s64 	%rd167, %rd17, %rd166;
	st.local.u32 	[%rd167], %r11;
	mov.u32 	%r436, %r21;
	mov.u32 	%r437, %r434;
	bra.uni 	$L__BB0_23;

$L__BB0_21:
	add.s32 	%r437, %r434, 1;
	mul.wide.u32 	%rd164, %r434, 4;
	add.s64 	%rd165, %rd18, %rd164;
	st.local.u32 	[%rd165], %r11;

$L__BB0_23:
	@%p6 bra 	$L__BB0_25;

	add.s32 	%r24, %r438, 1;
	mul.wide.u32 	%rd168, %r438, 4;
	add.s64 	%rd169, %rd19, %rd168;
	st.local.u32 	[%rd169], %r14;
	mov.u32 	%r438, %r24;

$L__BB0_25:
	@%p7 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	mul.wide.u32 	%rd172, %r436, 4;
	add.s64 	%rd173, %rd17, %rd172;
	st.local.u32 	[%rd173], %r12;
	bra.uni 	$L__BB0_28;

$L__BB0_26:
	mul.wide.u32 	%rd170, %r437, 4;
	add.s64 	%rd171, %rd18, %rd170;
	st.local.u32 	[%rd171], %r12;

$L__BB0_28:
	@%p8 bra 	$L__BB0_30;

	mul.wide.u32 	%rd174, %r438, 4;
	add.s64 	%rd175, %rd19, %rd174;
	st.local.u32 	[%rd175], %r15;

$L__BB0_30:
	ld.local.u32 	%r480, [%rd17];
	ld.local.u32 	%r479, [%rd17+4];
	ld.local.u32 	%r478, [%rd18];
	ld.local.u32 	%r481, [%rd19];
	setp.eq.s32 	%p42, %r10, %r480;
	mov.u32 	%r446, 1;
	mov.u32 	%r439, %r446;
	mov.u32 	%r445, %r448;
	@%p42 bra 	$L__BB0_33;

	setp.eq.s32 	%p43, %r10, %r479;
	mov.u32 	%r439, 0;
	mov.u32 	%r445, %r448;
	@%p43 bra 	$L__BB0_33;

	setp.eq.s32 	%p44, %r10, %r478;
	selp.b32 	%r445, 0, 2, %p44;
	mov.u32 	%r439, %r446;

$L__BB0_33:
	setp.eq.s32 	%p45, %r483, %r480;
	mov.u32 	%r441, %r446;
	@%p45 bra 	$L__BB0_36;

	setp.eq.s32 	%p46, %r483, %r479;
	mov.u32 	%r441, 0;
	@%p46 bra 	$L__BB0_36;

	setp.eq.s32 	%p47, %r483, %r481;
	selp.b32 	%r448, 0, 2, %p47;
	mov.u32 	%r441, %r446;

$L__BB0_36:
	setp.eq.s32 	%p48, %r11, %r480;
	mov.u32 	%r443, %r446;
	mov.u32 	%r444, %r439;
	@%p48 bra 	$L__BB0_39;

	setp.eq.s32 	%p49, %r11, %r479;
	mov.u32 	%r444, 1;
	mov.u32 	%r443, 0;
	@%p49 bra 	$L__BB0_39;

	setp.eq.s32 	%p50, %r11, %r478;
	selp.b32 	%r445, 1, %r445, %p50;
	mov.u32 	%r444, %r439;

$L__BB0_39:
	setp.eq.s32 	%p51, %r14, %r480;
	mov.u32 	%r447, %r441;
	@%p51 bra 	$L__BB0_42;

	setp.eq.s32 	%p52, %r14, %r479;
	mov.u32 	%r447, 1;
	mov.u32 	%r446, 0;
	@%p52 bra 	$L__BB0_42;

	setp.eq.s32 	%p53, %r14, %r481;
	selp.b32 	%r448, 1, %r448, %p53;
	mov.u32 	%r447, %r441;

$L__BB0_42:
	setp.eq.s32 	%p54, %r12, %r480;
	mov.u32 	%r452, 2;
	mov.u32 	%r477, %r452;
	mov.u32 	%r450, %r444;
	@%p54 bra 	$L__BB0_45;

	setp.eq.s32 	%p55, %r12, %r479;
	mov.u32 	%r450, 2;
	mov.u32 	%r477, %r443;
	@%p55 bra 	$L__BB0_45;

	setp.eq.s32 	%p56, %r12, %r478;
	selp.b32 	%r445, 2, %r445, %p56;
	mov.u32 	%r477, %r443;
	mov.u32 	%r450, %r444;

$L__BB0_45:
	setp.eq.s32 	%p57, %r15, %r480;
	mov.u32 	%r453, %r447;
	@%p57 bra 	$L__BB0_48;

	setp.eq.s32 	%p58, %r15, %r479;
	mov.u32 	%r453, 2;
	mov.u32 	%r452, %r446;
	@%p58 bra 	$L__BB0_48;

	setp.eq.s32 	%p59, %r15, %r481;
	selp.b32 	%r448, 2, %r448, %p59;
	mov.u32 	%r452, %r446;
	mov.u32 	%r453, %r447;

$L__BB0_48:
	ld.param.u32 	%r484, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_17];
	ld.param.u64 	%rd360, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_16];
	ld.param.u64 	%rd359, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiii_param_15];
	st.local.u32 	[%rd24+8], %r445;
	st.local.u32 	[%rd24+4], %r450;
	st.local.u32 	[%rd24], %r477;
	st.local.u32 	[%rd25+8], %r448;
	st.local.u32 	[%rd25+4], %r453;
	st.local.u32 	[%rd25], %r452;
	mov.u32 	%r482, %r479;
	mov.u32 	%r483, %r480;

$L__BB0_83:
	mul.lo.s32 	%r281, %r480, 3;
	mul.wide.s32 	%rd188, %r281, 8;
	add.s64 	%rd189, %rd30, %rd188;
	ld.global.f64 	%fd1, [%rd189+8];
	ld.global.f64 	%fd2, [%rd189+16];
	mul.lo.s32 	%r282, %r479, 3;
	mul.wide.s32 	%rd191, %r282, 8;
	add.s64 	%rd192, %rd30, %rd191;
	ld.global.f64 	%fd233, [%rd192+8];
	ld.global.f64 	%fd234, [%rd192+16];
	mul.lo.s32 	%r283, %r478, 3;
	mul.wide.s32 	%rd193, %r283, 8;
	add.s64 	%rd194, %rd30, %rd193;
	ld.global.f64 	%fd235, [%rd194];
	ld.global.f64 	%fd236, [%rd194+8];
	ld.global.f64 	%fd237, [%rd194+16];
	mul.lo.s32 	%r284, %r483, 3;
	mul.wide.s32 	%rd195, %r284, 8;
	add.s64 	%rd196, %rd30, %rd195;
	ld.global.f64 	%fd3, [%rd196];
	ld.global.f64 	%fd4, [%rd196+8];
	ld.global.f64 	%fd5, [%rd196+16];
	mul.lo.s32 	%r285, %r482, 3;
	mul.wide.s32 	%rd197, %r285, 8;
	add.s64 	%rd198, %rd30, %rd197;
	ld.global.f64 	%fd238, [%rd198];
	ld.global.f64 	%fd239, [%rd198+8];
	ld.global.f64 	%fd240, [%rd198+16];
	mul.lo.s32 	%r286, %r481, 3;
	mul.wide.s32 	%rd199, %r286, 8;
	add.s64 	%rd200, %rd30, %rd199;
	ld.global.f64 	%fd241, [%rd200];
	ld.global.f64 	%fd242, [%rd200+8];
	ld.global.f64 	%fd243, [%rd200+16];
	ld.global.f64 	%fd244, [%rd192];
	ld.global.f64 	%fd6, [%rd189];
	sub.f64 	%fd245, %fd244, %fd6;
	st.f64 	[%rd38], %fd245;
	sub.f64 	%fd246, %fd233, %fd1;
	st.f64 	[%rd38+8], %fd246;
	sub.f64 	%fd247, %fd234, %fd2;
	st.f64 	[%rd38+16], %fd247;
	sub.f64 	%fd248, %fd235, %fd6;
	st.f64 	[%rd38+24], %fd248;
	sub.f64 	%fd249, %fd236, %fd1;
	mov.u64 	%rd201, 32;
	st.f64 	[%rd38+32], %fd249;
	sub.f64 	%fd250, %fd237, %fd2;
	st.f64 	[%rd38+40], %fd250;
	sub.f64 	%fd251, %fd238, %fd3;
	st.f64 	[%rd39], %fd251;
	sub.f64 	%fd252, %fd239, %fd4;
	st.f64 	[%rd39+8], %fd252;
	sub.f64 	%fd253, %fd240, %fd5;
	st.f64 	[%rd39+16], %fd253;
	sub.f64 	%fd254, %fd241, %fd3;
	st.f64 	[%rd39+24], %fd254;
	sub.f64 	%fd255, %fd242, %fd4;
	st.f64 	[%rd39+32], %fd255;
	sub.f64 	%fd256, %fd243, %fd5;
	st.f64 	[%rd39+40], %fd256;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd146;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 12
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd49, [retval0+0];
	} // callseq 13
	setp.ne.s64 	%p91, %rd49, 0;
	@%p91 bra 	$L__BB0_85;

	mov.u64 	%rd202, -1;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd202;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd203, [retval0+0];
	} // callseq 14

$L__BB0_85:
	cvta.to.global.u64 	%rd51, %rd360;
	mov.u64 	%rd361, %rd146;

$L__BB0_86:
	shl.b64 	%rd53, %rd361, 1;
	mul.lo.s64 	%rd206, %rd361, 24;
	add.s64 	%rd54, %rd38, %rd206;
	mov.u64 	%rd362, %rd146;

$L__BB0_87:
	add.s64 	%rd207, %rd362, %rd53;
	shl.b64 	%rd208, %rd207, 3;
	add.s64 	%rd209, %rd49, %rd208;
	mul.lo.s64 	%rd210, %rd362, 24;
	add.s64 	%rd211, %rd38, %rd210;
	ld.f64 	%fd257, [%rd54];
	ld.f64 	%fd258, [%rd211];
	ld.f64 	%fd259, [%rd54+8];
	ld.f64 	%fd260, [%rd211+8];
	mul.f64 	%fd261, %fd260, %fd259;
	fma.rn.f64 	%fd262, %fd258, %fd257, %fd261;
	ld.f64 	%fd263, [%rd54+16];
	ld.f64 	%fd264, [%rd211+16];
	fma.rn.f64 	%fd265, %fd264, %fd263, %fd262;
	st.f64 	[%rd209], %fd265;
	add.s64 	%rd362, %rd362, 1;
	setp.lt.u64 	%p92, %rd362, 2;
	@%p92 bra 	$L__BB0_87;

	add.s64 	%rd361, %rd361, 1;
	setp.lt.u64 	%p93, %rd361, 2;
	@%p93 bra 	$L__BB0_86;

	mov.u64 	%rd212, 0;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd212;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 15
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd58, [retval0+0];
	} // callseq 16
	setp.ne.s64 	%p94, %rd58, 0;
	@%p94 bra 	$L__BB0_91;

	mov.u64 	%rd214, -1;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd214;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd215, [retval0+0];
	} // callseq 17

$L__BB0_91:
	mov.u64 	%rd363, %rd212;

$L__BB0_92:
	shl.b64 	%rd60, %rd363, 1;
	mul.lo.s64 	%rd218, %rd363, 24;
	add.s64 	%rd61, %rd39, %rd218;
	mov.u64 	%rd364, %rd212;

$L__BB0_93:
	add.s64 	%rd219, %rd364, %rd60;
	shl.b64 	%rd220, %rd219, 3;
	add.s64 	%rd221, %rd58, %rd220;
	mul.lo.s64 	%rd222, %rd364, 24;
	add.s64 	%rd223, %rd39, %rd222;
	ld.f64 	%fd266, [%rd61];
	ld.f64 	%fd267, [%rd223];
	ld.f64 	%fd268, [%rd61+8];
	ld.f64 	%fd269, [%rd223+8];
	mul.f64 	%fd270, %fd269, %fd268;
	fma.rn.f64 	%fd271, %fd267, %fd266, %fd270;
	ld.f64 	%fd272, [%rd61+16];
	ld.f64 	%fd273, [%rd223+16];
	fma.rn.f64 	%fd274, %fd273, %fd272, %fd271;
	st.f64 	[%rd221], %fd274;
	add.s64 	%rd364, %rd364, 1;
	setp.lt.u64 	%p95, %rd364, 2;
	@%p95 bra 	$L__BB0_93;

	add.s64 	%rd363, %rd363, 1;
	setp.lt.u64 	%p96, %rd363, 2;
	@%p96 bra 	$L__BB0_92;

	ld.f64 	%fd275, [%rd49+24];
	mov.u64 	%rd224, 0;
	ld.f64 	%fd276, [%rd49];
	mul.f64 	%fd277, %fd276, %fd275;
	ld.f64 	%fd278, [%rd49+8];
	ld.f64 	%fd279, [%rd49+16];
	mul.f64 	%fd280, %fd279, %fd278;
	sub.f64 	%fd7, %fd277, %fd280;
	ld.f64 	%fd281, [%rd58+24];
	ld.f64 	%fd282, [%rd58];
	mul.f64 	%fd283, %fd282, %fd281;
	ld.f64 	%fd284, [%rd58+8];
	ld.f64 	%fd285, [%rd58+16];
	mul.f64 	%fd286, %fd285, %fd284;
	sub.f64 	%fd8, %fd283, %fd286;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd224;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 18
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd67, [retval0+0];
	} // callseq 19
	setp.ne.s64 	%p97, %rd67, 0;
	@%p97 bra 	$L__BB0_97;

	mov.u64 	%rd226, -1;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd226;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd227, [retval0+0];
	} // callseq 20

$L__BB0_97:
	ld.f64 	%fd287, [%rd49];
	neg.f64 	%fd288, %fd287;
	st.f64 	[%rd67], %fd288;
	ld.f64 	%fd289, [%rd49+8];
	neg.f64 	%fd290, %fd289;
	st.f64 	[%rd67+8], %fd290;
	ld.f64 	%fd291, [%rd49+16];
	neg.f64 	%fd292, %fd291;
	st.f64 	[%rd67+16], %fd292;
	ld.f64 	%fd293, [%rd49+24];
	neg.f64 	%fd294, %fd293;
	st.f64 	[%rd67+24], %fd294;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd224;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 21
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd69, [retval0+0];
	} // callseq 22
	setp.ne.s64 	%p98, %rd69, 0;
	@%p98 bra 	$L__BB0_99;

	mov.u64 	%rd230, -1;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd230;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd231, [retval0+0];
	} // callseq 23

$L__BB0_99:
	ld.f64 	%fd295, [%rd58];
	neg.f64 	%fd296, %fd295;
	st.f64 	[%rd69], %fd296;
	ld.f64 	%fd297, [%rd58+8];
	neg.f64 	%fd298, %fd297;
	st.f64 	[%rd69+8], %fd298;
	ld.f64 	%fd299, [%rd58+16];
	neg.f64 	%fd300, %fd299;
	st.f64 	[%rd69+16], %fd300;
	ld.f64 	%fd301, [%rd58+24];
	neg.f64 	%fd302, %fd301;
	st.f64 	[%rd69+24], %fd302;
	ld.f64 	%fd303, [%rd49+24];
	st.f64 	[%rd67], %fd303;
	ld.f64 	%fd304, [%rd49];
	st.f64 	[%rd67+24], %fd304;
	ld.f64 	%fd305, [%rd58+24];
	st.f64 	[%rd69], %fd305;
	ld.f64 	%fd306, [%rd58];
	st.f64 	[%rd69+24], %fd306;
	ld.f64 	%fd307, [%rd67];
	div.rn.f64 	%fd308, %fd307, %fd7;
	st.f64 	[%rd67], %fd308;
	ld.f64 	%fd309, [%rd67+8];
	div.rn.f64 	%fd310, %fd309, %fd7;
	st.f64 	[%rd67+8], %fd310;
	ld.f64 	%fd311, [%rd67+16];
	div.rn.f64 	%fd312, %fd311, %fd7;
	st.f64 	[%rd67+16], %fd312;
	ld.f64 	%fd313, [%rd67+24];
	div.rn.f64 	%fd314, %fd313, %fd7;
	st.f64 	[%rd67+24], %fd314;
	ld.f64 	%fd315, [%rd69];
	div.rn.f64 	%fd316, %fd315, %fd8;
	st.f64 	[%rd69], %fd316;
	ld.f64 	%fd317, [%rd69+8];
	div.rn.f64 	%fd318, %fd317, %fd8;
	st.f64 	[%rd69+8], %fd318;
	ld.f64 	%fd319, [%rd69+16];
	div.rn.f64 	%fd320, %fd319, %fd8;
	st.f64 	[%rd69+16], %fd320;
	ld.f64 	%fd321, [%rd69+24];
	div.rn.f64 	%fd322, %fd321, %fd8;
	st.f64 	[%rd69+24], %fd322;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd224;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 24
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd70, [retval0+0];
	} // callseq 25
	setp.ne.s64 	%p99, %rd70, 0;
	@%p99 bra 	$L__BB0_101;

	mov.u64 	%rd234, -1;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd234;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd235, [retval0+0];
	} // callseq 26

$L__BB0_101:
	mov.u64 	%rd365, %rd224;

$L__BB0_102:
	mul.lo.s64 	%rd72, %rd365, 3;
	shl.b64 	%rd238, %rd365, 4;
	add.s64 	%rd73, %rd67, %rd238;
	mov.u64 	%rd366, %rd224;

$L__BB0_103:
	add.s64 	%rd239, %rd366, %rd72;
	shl.b64 	%rd240, %rd239, 3;
	add.s64 	%rd241, %rd70, %rd240;
	shl.b64 	%rd242, %rd366, 3;
	add.s64 	%rd243, %rd38, %rd242;
	ld.f64 	%fd323, [%rd73];
	ld.f64 	%fd324, [%rd243];
	ld.f64 	%fd325, [%rd73+8];
	ld.f64 	%fd326, [%rd243+24];
	mul.f64 	%fd327, %fd326, %fd325;
	fma.rn.f64 	%fd328, %fd324, %fd323, %fd327;
	st.f64 	[%rd241], %fd328;
	add.s64 	%rd366, %rd366, 1;
	setp.lt.u64 	%p100, %rd366, 3;
	@%p100 bra 	$L__BB0_103;

	add.s64 	%rd365, %rd365, 1;
	setp.lt.u64 	%p101, %rd365, 2;
	@%p101 bra 	$L__BB0_102;

	mov.u64 	%rd244, 0;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd244;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 27
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd77, [retval0+0];
	} // callseq 28
	setp.ne.s64 	%p102, %rd77, 0;
	@%p102 bra 	$L__BB0_107;

	mov.u64 	%rd246, -1;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd246;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd247, [retval0+0];
	} // callseq 29

$L__BB0_107:
	mov.u64 	%rd367, %rd244;

$L__BB0_108:
	mul.lo.s64 	%rd79, %rd367, 3;
	shl.b64 	%rd250, %rd367, 4;
	add.s64 	%rd80, %rd69, %rd250;
	mov.u64 	%rd368, %rd244;

$L__BB0_109:
	add.s64 	%rd251, %rd368, %rd79;
	shl.b64 	%rd252, %rd251, 3;
	add.s64 	%rd253, %rd77, %rd252;
	shl.b64 	%rd254, %rd368, 3;
	add.s64 	%rd255, %rd39, %rd254;
	ld.f64 	%fd329, [%rd80];
	ld.f64 	%fd330, [%rd255];
	ld.f64 	%fd331, [%rd80+8];
	ld.f64 	%fd332, [%rd255+24];
	mul.f64 	%fd333, %fd332, %fd331;
	fma.rn.f64 	%fd334, %fd330, %fd329, %fd333;
	st.f64 	[%rd253], %fd334;
	add.s64 	%rd368, %rd368, 1;
	setp.lt.u64 	%p103, %rd368, 3;
	@%p103 bra 	$L__BB0_109;

	add.s64 	%rd367, %rd367, 1;
	setp.lt.u64 	%p104, %rd367, 2;
	@%p104 bra 	$L__BB0_108;

	mov.u64 	%rd256, 0;
	st.local.u64 	[%rd26], %rd256;
	st.local.u64 	[%rd26+8], %rd256;
	st.local.u64 	[%rd26+16], %rd256;
	st.local.u64 	[%rd26+24], %rd256;
	st.local.u64 	[%rd26+32], %rd256;
	st.local.u64 	[%rd26+40], %rd256;
	st.local.u64 	[%rd26+48], %rd256;
	st.local.u64 	[%rd26+56], %rd256;
	st.local.u64 	[%rd26+64], %rd256;
	st.local.u64 	[%rd27], %rd256;
	st.local.u64 	[%rd27+8], %rd256;
	st.local.u64 	[%rd27+16], %rd256;
	st.local.u64 	[%rd27+24], %rd256;
	st.local.u64 	[%rd27+32], %rd256;
	st.local.u64 	[%rd27+40], %rd256;
	st.local.u64 	[%rd27+48], %rd256;
	st.local.u64 	[%rd27+56], %rd256;
	st.local.u64 	[%rd27+64], %rd256;
	mov.u32 	%r486, 0;
	bra.uni 	$L__BB0_112;

$L__BB0_243:
	add.s64 	%rd357, %rd24, 4;
	shl.b64 	%rd341, %rd84, 2;
	add.s64 	%rd342, %rd357, %rd341;
	ld.local.u32 	%r477, [%rd342];

$L__BB0_112:
	mov.u32 	%r487, 0;
	cvt.s64.s32 	%rd84, %r486;
	add.s32 	%r289, %r477, 1;
	mul.hi.s32 	%r290, %r289, 1431655766;
	shr.u32 	%r291, %r290, 31;
	add.s32 	%r292, %r290, %r291;
	mul.lo.s32 	%r293, %r292, 3;
	sub.s32 	%r294, %r289, %r293;
	add.s32 	%r295, %r294, 1;
	mul.hi.s32 	%r296, %r295, 1431655766;
	shr.u32 	%r297, %r296, 31;
	add.s32 	%r298, %r296, %r297;
	mul.lo.s32 	%r299, %r298, 3;
	sub.s32 	%r300, %r295, %r299;
	mul.wide.s32 	%rd257, %r294, 4;
	add.s64 	%rd258, %rd20, %rd257;
	mul.wide.s32 	%rd259, %r300, 4;
	add.s64 	%rd260, %rd20, %rd259;
	ld.local.u32 	%r301, [%rd260];
	ld.local.u32 	%r302, [%rd258];
	setp.lt.s32 	%p105, %r302, %r301;
	selp.f64 	%fd9, 0d3FF0000000000000, 0dBFF0000000000000, %p105;
	mul.wide.s32 	%rd261, %r477, 4;
	add.s64 	%rd85, %rd22, %rd261;

$L__BB0_113:
	mul.wide.s32 	%rd262, %r487, 4;
	add.s64 	%rd263, %rd25, %rd262;
	ld.local.u32 	%r99, [%rd263];
	mul.wide.s32 	%rd264, %r487, 3;
	add.s64 	%rd265, %rd264, %rd84;
	shl.b64 	%rd266, %rd265, 3;
	add.s64 	%rd86, %rd26, %rd266;
	add.s64 	%rd87, %rd27, %rd266;
	setp.gt.s32 	%p106, %r484, 0;
	@%p106 bra 	$L__BB0_115;
	bra.uni 	$L__BB0_114;

$L__BB0_115:
	add.s32 	%r306, %r99, 1;
	mul.hi.s32 	%r307, %r306, 1431655766;
	shr.u32 	%r308, %r307, 31;
	add.s32 	%r309, %r307, %r308;
	mul.lo.s32 	%r310, %r309, 3;
	sub.s32 	%r311, %r306, %r310;
	add.s32 	%r312, %r311, 1;
	mul.hi.s32 	%r313, %r312, 1431655766;
	shr.u32 	%r314, %r313, 31;
	add.s32 	%r315, %r313, %r314;
	mul.lo.s32 	%r316, %r315, 3;
	sub.s32 	%r317, %r312, %r316;
	mul.wide.s32 	%rd267, %r317, 4;
	add.s64 	%rd268, %rd21, %rd267;
	ld.local.u32 	%r318, [%rd268];
	mul.wide.s32 	%rd269, %r311, 4;
	add.s64 	%rd270, %rd21, %rd269;
	ld.local.u32 	%r319, [%rd270];
	setp.lt.s32 	%p107, %r319, %r318;
	selp.f64 	%fd14, 0d3FF0000000000000, 0dBFF0000000000000, %p107;
	mov.u32 	%r488, 0;

$L__BB0_116:
	cvta.to.global.u64 	%rd358, %rd359;
	shr.u32 	%r431, %r486, 1;
	cvt.rn.f64.s32 	%fd775, %r431;
	and.b32  	%r430, %r486, 1;
	cvt.rn.f64.s32 	%fd774, %r430;
	shr.u32 	%r429, %r487, 1;
	cvt.rn.f64.s32 	%fd773, %r429;
	and.b32  	%r428, %r487, 1;
	cvt.rn.f64.s32 	%fd772, %r428;
	shl.b32 	%r322, %r488, 2;
	mul.wide.s32 	%rd271, %r322, 8;
	add.s64 	%rd272, %rd51, %rd271;
	ld.global.f64 	%fd335, [%rd272];
	sub.f64 	%fd336, %fd335, %fd774;
	ld.global.f64 	%fd337, [%rd272+8];
	sub.f64 	%fd338, %fd337, %fd775;
	ld.global.f64 	%fd339, [%rd272+16];
	sub.f64 	%fd340, %fd339, %fd772;
	ld.global.f64 	%fd341, [%rd272+24];
	sub.f64 	%fd342, %fd341, %fd773;
	ld.f64 	%fd343, [%rd38];
	ld.f64 	%fd344, [%rd38+24];
	mul.f64 	%fd345, %fd338, %fd344;
	fma.rn.f64 	%fd346, %fd336, %fd343, %fd345;
	mul.f64 	%fd17, %fd9, %fd346;
	ld.f64 	%fd347, [%rd38+8];
	ld.f64 	%fd348, [%rd38+32];
	mul.f64 	%fd349, %fd338, %fd348;
	fma.rn.f64 	%fd350, %fd336, %fd347, %fd349;
	mul.f64 	%fd18, %fd9, %fd350;
	ld.f64 	%fd351, [%rd38+16];
	ld.f64 	%fd352, [%rd38+40];
	mul.f64 	%fd353, %fd338, %fd352;
	fma.rn.f64 	%fd354, %fd336, %fd351, %fd353;
	mul.f64 	%fd19, %fd9, %fd354;
	ld.f64 	%fd355, [%rd39];
	ld.f64 	%fd356, [%rd39+24];
	mul.f64 	%fd357, %fd342, %fd356;
	fma.rn.f64 	%fd358, %fd340, %fd355, %fd357;
	mul.f64 	%fd20, %fd14, %fd358;
	ld.f64 	%fd359, [%rd39+8];
	ld.f64 	%fd360, [%rd39+32];
	mul.f64 	%fd361, %fd342, %fd360;
	fma.rn.f64 	%fd362, %fd340, %fd359, %fd361;
	mul.f64 	%fd21, %fd14, %fd362;
	ld.f64 	%fd363, [%rd39+16];
	ld.f64 	%fd364, [%rd39+40];
	mul.f64 	%fd365, %fd342, %fd364;
	fma.rn.f64 	%fd366, %fd340, %fd363, %fd365;
	mul.f64 	%fd22, %fd14, %fd366;
	fma.rn.f64 	%fd367, %fd335, %fd343, %fd6;
	fma.rn.f64 	%fd23, %fd337, %fd344, %fd367;
	fma.rn.f64 	%fd368, %fd335, %fd347, %fd1;
	fma.rn.f64 	%fd24, %fd337, %fd348, %fd368;
	fma.rn.f64 	%fd369, %fd335, %fd351, %fd2;
	fma.rn.f64 	%fd25, %fd337, %fd352, %fd369;
	fma.rn.f64 	%fd370, %fd339, %fd355, %fd3;
	fma.rn.f64 	%fd827, %fd341, %fd356, %fd370;
	fma.rn.f64 	%fd371, %fd339, %fd359, %fd4;
	fma.rn.f64 	%fd831, %fd341, %fd360, %fd371;
	fma.rn.f64 	%fd372, %fd339, %fd363, %fd5;
	fma.rn.f64 	%fd835, %fd341, %fd364, %fd372;
	mul.wide.s32 	%rd273, %r488, 8;
	add.s64 	%rd88, %rd358, %rd273;
	ld.global.f64 	%fd29, [%rd88];
	sub.f64 	%fd30, %fd827, %fd23;
	sub.f64 	%fd31, %fd831, %fd24;
	sub.f64 	%fd32, %fd835, %fd25;
	mul.f64 	%fd373, %fd32, %fd32;
	fma.rn.f64 	%fd374, %fd31, %fd31, %fd373;
	fma.rn.f64 	%fd33, %fd30, %fd30, %fd374;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r323, %temp}, %fd23;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd23;
	}
	and.b32  	%r324, %r489, 2147483647;
	setp.ne.s32 	%p108, %r324, 2146435072;
	setp.ne.s32 	%p109, %r323, 0;
	or.pred  	%p110, %p109, %p108;
	mov.f64 	%fd779, %fd23;
	@%p110 bra 	$L__BB0_118;

	mov.f64 	%fd375, 0d0000000000000000;
	mul.rn.f64 	%fd779, %fd23, %fd375;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd779;
	}

$L__BB0_118:
	mul.f64 	%fd376, %fd779, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r490, %fd376;
	st.local.u32 	[%rd2], %r490;
	cvt.rn.f64.s32 	%fd377, %r490;
	neg.f64 	%fd378, %fd377;
	mov.f64 	%fd379, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd380, %fd378, %fd379, %fd779;
	mov.f64 	%fd381, 0d3C91A62633145C00;
	fma.rn.f64 	%fd382, %fd378, %fd381, %fd380;
	mov.f64 	%fd383, 0d397B839A252049C0;
	fma.rn.f64 	%fd780, %fd378, %fd383, %fd382;
	and.b32  	%r325, %r489, 2145386496;
	setp.lt.u32 	%p111, %r325, 1105199104;
	@%p111 bra 	$L__BB0_120;

	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd779;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd780, [retval0+0];
	} // callseq 30
	ld.local.u32 	%r490, [%rd2];

$L__BB0_120:
	add.s32 	%r107, %r490, 1;
	and.b32  	%r326, %r107, 1;
	shl.b32 	%r327, %r107, 3;
	and.b32  	%r328, %r327, 8;
	setp.eq.s32 	%p112, %r326, 0;
	selp.f64 	%fd384, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p112;
	mul.wide.s32 	%rd275, %r328, 8;
	mov.u64 	%rd276, __cudart_sin_cos_coeffs;
	add.s64 	%rd277, %rd276, %rd275;
	ld.global.nc.f64 	%fd385, [%rd277+8];
	mul.rn.f64 	%fd39, %fd780, %fd780;
	fma.rn.f64 	%fd386, %fd384, %fd39, %fd385;
	ld.global.nc.f64 	%fd387, [%rd277+16];
	fma.rn.f64 	%fd388, %fd386, %fd39, %fd387;
	ld.global.nc.f64 	%fd389, [%rd277+24];
	fma.rn.f64 	%fd390, %fd388, %fd39, %fd389;
	ld.global.nc.f64 	%fd391, [%rd277+32];
	fma.rn.f64 	%fd392, %fd390, %fd39, %fd391;
	ld.global.nc.f64 	%fd393, [%rd277+40];
	fma.rn.f64 	%fd394, %fd392, %fd39, %fd393;
	ld.global.nc.f64 	%fd395, [%rd277+48];
	fma.rn.f64 	%fd40, %fd394, %fd39, %fd395;
	fma.rn.f64 	%fd782, %fd40, %fd780, %fd780;
	@%p112 bra 	$L__BB0_122;

	mov.f64 	%fd396, 0d3FF0000000000000;
	fma.rn.f64 	%fd782, %fd40, %fd39, %fd396;

$L__BB0_122:
	and.b32  	%r329, %r107, 2;
	setp.eq.s32 	%p113, %r329, 0;
	@%p113 bra 	$L__BB0_124;

	mov.f64 	%fd397, 0d0000000000000000;
	mov.f64 	%fd398, 0dBFF0000000000000;
	fma.rn.f64 	%fd782, %fd782, %fd398, %fd397;

$L__BB0_124:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r491}, %fd24;
	}
	and.b32  	%r330, %r491, 2147483647;
	setp.ne.s32 	%p114, %r330, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r331, %temp}, %fd24;
	}
	setp.ne.s32 	%p115, %r331, 0;
	or.pred  	%p116, %p115, %p114;
	mov.f64 	%fd783, %fd24;
	@%p116 bra 	$L__BB0_126;

	mov.f64 	%fd399, 0d0000000000000000;
	mul.rn.f64 	%fd783, %fd24, %fd399;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r491}, %fd783;
	}

$L__BB0_126:
	mul.f64 	%fd400, %fd783, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r492, %fd400;
	st.local.u32 	[%rd2], %r492;
	cvt.rn.f64.s32 	%fd401, %r492;
	neg.f64 	%fd402, %fd401;
	fma.rn.f64 	%fd404, %fd402, %fd379, %fd783;
	fma.rn.f64 	%fd406, %fd402, %fd381, %fd404;
	fma.rn.f64 	%fd784, %fd402, %fd383, %fd406;
	and.b32  	%r332, %r491, 2145386496;
	setp.lt.u32 	%p117, %r332, 1105199104;
	@%p117 bra 	$L__BB0_128;

	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd783;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd784, [retval0+0];
	} // callseq 31
	ld.local.u32 	%r492, [%rd2];

$L__BB0_128:
	add.s32 	%r114, %r492, 1;
	and.b32  	%r333, %r114, 1;
	shl.b32 	%r334, %r114, 3;
	and.b32  	%r335, %r334, 8;
	setp.eq.s32 	%p118, %r333, 0;
	selp.f64 	%fd408, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd279, %r335, 8;
	add.s64 	%rd281, %rd276, %rd279;
	ld.global.nc.f64 	%fd409, [%rd281+8];
	mul.rn.f64 	%fd51, %fd784, %fd784;
	fma.rn.f64 	%fd410, %fd408, %fd51, %fd409;
	ld.global.nc.f64 	%fd411, [%rd281+16];
	fma.rn.f64 	%fd412, %fd410, %fd51, %fd411;
	ld.global.nc.f64 	%fd413, [%rd281+24];
	fma.rn.f64 	%fd414, %fd412, %fd51, %fd413;
	ld.global.nc.f64 	%fd415, [%rd281+32];
	fma.rn.f64 	%fd416, %fd414, %fd51, %fd415;
	ld.global.nc.f64 	%fd417, [%rd281+40];
	fma.rn.f64 	%fd418, %fd416, %fd51, %fd417;
	ld.global.nc.f64 	%fd419, [%rd281+48];
	fma.rn.f64 	%fd52, %fd418, %fd51, %fd419;
	fma.rn.f64 	%fd786, %fd52, %fd784, %fd784;
	@%p118 bra 	$L__BB0_130;

	mov.f64 	%fd420, 0d3FF0000000000000;
	fma.rn.f64 	%fd786, %fd52, %fd51, %fd420;

$L__BB0_130:
	and.b32  	%r336, %r114, 2;
	setp.eq.s32 	%p119, %r336, 0;
	@%p119 bra 	$L__BB0_132;

	mov.f64 	%fd421, 0d0000000000000000;
	mov.f64 	%fd422, 0dBFF0000000000000;
	fma.rn.f64 	%fd786, %fd786, %fd422, %fd421;

$L__BB0_132:
	sqrt.rn.f64 	%fd58, %fd33;
	mul.f64 	%fd59, %fd782, %fd786;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r493}, %fd25;
	}
	and.b32  	%r337, %r493, 2147483647;
	setp.ne.s32 	%p120, %r337, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd25;
	}
	setp.ne.s32 	%p121, %r338, 0;
	or.pred  	%p122, %p121, %p120;
	mov.f64 	%fd787, %fd25;
	@%p122 bra 	$L__BB0_134;

	mov.f64 	%fd423, 0d0000000000000000;
	mul.rn.f64 	%fd787, %fd25, %fd423;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r493}, %fd787;
	}

$L__BB0_134:
	mul.f64 	%fd424, %fd787, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r494, %fd424;
	st.local.u32 	[%rd2], %r494;
	cvt.rn.f64.s32 	%fd425, %r494;
	neg.f64 	%fd426, %fd425;
	fma.rn.f64 	%fd428, %fd426, %fd379, %fd787;
	fma.rn.f64 	%fd430, %fd426, %fd381, %fd428;
	fma.rn.f64 	%fd788, %fd426, %fd383, %fd430;
	and.b32  	%r339, %r493, 2145386496;
	setp.lt.u32 	%p123, %r339, 1105199104;
	@%p123 bra 	$L__BB0_136;

	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd787;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd788, [retval0+0];
	} // callseq 32
	ld.local.u32 	%r494, [%rd2];

$L__BB0_136:
	add.s32 	%r121, %r494, 1;
	and.b32  	%r340, %r121, 1;
	shl.b32 	%r341, %r121, 3;
	and.b32  	%r342, %r341, 8;
	setp.eq.s32 	%p124, %r340, 0;
	selp.f64 	%fd432, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p124;
	mul.wide.s32 	%rd283, %r342, 8;
	add.s64 	%rd285, %rd276, %rd283;
	ld.global.nc.f64 	%fd433, [%rd285+8];
	mul.rn.f64 	%fd65, %fd788, %fd788;
	fma.rn.f64 	%fd434, %fd432, %fd65, %fd433;
	ld.global.nc.f64 	%fd435, [%rd285+16];
	fma.rn.f64 	%fd436, %fd434, %fd65, %fd435;
	ld.global.nc.f64 	%fd437, [%rd285+24];
	fma.rn.f64 	%fd438, %fd436, %fd65, %fd437;
	ld.global.nc.f64 	%fd439, [%rd285+32];
	fma.rn.f64 	%fd440, %fd438, %fd65, %fd439;
	ld.global.nc.f64 	%fd441, [%rd285+40];
	fma.rn.f64 	%fd442, %fd440, %fd65, %fd441;
	ld.global.nc.f64 	%fd443, [%rd285+48];
	fma.rn.f64 	%fd66, %fd442, %fd65, %fd443;
	fma.rn.f64 	%fd790, %fd66, %fd788, %fd788;
	@%p124 bra 	$L__BB0_138;

	mov.f64 	%fd444, 0d3FF0000000000000;
	fma.rn.f64 	%fd790, %fd66, %fd65, %fd444;

$L__BB0_138:
	and.b32  	%r343, %r121, 2;
	setp.eq.s32 	%p125, %r343, 0;
	@%p125 bra 	$L__BB0_140;

	mov.f64 	%fd445, 0d0000000000000000;
	mov.f64 	%fd446, 0dBFF0000000000000;
	fma.rn.f64 	%fd790, %fd790, %fd446, %fd445;

$L__BB0_140:
	mul.f64 	%fd72, %fd59, %fd790;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r495}, %fd827;
	}
	and.b32  	%r344, %r495, 2147483647;
	setp.eq.s32 	%p126, %r344, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd827;
	}
	setp.eq.s32 	%p127, %r345, 0;
	and.pred  	%p17, %p127, %p126;
	not.pred 	%p128, %p17;
	mov.f64 	%fd791, %fd827;
	@%p128 bra 	$L__BB0_142;

	mov.f64 	%fd447, 0d0000000000000000;
	mul.rn.f64 	%fd791, %fd827, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r495}, %fd791;
	}

$L__BB0_142:
	mul.f64 	%fd448, %fd791, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r496, %fd448;
	st.local.u32 	[%rd2], %r496;
	cvt.rn.f64.s32 	%fd449, %r496;
	neg.f64 	%fd450, %fd449;
	fma.rn.f64 	%fd452, %fd450, %fd379, %fd791;
	fma.rn.f64 	%fd454, %fd450, %fd381, %fd452;
	fma.rn.f64 	%fd792, %fd450, %fd383, %fd454;
	and.b32  	%r346, %r495, 2145386496;
	setp.lt.u32 	%p129, %r346, 1105199104;
	@%p129 bra 	$L__BB0_144;

	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd791;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd792, [retval0+0];
	} // callseq 33
	ld.local.u32 	%r496, [%rd2];

$L__BB0_144:
	add.s32 	%r128, %r496, 1;
	and.b32  	%r347, %r128, 1;
	shl.b32 	%r348, %r128, 3;
	and.b32  	%r349, %r348, 8;
	setp.eq.s32 	%p130, %r347, 0;
	selp.f64 	%fd456, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p130;
	mul.wide.s32 	%rd287, %r349, 8;
	add.s64 	%rd289, %rd276, %rd287;
	ld.global.nc.f64 	%fd457, [%rd289+8];
	mul.rn.f64 	%fd78, %fd792, %fd792;
	fma.rn.f64 	%fd458, %fd456, %fd78, %fd457;
	ld.global.nc.f64 	%fd459, [%rd289+16];
	fma.rn.f64 	%fd460, %fd458, %fd78, %fd459;
	ld.global.nc.f64 	%fd461, [%rd289+24];
	fma.rn.f64 	%fd462, %fd460, %fd78, %fd461;
	ld.global.nc.f64 	%fd463, [%rd289+32];
	fma.rn.f64 	%fd464, %fd462, %fd78, %fd463;
	ld.global.nc.f64 	%fd465, [%rd289+40];
	fma.rn.f64 	%fd466, %fd464, %fd78, %fd465;
	ld.global.nc.f64 	%fd467, [%rd289+48];
	fma.rn.f64 	%fd79, %fd466, %fd78, %fd467;
	fma.rn.f64 	%fd794, %fd79, %fd792, %fd792;
	@%p130 bra 	$L__BB0_146;

	mov.f64 	%fd468, 0d3FF0000000000000;
	fma.rn.f64 	%fd794, %fd79, %fd78, %fd468;

$L__BB0_146:
	and.b32  	%r350, %r128, 2;
	setp.eq.s32 	%p131, %r350, 0;
	@%p131 bra 	$L__BB0_148;

	mov.f64 	%fd469, 0d0000000000000000;
	mov.f64 	%fd470, 0dBFF0000000000000;
	fma.rn.f64 	%fd794, %fd794, %fd470, %fd469;

$L__BB0_148:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r497}, %fd831;
	}
	and.b32  	%r351, %r497, 2147483647;
	setp.eq.s32 	%p132, %r351, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r352, %temp}, %fd831;
	}
	setp.eq.s32 	%p133, %r352, 0;
	and.pred  	%p18, %p133, %p132;
	not.pred 	%p134, %p18;
	mov.f64 	%fd795, %fd831;
	@%p134 bra 	$L__BB0_150;

	mov.f64 	%fd471, 0d0000000000000000;
	mul.rn.f64 	%fd795, %fd831, %fd471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r497}, %fd795;
	}

$L__BB0_150:
	mul.f64 	%fd472, %fd795, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r498, %fd472;
	st.local.u32 	[%rd2], %r498;
	cvt.rn.f64.s32 	%fd473, %r498;
	neg.f64 	%fd474, %fd473;
	fma.rn.f64 	%fd476, %fd474, %fd379, %fd795;
	fma.rn.f64 	%fd478, %fd474, %fd381, %fd476;
	fma.rn.f64 	%fd796, %fd474, %fd383, %fd478;
	and.b32  	%r353, %r497, 2145386496;
	setp.lt.u32 	%p135, %r353, 1105199104;
	@%p135 bra 	$L__BB0_152;

	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd795;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd796, [retval0+0];
	} // callseq 34
	ld.local.u32 	%r498, [%rd2];

$L__BB0_152:
	add.s32 	%r135, %r498, 1;
	and.b32  	%r354, %r135, 1;
	shl.b32 	%r355, %r135, 3;
	and.b32  	%r356, %r355, 8;
	setp.eq.s32 	%p136, %r354, 0;
	selp.f64 	%fd480, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd291, %r356, 8;
	add.s64 	%rd293, %rd276, %rd291;
	ld.global.nc.f64 	%fd481, [%rd293+8];
	mul.rn.f64 	%fd90, %fd796, %fd796;
	fma.rn.f64 	%fd482, %fd480, %fd90, %fd481;
	ld.global.nc.f64 	%fd483, [%rd293+16];
	fma.rn.f64 	%fd484, %fd482, %fd90, %fd483;
	ld.global.nc.f64 	%fd485, [%rd293+24];
	fma.rn.f64 	%fd486, %fd484, %fd90, %fd485;
	ld.global.nc.f64 	%fd487, [%rd293+32];
	fma.rn.f64 	%fd488, %fd486, %fd90, %fd487;
	ld.global.nc.f64 	%fd489, [%rd293+40];
	fma.rn.f64 	%fd490, %fd488, %fd90, %fd489;
	ld.global.nc.f64 	%fd491, [%rd293+48];
	fma.rn.f64 	%fd91, %fd490, %fd90, %fd491;
	fma.rn.f64 	%fd798, %fd91, %fd796, %fd796;
	@%p136 bra 	$L__BB0_154;

	mov.f64 	%fd492, 0d3FF0000000000000;
	fma.rn.f64 	%fd798, %fd91, %fd90, %fd492;

$L__BB0_154:
	and.b32  	%r357, %r135, 2;
	setp.eq.s32 	%p137, %r357, 0;
	@%p137 bra 	$L__BB0_156;

	mov.f64 	%fd493, 0d0000000000000000;
	mov.f64 	%fd494, 0dBFF0000000000000;
	fma.rn.f64 	%fd798, %fd798, %fd494, %fd493;

$L__BB0_156:
	mul.f64 	%fd97, %fd794, %fd798;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r499}, %fd835;
	}
	and.b32  	%r358, %r499, 2147483647;
	setp.eq.s32 	%p138, %r358, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd835;
	}
	setp.eq.s32 	%p139, %r359, 0;
	and.pred  	%p19, %p139, %p138;
	not.pred 	%p140, %p19;
	mov.f64 	%fd799, %fd835;
	@%p140 bra 	$L__BB0_158;

	mov.f64 	%fd495, 0d0000000000000000;
	mul.rn.f64 	%fd799, %fd835, %fd495;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r499}, %fd799;
	}

$L__BB0_158:
	mul.f64 	%fd496, %fd799, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r500, %fd496;
	st.local.u32 	[%rd2], %r500;
	cvt.rn.f64.s32 	%fd497, %r500;
	neg.f64 	%fd498, %fd497;
	fma.rn.f64 	%fd500, %fd498, %fd379, %fd799;
	fma.rn.f64 	%fd502, %fd498, %fd381, %fd500;
	fma.rn.f64 	%fd800, %fd498, %fd383, %fd502;
	and.b32  	%r360, %r499, 2145386496;
	setp.lt.u32 	%p141, %r360, 1105199104;
	@%p141 bra 	$L__BB0_160;

	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd799;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd800, [retval0+0];
	} // callseq 35
	ld.local.u32 	%r500, [%rd2];

$L__BB0_160:
	add.s32 	%r142, %r500, 1;
	and.b32  	%r361, %r142, 1;
	shl.b32 	%r362, %r142, 3;
	and.b32  	%r363, %r362, 8;
	setp.eq.s32 	%p142, %r361, 0;
	selp.f64 	%fd504, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd295, %r363, 8;
	add.s64 	%rd297, %rd276, %rd295;
	ld.global.nc.f64 	%fd505, [%rd297+8];
	mul.rn.f64 	%fd103, %fd800, %fd800;
	fma.rn.f64 	%fd506, %fd504, %fd103, %fd505;
	ld.global.nc.f64 	%fd507, [%rd297+16];
	fma.rn.f64 	%fd508, %fd506, %fd103, %fd507;
	ld.global.nc.f64 	%fd509, [%rd297+24];
	fma.rn.f64 	%fd510, %fd508, %fd103, %fd509;
	ld.global.nc.f64 	%fd511, [%rd297+32];
	fma.rn.f64 	%fd512, %fd510, %fd103, %fd511;
	ld.global.nc.f64 	%fd513, [%rd297+40];
	fma.rn.f64 	%fd514, %fd512, %fd103, %fd513;
	ld.global.nc.f64 	%fd515, [%rd297+48];
	fma.rn.f64 	%fd104, %fd514, %fd103, %fd515;
	fma.rn.f64 	%fd802, %fd104, %fd800, %fd800;
	@%p142 bra 	$L__BB0_162;

	mov.f64 	%fd516, 0d3FF0000000000000;
	fma.rn.f64 	%fd802, %fd104, %fd103, %fd516;

$L__BB0_162:
	and.b32  	%r364, %r142, 2;
	setp.eq.s32 	%p143, %r364, 0;
	@%p143 bra 	$L__BB0_164;

	mov.f64 	%fd517, 0d0000000000000000;
	mov.f64 	%fd518, 0dBFF0000000000000;
	fma.rn.f64 	%fd802, %fd802, %fd518, %fd517;

$L__BB0_164:
	sub.f64 	%fd778, %fd827, %fd23;
	sub.f64 	%fd777, %fd831, %fd24;
	sub.f64 	%fd776, %fd835, %fd25;
	mul.wide.s32 	%rd345, %r488, 8;
	cvta.to.global.u64 	%rd344, %rd359;
	add.s64 	%rd343, %rd344, %rd345;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r501}, %fd827;
	}
	mul.f64 	%fd519, %fd97, %fd802;
	sub.f64 	%fd520, %fd72, %fd519;
	mul.f64 	%fd521, %fd776, 0d0000000000000000;
	fma.rn.f64 	%fd522, %fd777, 0d0000000000000000, %fd521;
	fma.rn.f64 	%fd523, %fd778, %fd520, %fd522;
	div.rn.f64 	%fd524, %fd523, 0d402921FB54442D18;
	mul.f64 	%fd525, %fd58, %fd58;
	mul.f64 	%fd526, %fd58, %fd525;
	div.rn.f64 	%fd527, %fd524, %fd526;
	mul.f64 	%fd528, %fd29, %fd527;
	mul.f64 	%fd529, %fd22, %fd19;
	fma.rn.f64 	%fd530, %fd21, %fd18, %fd529;
	fma.rn.f64 	%fd531, %fd20, %fd17, %fd530;
	ld.local.f64 	%fd532, [%rd86];
	fma.rn.f64 	%fd840, %fd528, %fd531, %fd532;
	st.local.f64 	[%rd86], %fd840;
	mov.f64 	%fd533, 0d3FB45F306DC9C883;
	div.rn.f64 	%fd534, %fd533, %fd58;
	ld.global.f64 	%fd535, [%rd343];
	mul.f64 	%fd111, %fd535, %fd534;
	mov.f64 	%fd803, %fd827;
	@%p128 bra 	$L__BB0_166;

	mov.f64 	%fd536, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd827, %fd536;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r501}, %fd803;
	}

$L__BB0_166:
	mul.f64 	%fd537, %fd803, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r502, %fd537;
	st.local.u32 	[%rd2], %r502;
	cvt.rn.f64.s32 	%fd538, %r502;
	neg.f64 	%fd539, %fd538;
	fma.rn.f64 	%fd541, %fd539, %fd379, %fd803;
	fma.rn.f64 	%fd543, %fd539, %fd381, %fd541;
	fma.rn.f64 	%fd804, %fd539, %fd383, %fd543;
	and.b32  	%r365, %r501, 2145386496;
	setp.lt.u32 	%p145, %r365, 1105199104;
	@%p145 bra 	$L__BB0_168;

	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd803;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd804, [retval0+0];
	} // callseq 36
	ld.local.u32 	%r502, [%rd2];

$L__BB0_168:
	and.b32  	%r366, %r502, 1;
	shl.b32 	%r367, %r502, 3;
	and.b32  	%r368, %r367, 8;
	setp.eq.s32 	%p146, %r366, 0;
	selp.f64 	%fd545, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p146;
	mul.wide.s32 	%rd299, %r368, 8;
	add.s64 	%rd301, %rd276, %rd299;
	ld.global.nc.f64 	%fd546, [%rd301+8];
	mul.rn.f64 	%fd117, %fd804, %fd804;
	fma.rn.f64 	%fd547, %fd545, %fd117, %fd546;
	ld.global.nc.f64 	%fd548, [%rd301+16];
	fma.rn.f64 	%fd549, %fd547, %fd117, %fd548;
	ld.global.nc.f64 	%fd550, [%rd301+24];
	fma.rn.f64 	%fd551, %fd549, %fd117, %fd550;
	ld.global.nc.f64 	%fd552, [%rd301+32];
	fma.rn.f64 	%fd553, %fd551, %fd117, %fd552;
	ld.global.nc.f64 	%fd554, [%rd301+40];
	fma.rn.f64 	%fd555, %fd553, %fd117, %fd554;
	ld.global.nc.f64 	%fd556, [%rd301+48];
	fma.rn.f64 	%fd118, %fd555, %fd117, %fd556;
	fma.rn.f64 	%fd806, %fd118, %fd804, %fd804;
	@%p146 bra 	$L__BB0_170;

	mov.f64 	%fd557, 0d3FF0000000000000;
	fma.rn.f64 	%fd806, %fd118, %fd117, %fd557;

$L__BB0_170:
	and.b32  	%r369, %r502, 2;
	setp.eq.s32 	%p147, %r369, 0;
	@%p147 bra 	$L__BB0_172;

	mov.f64 	%fd558, 0d0000000000000000;
	mov.f64 	%fd559, 0dBFF0000000000000;
	fma.rn.f64 	%fd806, %fd806, %fd559, %fd558;

$L__BB0_172:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r503}, %fd831;
	}
	mov.f64 	%fd807, %fd831;
	@%p134 bra 	$L__BB0_174;

	mov.f64 	%fd560, 0d0000000000000000;
	mul.rn.f64 	%fd807, %fd831, %fd560;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r503}, %fd807;
	}

$L__BB0_174:
	mul.f64 	%fd561, %fd807, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r504, %fd561;
	st.local.u32 	[%rd2], %r504;
	cvt.rn.f64.s32 	%fd562, %r504;
	neg.f64 	%fd563, %fd562;
	fma.rn.f64 	%fd565, %fd563, %fd379, %fd807;
	fma.rn.f64 	%fd567, %fd563, %fd381, %fd565;
	fma.rn.f64 	%fd808, %fd563, %fd383, %fd567;
	and.b32  	%r370, %r503, 2145386496;
	setp.lt.u32 	%p149, %r370, 1105199104;
	@%p149 bra 	$L__BB0_176;

	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd807;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 37
	ld.local.u32 	%r504, [%rd2];

$L__BB0_176:
	add.s32 	%r153, %r504, 1;
	and.b32  	%r371, %r153, 1;
	shl.b32 	%r372, %r153, 3;
	and.b32  	%r373, %r372, 8;
	setp.eq.s32 	%p150, %r371, 0;
	selp.f64 	%fd569, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p150;
	mul.wide.s32 	%rd303, %r373, 8;
	add.s64 	%rd305, %rd276, %rd303;
	ld.global.nc.f64 	%fd570, [%rd305+8];
	mul.rn.f64 	%fd129, %fd808, %fd808;
	fma.rn.f64 	%fd571, %fd569, %fd129, %fd570;
	ld.global.nc.f64 	%fd572, [%rd305+16];
	fma.rn.f64 	%fd573, %fd571, %fd129, %fd572;
	ld.global.nc.f64 	%fd574, [%rd305+24];
	fma.rn.f64 	%fd575, %fd573, %fd129, %fd574;
	ld.global.nc.f64 	%fd576, [%rd305+32];
	fma.rn.f64 	%fd577, %fd575, %fd129, %fd576;
	ld.global.nc.f64 	%fd578, [%rd305+40];
	fma.rn.f64 	%fd579, %fd577, %fd129, %fd578;
	ld.global.nc.f64 	%fd580, [%rd305+48];
	fma.rn.f64 	%fd130, %fd579, %fd129, %fd580;
	fma.rn.f64 	%fd810, %fd130, %fd808, %fd808;
	@%p150 bra 	$L__BB0_178;

	mov.f64 	%fd581, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd130, %fd129, %fd581;

$L__BB0_178:
	and.b32  	%r374, %r153, 2;
	setp.eq.s32 	%p151, %r374, 0;
	@%p151 bra 	$L__BB0_180;

	mov.f64 	%fd582, 0d0000000000000000;
	mov.f64 	%fd583, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd583, %fd582;

$L__BB0_180:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r505}, %fd835;
	}
	mul.f64 	%fd136, %fd806, %fd810;
	mov.f64 	%fd811, %fd835;
	@%p140 bra 	$L__BB0_182;

	mov.f64 	%fd584, 0d0000000000000000;
	mul.rn.f64 	%fd811, %fd835, %fd584;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r505}, %fd811;
	}

$L__BB0_182:
	mul.f64 	%fd585, %fd811, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r506, %fd585;
	st.local.u32 	[%rd2], %r506;
	cvt.rn.f64.s32 	%fd586, %r506;
	neg.f64 	%fd587, %fd586;
	fma.rn.f64 	%fd589, %fd587, %fd379, %fd811;
	fma.rn.f64 	%fd591, %fd587, %fd381, %fd589;
	fma.rn.f64 	%fd812, %fd587, %fd383, %fd591;
	and.b32  	%r375, %r505, 2145386496;
	setp.lt.u32 	%p153, %r375, 1105199104;
	@%p153 bra 	$L__BB0_184;

	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd811;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 38
	ld.local.u32 	%r506, [%rd2];

$L__BB0_184:
	add.s32 	%r159, %r506, 1;
	and.b32  	%r376, %r159, 1;
	shl.b32 	%r377, %r159, 3;
	and.b32  	%r378, %r377, 8;
	setp.eq.s32 	%p154, %r376, 0;
	selp.f64 	%fd593, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p154;
	mul.wide.s32 	%rd307, %r378, 8;
	add.s64 	%rd309, %rd276, %rd307;
	ld.global.nc.f64 	%fd594, [%rd309+8];
	mul.rn.f64 	%fd142, %fd812, %fd812;
	fma.rn.f64 	%fd595, %fd593, %fd142, %fd594;
	ld.global.nc.f64 	%fd596, [%rd309+16];
	fma.rn.f64 	%fd597, %fd595, %fd142, %fd596;
	ld.global.nc.f64 	%fd598, [%rd309+24];
	fma.rn.f64 	%fd599, %fd597, %fd142, %fd598;
	ld.global.nc.f64 	%fd600, [%rd309+32];
	fma.rn.f64 	%fd601, %fd599, %fd142, %fd600;
	ld.global.nc.f64 	%fd602, [%rd309+40];
	fma.rn.f64 	%fd603, %fd601, %fd142, %fd602;
	ld.global.nc.f64 	%fd604, [%rd309+48];
	fma.rn.f64 	%fd143, %fd603, %fd142, %fd604;
	fma.rn.f64 	%fd814, %fd143, %fd812, %fd812;
	@%p154 bra 	$L__BB0_186;

	mov.f64 	%fd605, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd143, %fd142, %fd605;

$L__BB0_186:
	and.b32  	%r379, %r159, 2;
	setp.eq.s32 	%p155, %r379, 0;
	@%p155 bra 	$L__BB0_188;

	mov.f64 	%fd606, 0d0000000000000000;
	mov.f64 	%fd607, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd607, %fd606;

$L__BB0_188:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r507}, %fd827;
	}
	mul.f64 	%fd149, %fd136, %fd814;
	mov.f64 	%fd815, %fd827;
	@%p128 bra 	$L__BB0_190;

	mov.f64 	%fd608, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd827, %fd608;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r507}, %fd815;
	}

$L__BB0_190:
	mul.f64 	%fd609, %fd815, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r508, %fd609;
	st.local.u32 	[%rd2], %r508;
	cvt.rn.f64.s32 	%fd610, %r508;
	neg.f64 	%fd611, %fd610;
	fma.rn.f64 	%fd613, %fd611, %fd379, %fd815;
	fma.rn.f64 	%fd615, %fd611, %fd381, %fd613;
	fma.rn.f64 	%fd816, %fd611, %fd383, %fd615;
	and.b32  	%r380, %r507, 2145386496;
	setp.lt.u32 	%p157, %r380, 1105199104;
	@%p157 bra 	$L__BB0_192;

	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd815;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd816, [retval0+0];
	} // callseq 39
	ld.local.u32 	%r508, [%rd2];

$L__BB0_192:
	add.s32 	%r165, %r508, 1;
	and.b32  	%r381, %r165, 1;
	shl.b32 	%r382, %r165, 3;
	and.b32  	%r383, %r382, 8;
	setp.eq.s32 	%p158, %r381, 0;
	selp.f64 	%fd617, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p158;
	mul.wide.s32 	%rd311, %r383, 8;
	add.s64 	%rd313, %rd276, %rd311;
	ld.global.nc.f64 	%fd618, [%rd313+8];
	mul.rn.f64 	%fd155, %fd816, %fd816;
	fma.rn.f64 	%fd619, %fd617, %fd155, %fd618;
	ld.global.nc.f64 	%fd620, [%rd313+16];
	fma.rn.f64 	%fd621, %fd619, %fd155, %fd620;
	ld.global.nc.f64 	%fd622, [%rd313+24];
	fma.rn.f64 	%fd623, %fd621, %fd155, %fd622;
	ld.global.nc.f64 	%fd624, [%rd313+32];
	fma.rn.f64 	%fd625, %fd623, %fd155, %fd624;
	ld.global.nc.f64 	%fd626, [%rd313+40];
	fma.rn.f64 	%fd627, %fd625, %fd155, %fd626;
	ld.global.nc.f64 	%fd628, [%rd313+48];
	fma.rn.f64 	%fd156, %fd627, %fd155, %fd628;
	fma.rn.f64 	%fd818, %fd156, %fd816, %fd816;
	@%p158 bra 	$L__BB0_194;

	mov.f64 	%fd629, 0d3FF0000000000000;
	fma.rn.f64 	%fd818, %fd156, %fd155, %fd629;

$L__BB0_194:
	and.b32  	%r384, %r165, 2;
	setp.eq.s32 	%p159, %r384, 0;
	@%p159 bra 	$L__BB0_196;

	mov.f64 	%fd630, 0d0000000000000000;
	mov.f64 	%fd631, 0dBFF0000000000000;
	fma.rn.f64 	%fd818, %fd818, %fd631, %fd630;

$L__BB0_196:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r509}, %fd831;
	}
	mov.f64 	%fd819, %fd831;
	@%p134 bra 	$L__BB0_198;

	mov.f64 	%fd632, 0d0000000000000000;
	mul.rn.f64 	%fd819, %fd831, %fd632;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r509}, %fd819;
	}

$L__BB0_198:
	mul.f64 	%fd633, %fd819, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r510, %fd633;
	st.local.u32 	[%rd2], %r510;
	cvt.rn.f64.s32 	%fd634, %r510;
	neg.f64 	%fd635, %fd634;
	fma.rn.f64 	%fd637, %fd635, %fd379, %fd819;
	fma.rn.f64 	%fd639, %fd635, %fd381, %fd637;
	fma.rn.f64 	%fd820, %fd635, %fd383, %fd639;
	and.b32  	%r385, %r509, 2145386496;
	setp.lt.u32 	%p161, %r385, 1105199104;
	@%p161 bra 	$L__BB0_200;

	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd819;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd820, [retval0+0];
	} // callseq 40
	ld.local.u32 	%r510, [%rd2];

$L__BB0_200:
	and.b32  	%r386, %r510, 1;
	shl.b32 	%r387, %r510, 3;
	and.b32  	%r388, %r387, 8;
	setp.eq.s32 	%p162, %r386, 0;
	selp.f64 	%fd641, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p162;
	mul.wide.s32 	%rd315, %r388, 8;
	add.s64 	%rd317, %rd276, %rd315;
	ld.global.nc.f64 	%fd642, [%rd317+8];
	mul.rn.f64 	%fd167, %fd820, %fd820;
	fma.rn.f64 	%fd643, %fd641, %fd167, %fd642;
	ld.global.nc.f64 	%fd644, [%rd317+16];
	fma.rn.f64 	%fd645, %fd643, %fd167, %fd644;
	ld.global.nc.f64 	%fd646, [%rd317+24];
	fma.rn.f64 	%fd647, %fd645, %fd167, %fd646;
	ld.global.nc.f64 	%fd648, [%rd317+32];
	fma.rn.f64 	%fd649, %fd647, %fd167, %fd648;
	ld.global.nc.f64 	%fd650, [%rd317+40];
	fma.rn.f64 	%fd651, %fd649, %fd167, %fd650;
	ld.global.nc.f64 	%fd652, [%rd317+48];
	fma.rn.f64 	%fd168, %fd651, %fd167, %fd652;
	fma.rn.f64 	%fd822, %fd168, %fd820, %fd820;
	@%p162 bra 	$L__BB0_202;

	mov.f64 	%fd653, 0d3FF0000000000000;
	fma.rn.f64 	%fd822, %fd168, %fd167, %fd653;

$L__BB0_202:
	and.b32  	%r389, %r510, 2;
	setp.eq.s32 	%p163, %r389, 0;
	@%p163 bra 	$L__BB0_204;

	mov.f64 	%fd654, 0d0000000000000000;
	mov.f64 	%fd655, 0dBFF0000000000000;
	fma.rn.f64 	%fd822, %fd822, %fd655, %fd654;

$L__BB0_204:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r511}, %fd835;
	}
	mul.f64 	%fd174, %fd818, %fd822;
	mov.f64 	%fd823, %fd835;
	@%p140 bra 	$L__BB0_206;

	mov.f64 	%fd656, 0d0000000000000000;
	mul.rn.f64 	%fd823, %fd835, %fd656;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r511}, %fd823;
	}

$L__BB0_206:
	mul.f64 	%fd657, %fd823, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r512, %fd657;
	st.local.u32 	[%rd2], %r512;
	cvt.rn.f64.s32 	%fd658, %r512;
	neg.f64 	%fd659, %fd658;
	fma.rn.f64 	%fd661, %fd659, %fd379, %fd823;
	fma.rn.f64 	%fd663, %fd659, %fd381, %fd661;
	fma.rn.f64 	%fd824, %fd659, %fd383, %fd663;
	and.b32  	%r390, %r511, 2145386496;
	setp.lt.u32 	%p165, %r390, 1105199104;
	@%p165 bra 	$L__BB0_208;

	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd823;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd824, [retval0+0];
	} // callseq 41
	ld.local.u32 	%r512, [%rd2];

$L__BB0_208:
	add.s32 	%r176, %r512, 1;
	and.b32  	%r391, %r176, 1;
	shl.b32 	%r392, %r176, 3;
	and.b32  	%r393, %r392, 8;
	setp.eq.s32 	%p166, %r391, 0;
	selp.f64 	%fd665, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p166;
	mul.wide.s32 	%rd319, %r393, 8;
	add.s64 	%rd321, %rd276, %rd319;
	ld.global.nc.f64 	%fd666, [%rd321+8];
	mul.rn.f64 	%fd180, %fd824, %fd824;
	fma.rn.f64 	%fd667, %fd665, %fd180, %fd666;
	ld.global.nc.f64 	%fd668, [%rd321+16];
	fma.rn.f64 	%fd669, %fd667, %fd180, %fd668;
	ld.global.nc.f64 	%fd670, [%rd321+24];
	fma.rn.f64 	%fd671, %fd669, %fd180, %fd670;
	ld.global.nc.f64 	%fd672, [%rd321+32];
	fma.rn.f64 	%fd673, %fd671, %fd180, %fd672;
	ld.global.nc.f64 	%fd674, [%rd321+40];
	fma.rn.f64 	%fd675, %fd673, %fd180, %fd674;
	ld.global.nc.f64 	%fd676, [%rd321+48];
	fma.rn.f64 	%fd181, %fd675, %fd180, %fd676;
	fma.rn.f64 	%fd826, %fd181, %fd824, %fd824;
	@%p166 bra 	$L__BB0_210;

	mov.f64 	%fd677, 0d3FF0000000000000;
	fma.rn.f64 	%fd826, %fd181, %fd180, %fd677;

$L__BB0_210:
	and.b32  	%r394, %r176, 2;
	setp.eq.s32 	%p167, %r394, 0;
	@%p167 bra 	$L__BB0_212;

	mov.f64 	%fd678, 0d0000000000000000;
	mov.f64 	%fd679, 0dBFF0000000000000;
	fma.rn.f64 	%fd826, %fd826, %fd679, %fd678;

$L__BB0_212:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r513}, %fd827;
	}
	mul.f64 	%fd187, %fd174, %fd826;
	@%p128 bra 	$L__BB0_214;

	mov.f64 	%fd680, 0d0000000000000000;
	mul.rn.f64 	%fd827, %fd827, %fd680;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r513}, %fd827;
	}

$L__BB0_214:
	mul.f64 	%fd681, %fd827, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r514, %fd681;
	st.local.u32 	[%rd2], %r514;
	cvt.rn.f64.s32 	%fd682, %r514;
	neg.f64 	%fd683, %fd682;
	fma.rn.f64 	%fd685, %fd683, %fd379, %fd827;
	fma.rn.f64 	%fd687, %fd683, %fd381, %fd685;
	fma.rn.f64 	%fd828, %fd683, %fd383, %fd687;
	and.b32  	%r395, %r513, 2145386496;
	setp.lt.u32 	%p169, %r395, 1105199104;
	@%p169 bra 	$L__BB0_216;

	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd827;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd828, [retval0+0];
	} // callseq 42
	ld.local.u32 	%r514, [%rd2];

$L__BB0_216:
	add.s32 	%r182, %r514, 1;
	and.b32  	%r396, %r182, 1;
	shl.b32 	%r397, %r182, 3;
	and.b32  	%r398, %r397, 8;
	setp.eq.s32 	%p170, %r396, 0;
	selp.f64 	%fd689, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p170;
	mul.wide.s32 	%rd323, %r398, 8;
	add.s64 	%rd325, %rd276, %rd323;
	ld.global.nc.f64 	%fd690, [%rd325+8];
	mul.rn.f64 	%fd193, %fd828, %fd828;
	fma.rn.f64 	%fd691, %fd689, %fd193, %fd690;
	ld.global.nc.f64 	%fd692, [%rd325+16];
	fma.rn.f64 	%fd693, %fd691, %fd193, %fd692;
	ld.global.nc.f64 	%fd694, [%rd325+24];
	fma.rn.f64 	%fd695, %fd693, %fd193, %fd694;
	ld.global.nc.f64 	%fd696, [%rd325+32];
	fma.rn.f64 	%fd697, %fd695, %fd193, %fd696;
	ld.global.nc.f64 	%fd698, [%rd325+40];
	fma.rn.f64 	%fd699, %fd697, %fd193, %fd698;
	ld.global.nc.f64 	%fd700, [%rd325+48];
	fma.rn.f64 	%fd194, %fd699, %fd193, %fd700;
	fma.rn.f64 	%fd830, %fd194, %fd828, %fd828;
	@%p170 bra 	$L__BB0_218;

	mov.f64 	%fd701, 0d3FF0000000000000;
	fma.rn.f64 	%fd830, %fd194, %fd193, %fd701;

$L__BB0_218:
	and.b32  	%r399, %r182, 2;
	setp.eq.s32 	%p171, %r399, 0;
	@%p171 bra 	$L__BB0_220;

	mov.f64 	%fd702, 0d0000000000000000;
	mov.f64 	%fd703, 0dBFF0000000000000;
	fma.rn.f64 	%fd830, %fd830, %fd703, %fd702;

$L__BB0_220:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r515}, %fd831;
	}
	@%p134 bra 	$L__BB0_222;

	mov.f64 	%fd704, 0d0000000000000000;
	mul.rn.f64 	%fd831, %fd831, %fd704;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r515}, %fd831;
	}

$L__BB0_222:
	mul.f64 	%fd705, %fd831, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r516, %fd705;
	st.local.u32 	[%rd2], %r516;
	cvt.rn.f64.s32 	%fd706, %r516;
	neg.f64 	%fd707, %fd706;
	fma.rn.f64 	%fd709, %fd707, %fd379, %fd831;
	fma.rn.f64 	%fd711, %fd707, %fd381, %fd709;
	fma.rn.f64 	%fd832, %fd707, %fd383, %fd711;
	and.b32  	%r400, %r515, 2145386496;
	setp.lt.u32 	%p173, %r400, 1105199104;
	@%p173 bra 	$L__BB0_224;

	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd831;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 43
	ld.local.u32 	%r516, [%rd2];

$L__BB0_224:
	add.s32 	%r188, %r516, 1;
	and.b32  	%r401, %r188, 1;
	shl.b32 	%r402, %r188, 3;
	and.b32  	%r403, %r402, 8;
	setp.eq.s32 	%p174, %r401, 0;
	selp.f64 	%fd713, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p174;
	mul.wide.s32 	%rd327, %r403, 8;
	add.s64 	%rd329, %rd276, %rd327;
	ld.global.nc.f64 	%fd714, [%rd329+8];
	mul.rn.f64 	%fd205, %fd832, %fd832;
	fma.rn.f64 	%fd715, %fd713, %fd205, %fd714;
	ld.global.nc.f64 	%fd716, [%rd329+16];
	fma.rn.f64 	%fd717, %fd715, %fd205, %fd716;
	ld.global.nc.f64 	%fd718, [%rd329+24];
	fma.rn.f64 	%fd719, %fd717, %fd205, %fd718;
	ld.global.nc.f64 	%fd720, [%rd329+32];
	fma.rn.f64 	%fd721, %fd719, %fd205, %fd720;
	ld.global.nc.f64 	%fd722, [%rd329+40];
	fma.rn.f64 	%fd723, %fd721, %fd205, %fd722;
	ld.global.nc.f64 	%fd724, [%rd329+48];
	fma.rn.f64 	%fd206, %fd723, %fd205, %fd724;
	fma.rn.f64 	%fd834, %fd206, %fd832, %fd832;
	@%p174 bra 	$L__BB0_226;

	mov.f64 	%fd725, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd206, %fd205, %fd725;

$L__BB0_226:
	and.b32  	%r404, %r188, 2;
	setp.eq.s32 	%p175, %r404, 0;
	@%p175 bra 	$L__BB0_228;

	mov.f64 	%fd726, 0d0000000000000000;
	mov.f64 	%fd727, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd727, %fd726;

$L__BB0_228:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r517}, %fd835;
	}
	mul.f64 	%fd212, %fd830, %fd834;
	@%p140 bra 	$L__BB0_230;

	mov.f64 	%fd728, 0d0000000000000000;
	mul.rn.f64 	%fd835, %fd835, %fd728;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r517}, %fd835;
	}

$L__BB0_230:
	mul.f64 	%fd729, %fd835, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r518, %fd729;
	st.local.u32 	[%rd2], %r518;
	cvt.rn.f64.s32 	%fd730, %r518;
	neg.f64 	%fd731, %fd730;
	fma.rn.f64 	%fd733, %fd731, %fd379, %fd835;
	fma.rn.f64 	%fd735, %fd731, %fd381, %fd733;
	fma.rn.f64 	%fd836, %fd731, %fd383, %fd735;
	and.b32  	%r405, %r517, 2145386496;
	setp.lt.u32 	%p177, %r405, 1105199104;
	@%p177 bra 	$L__BB0_232;

	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd835;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd836, [retval0+0];
	} // callseq 44
	ld.local.u32 	%r518, [%rd2];

$L__BB0_232:
	and.b32  	%r406, %r518, 1;
	shl.b32 	%r407, %r518, 3;
	and.b32  	%r408, %r407, 8;
	setp.eq.s32 	%p178, %r406, 0;
	selp.f64 	%fd737, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p178;
	mul.wide.s32 	%rd331, %r408, 8;
	add.s64 	%rd333, %rd276, %rd331;
	ld.global.nc.f64 	%fd738, [%rd333+8];
	mul.rn.f64 	%fd218, %fd836, %fd836;
	fma.rn.f64 	%fd739, %fd737, %fd218, %fd738;
	ld.global.nc.f64 	%fd740, [%rd333+16];
	fma.rn.f64 	%fd741, %fd739, %fd218, %fd740;
	ld.global.nc.f64 	%fd742, [%rd333+24];
	fma.rn.f64 	%fd743, %fd741, %fd218, %fd742;
	ld.global.nc.f64 	%fd744, [%rd333+32];
	fma.rn.f64 	%fd745, %fd743, %fd218, %fd744;
	ld.global.nc.f64 	%fd746, [%rd333+40];
	fma.rn.f64 	%fd747, %fd745, %fd218, %fd746;
	ld.global.nc.f64 	%fd748, [%rd333+48];
	fma.rn.f64 	%fd219, %fd747, %fd218, %fd748;
	fma.rn.f64 	%fd838, %fd219, %fd836, %fd836;
	@%p178 bra 	$L__BB0_234;

	mov.f64 	%fd749, 0d3FF0000000000000;
	fma.rn.f64 	%fd838, %fd219, %fd218, %fd749;

$L__BB0_234:
	and.b32  	%r409, %r518, 2;
	setp.eq.s32 	%p179, %r409, 0;
	@%p179 bra 	$L__BB0_236;

	mov.f64 	%fd750, 0d0000000000000000;
	mov.f64 	%fd751, 0dBFF0000000000000;
	fma.rn.f64 	%fd838, %fd838, %fd751, %fd750;

$L__BB0_236:
	mul.f64 	%fd752, %fd212, %fd838;
	mul.f64 	%fd753, %fd752, %fd22;
	neg.f64 	%fd754, %fd753;
	mul.f64 	%fd755, %fd187, %fd21;
	sub.f64 	%fd756, %fd754, %fd755;
	mul.f64 	%fd757, %fd149, %fd20;
	sub.f64 	%fd758, %fd756, %fd757;
	mul.f64 	%fd759, %fd22, 0d0000000000000000;
	fma.rn.f64 	%fd760, %fd21, 0d0000000000000000, %fd759;
	fma.rn.f64 	%fd761, %fd20, 0d0000000000000000, %fd760;
	mul.f64 	%fd762, %fd761, %fd19;
	fma.rn.f64 	%fd763, %fd761, %fd18, %fd762;
	fma.rn.f64 	%fd764, %fd758, %fd17, %fd763;
	ld.local.f64 	%fd765, [%rd87];
	fma.rn.f64 	%fd839, %fd111, %fd764, %fd765;
	st.local.f64 	[%rd87], %fd839;
	add.s32 	%r488, %r488, 1;
	setp.lt.s32 	%p180, %r488, %r484;
	@%p180 bra 	$L__BB0_116;
	bra.uni 	$L__BB0_237;

$L__BB0_114:
	ld.local.f64 	%fd840, [%rd86];
	ld.local.f64 	%fd839, [%rd87];

$L__BB0_237:
	ld.local.u32 	%r410, [%rd85];
	mul.wide.s32 	%rd334, %r410, 8;
	add.s64 	%rd335, %rd29, %rd334;
	fma.rn.f64 	%fd766, %fd840, 0d3FE0000000000000, %fd839;
	ld.global.f64 	%fd767, [%rd335];
	mul.f64 	%fd768, %fd767, %fd766;
	mul.wide.s32 	%rd336, %r99, 4;
	add.s64 	%rd337, %rd23, %rd336;
	ld.local.u32 	%r411, [%rd337];
	mul.wide.s32 	%rd338, %r411, 8;
	add.s64 	%rd339, %rd29, %rd338;
	ld.global.f64 	%fd769, [%rd339];
	mul.f64 	%fd228, %fd768, %fd769;
	ld.global.u64 	%rd369, [%rd1];

$L__BB0_238:
	mov.b64 	%fd770, %rd369;
	add.f64 	%fd771, %fd228, %fd770;
	mov.b64 	%rd340, %fd771;
	atom.global.cas.b64 	%rd91, [%rd1], %rd369, %rd340;
	setp.ne.s64 	%p181, %rd369, %rd91;
	mov.u64 	%rd369, %rd91;
	@%p181 bra 	$L__BB0_238;

	add.s32 	%r487, %r487, 1;
	setp.lt.u32 	%p182, %r487, 3;
	@%p182 bra 	$L__BB0_113;

	cvt.u32.u64 	%r412, %rd84;
	add.s32 	%r486, %r412, 1;
	setp.lt.u32 	%p183, %r486, 3;
	@%p183 bra 	$L__BB0_243;

	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd77;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 45
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd70;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 46
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd69;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 47
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd67;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 48
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd58;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 49
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd49;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 50
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd39;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 51
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 52
	add.s32 	%r8, %r8, 1;
	setp.lt.s32 	%p184, %r8, %r4;
	@%p184 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_242;

$L__BB0_11:
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd39;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 10
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 11

$L__BB0_242:
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot1[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB1_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r4, %r11, %r10;
	mov.u32 	%r12, 19;
	sub.s32 	%r13, %r12, %r10;
	setp.gt.s32 	%p2, %r4, 14;
	selp.b32 	%r5, 18, %r13, %p2;
	setp.gt.s32 	%p3, %r4, %r5;
	mov.u64 	%rd75, 0;
	mov.u64 	%rd76, %rd1;
	@%p3 bra 	$L__BB1_4;

	add.s32 	%r6, %r4, -1;
	mov.b64 	%rd22, %fd4;
	shl.b64 	%rd23, %rd22, 11;
	or.b64  	%rd4, %rd23, -9223372036854775808;
	mov.u64 	%rd25, __cudart_i2opi_d;
	mov.u64 	%rd76, %rd1;
	mov.u32 	%r28, %r6;

$L__BB1_3:
	.pragma "nounroll";
	mul.wide.s32 	%rd24, %r28, 8;
	add.s64 	%rd26, %rd25, %rd24;
	ld.global.nc.u64 	%rd27, [%rd26];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd27;
	mov.b64 	{%blo,%bhi}, %rd4;
	mov.b64 	{%clo,%chi}, %rd75;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd28, {%r0,%r1};
	mov.b64 	%rd75, {%r2,%r3};
	}
	st.local.u64 	[%rd76], %rd28;
	add.s32 	%r28, %r28, 1;
	sub.s32 	%r14, %r28, %r6;
	mul.wide.s32 	%rd29, %r14, 8;
	add.s64 	%rd76, %rd1, %rd29;
	setp.lt.s32 	%p4, %r28, %r5;
	@%p4 bra 	$L__BB1_3;

$L__BB1_4:
	st.local.u64 	[%rd76], %rd75;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB1_6;

	mov.u32 	%r15, 64;
	sub.s32 	%r16, %r15, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r16;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r16;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB1_6:
	and.b32  	%r17, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r18, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r19, %rd39;
	and.b32  	%r20, %r19, 1;
	add.s32 	%r21, %r20, %r18;
	neg.s32 	%r22, %r21;
	setp.eq.s32 	%p6, %r17, 0;
	selp.b32 	%r23, %r21, %r22, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r23;
	setp.eq.s32 	%p7, %r20, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r24, %r17, -2147483648;
	selp.b32 	%r25, %r17, %r24, %p7;
	clz.b64 	%r26, %rd45;
	cvt.u64.u32 	%rd47, %r26;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r26;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r27, %rd50;
	shr.u64 	%rd51, %rd46, %r27;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r25;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB1_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}

