//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31057947
// Cuda compilation tools, release 11.6, V11.6.124
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .func  (.param .b64 func_retval0) malloc
(
	.param .b64 malloc_param_0
)
;
.extern .func free
(
	.param .b64 free_param_0
)
;
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
// _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives has been demoted
.global .align 1 .b8 $str[24] = {78, 117, 109, 98, 101, 114, 32, 111, 102, 32, 98, 108, 111, 99, 107, 115, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$1[25] = {84, 104, 114, 101, 97, 100, 115, 32, 112, 101, 114, 32, 98, 108, 111, 99, 107, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$2[56] = {84, 111, 116, 97, 108, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 58, 32, 37, 100, 32, 44, 32, 73, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 115, 32, 112, 101, 114, 32, 116, 104, 114, 101, 97, 100, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 1 .b8 $str$3[54] = {73, 110, 32, 98, 108, 111, 99, 107, 32, 48, 32, 116, 104, 114, 101, 97, 100, 32, 48, 32, 99, 111, 109, 112, 117, 116, 105, 110, 103, 32, 105, 110, 116, 101, 114, 97, 99, 116, 105, 111, 110, 32, 110, 111, 46, 32, 58, 32, 37, 100, 32, 10, 32, 0};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i(
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_0,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_1,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_2,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_3,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_4,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_5,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_6,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_7,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_8,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_9,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_10,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_11,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_12,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_13,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_14,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_15,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_16,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_17,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_18,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_19,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_20,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_21,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_22,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_23,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_24,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_25,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_26,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_27,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_28,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_29,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_30,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_31,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_32,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_33,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_34,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_35,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_36,
	.param .u64 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_37,
	.param .u32 _Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_38
)
{
	.local .align 8 .b8 	__local_depot0[248];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<200>;
	.reg .b32 	%r<577>;
	.reg .f64 	%fd<874>;
	.reg .b64 	%rd<399>;
	// demoted variable
	.shared .align 8 .b8 _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives[20736];

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r224, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_4];
	ld.param.u32 	%r225, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_5];
	ld.param.u64 	%rd97, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_6];
	ld.param.u64 	%rd98, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_7];
	ld.param.u64 	%rd99, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_8];
	ld.param.u64 	%rd109, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_24];
	ld.param.u64 	%rd110, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_25];
	ld.param.u64 	%rd111, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_26];
	ld.param.u64 	%rd112, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_29];
	ld.param.u64 	%rd113, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_30];
	ld.param.u32 	%r230, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_38];
	add.u64 	%rd115, %SP, 8;
	add.u64 	%rd1, %SPL, 8;
	add.u64 	%rd124, %SP, 0;
	add.u64 	%rd10, %SPL, 0;
	add.u64 	%rd17, %SPL, 32;
	add.u64 	%rd18, %SPL, 64;
	add.u64 	%rd19, %SPL, 76;
	add.u64 	%rd20, %SPL, 88;
	add.u64 	%rd21, %SPL, 100;
	add.u64 	%rd22, %SPL, 112;
	add.u64 	%rd23, %SPL, 124;
	add.u64 	%rd24, %SPL, 136;
	add.u64 	%rd25, %SPL, 148;
	add.u64 	%rd26, %SPL, 160;
	add.u64 	%rd27, %SPL, 176;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %tid.x;
	setp.lt.s32 	%p20, %r230, 1;
	@%p20 bra 	$L__BB0_7;

	mul.lo.s32 	%r3, %r2, %r230;
	and.b32  	%r489, %r230, 3;
	add.s32 	%r232, %r230, -1;
	setp.lt.u32 	%p21, %r232, 3;
	mov.u32 	%r487, 0;
	@%p21 bra 	$L__BB0_4;

	sub.s32 	%r486, %r230, %r489;
	mov.u64 	%rd142, 0;

$L__BB0_3:
	add.s32 	%r234, %r487, %r3;
	shl.b32 	%r235, %r234, 3;
	mov.u32 	%r236, _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives;
	add.s32 	%r237, %r236, %r235;
	st.shared.u64 	[%r237], %rd142;
	st.shared.u64 	[%r237+8], %rd142;
	st.shared.u64 	[%r237+16], %rd142;
	st.shared.u64 	[%r237+24], %rd142;
	add.s32 	%r487, %r487, 4;
	add.s32 	%r486, %r486, -4;
	setp.ne.s32 	%p22, %r486, 0;
	@%p22 bra 	$L__BB0_3;

$L__BB0_4:
	setp.eq.s32 	%p23, %r489, 0;
	@%p23 bra 	$L__BB0_7;

	add.s32 	%r238, %r487, %r3;
	shl.b32 	%r239, %r238, 3;
	mov.u32 	%r240, _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives;
	add.s32 	%r488, %r240, %r239;
	mov.u64 	%rd143, 0;

$L__BB0_6:
	.pragma "nounroll";
	st.shared.u64 	[%r488], %rd143;
	add.s32 	%r488, %r488, 8;
	add.s32 	%r489, %r489, -1;
	setp.ne.s32 	%p24, %r489, 0;
	@%p24 bra 	$L__BB0_6;

$L__BB0_7:
	mov.u32 	%r16, %ctaid.x;
	cvt.rn.f64.s32 	%fd237, %r224;
	cvt.rn.f64.s32 	%fd238, %r225;
	div.rn.f64 	%fd239, %fd237, %fd238;
	cvt.rpi.f64.f64 	%fd240, %fd239;
	cvt.rzi.s32.f64 	%r17, %fd240;
	or.b32  	%r18, %r16, %r2;
	setp.ne.s32 	%p25, %r18, 0;
	add.u64 	%rd144, %SP, 56;
	add.u64 	%rd28, %SPL, 56;
	@%p25 bra 	$L__BB0_9;

	mov.u32 	%r241, %nctaid.x;
	st.local.u32 	[%rd28], %r241;
	mov.u64 	%rd145, $str;
	cvta.global.u64 	%rd146, %rd145;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd146;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd144;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r242, [retval0+0];
	} // callseq 0
	st.local.u32 	[%rd28], %r1;
	mov.u64 	%rd148, $str$1;
	cvta.global.u64 	%rd149, %rd148;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd149;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd144;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r243, [retval0+0];
	} // callseq 1
	st.local.u32 	[%rd28], %r224;
	st.local.u32 	[%rd28+4], %r17;
	mov.u64 	%rd150, $str$2;
	cvta.global.u64 	%rd151, %rd150;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd151;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd144;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r244, [retval0+0];
	} // callseq 2

$L__BB0_9:
	setp.lt.s32 	%p26, %r17, 1;
	mul.lo.s32 	%r19, %r16, %r1;
	@%p26 bra 	$L__BB0_249;

	cvta.to.global.u64 	%rd29, %rd109;
	cvta.to.global.u64 	%rd30, %rd111;
	cvta.to.global.u64 	%rd31, %rd99;
	cvta.to.global.u64 	%rd32, %rd113;
	cvta.to.global.u64 	%rd33, %rd112;
	cvta.to.global.u64 	%rd34, %rd110;
	cvta.to.global.u64 	%rd35, %rd98;
	cvta.to.global.u64 	%rd36, %rd97;
	add.s32 	%r246, %r19, %r2;
	mul.lo.s32 	%r20, %r17, %r246;
	mul.lo.s32 	%r21, %r2, %r230;
	mov.u32 	%r490, 0;

$L__BB0_11:
	@%p25 bra 	$L__BB0_13;

	add.u64 	%rd376, %SP, 56;
	add.u64 	%rd375, %SP, 56;
	add.u64 	%rd374, %SPL, 56;
	st.local.u32 	[%rd374], %r490;
	mov.u64 	%rd152, $str$3;
	cvta.global.u64 	%rd153, %rd152;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd153;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd375;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r247, [retval0+0];
	} // callseq 3

$L__BB0_13:
	add.s32 	%r23, %r490, %r20;
	mov.u64 	%rd155, 0;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd155;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 4
	mov.u64 	%rd156, 48;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd156;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd37, [retval0+0];
	} // callseq 5
	setp.ne.s64 	%p28, %rd37, 0;
	@%p28 bra 	$L__BB0_15;

	mov.u64 	%rd157, -1;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd157;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd158, [retval0+0];
	} // callseq 6

$L__BB0_15:
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd155;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd156;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd38, [retval0+0];
	} // callseq 8
	setp.ne.s64 	%p29, %rd38, 0;
	@%p29 bra 	$L__BB0_17;

	mov.u64 	%rd161, -1;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd161;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd162, [retval0+0];
	} // callseq 9

$L__BB0_17:
	ld.param.u32 	%r475, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_4];
	setp.lt.s32 	%p30, %r23, %r475;
	@%p30 bra 	$L__BB0_19;
	bra.uni 	$L__BB0_18;

$L__BB0_19:
	ld.param.u32 	%r541, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_11];
	ld.param.u64 	%rd389, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_10];
	ld.param.u64 	%rd388, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_9];
	mul.wide.s32 	%rd163, %r23, 4;
	add.s64 	%rd164, %rd36, %rd163;
	add.s64 	%rd165, %rd35, %rd163;
	ld.global.u32 	%r248, [%rd164];
	mul.lo.s32 	%r249, %r248, 3;
	ld.global.u32 	%r250, [%rd165];
	mul.lo.s32 	%r251, %r250, 3;
	mul.wide.s32 	%rd166, %r249, 4;
	add.s64 	%rd167, %rd34, %rd166;
	ld.global.u32 	%r24, [%rd167];
	ld.global.u32 	%r25, [%rd167+4];
	ld.global.u32 	%r26, [%rd167+8];
	mul.wide.s32 	%rd168, %r251, 4;
	add.s64 	%rd169, %rd34, %rd168;
	ld.global.u32 	%r540, [%rd169];
	ld.global.u32 	%r28, [%rd169+4];
	ld.global.u32 	%r29, [%rd169+8];
	st.local.u32 	[%rd21], %r24;
	st.local.u32 	[%rd21+4], %r25;
	st.local.u32 	[%rd21+8], %r26;
	st.local.u32 	[%rd22], %r540;
	st.local.u32 	[%rd22+4], %r28;
	st.local.u32 	[%rd22+8], %r29;
	add.s64 	%rd170, %rd33, %rd166;
	ld.global.u32 	%r252, [%rd170];
	st.local.u32 	[%rd23], %r252;
	ld.global.u32 	%r253, [%rd170+4];
	st.local.u32 	[%rd23+4], %r253;
	ld.global.u32 	%r254, [%rd170+8];
	st.local.u32 	[%rd23+8], %r254;
	add.s64 	%rd171, %rd32, %rd168;
	ld.global.u32 	%r255, [%rd171];
	st.local.u32 	[%rd24], %r255;
	ld.global.u32 	%r256, [%rd171+4];
	st.local.u32 	[%rd24+4], %r256;
	ld.global.u32 	%r257, [%rd171+8];
	st.local.u32 	[%rd24+8], %r257;
	mov.u32 	%r496, 0;
	st.local.u32 	[%rd25], %r496;
	mov.u32 	%r492, 1;
	st.local.u32 	[%rd25+4], %r492;
	mov.u32 	%r506, 2;
	st.local.u32 	[%rd25+8], %r506;
	st.local.u32 	[%rd26], %r496;
	st.local.u32 	[%rd26+4], %r492;
	st.local.u32 	[%rd26+8], %r506;
	add.s64 	%rd172, %rd31, %rd163;
	ld.global.u32 	%r30, [%rd172];
	setp.eq.s32 	%p31, %r30, 0;
	mov.u32 	%r535, %r26;
	mov.u32 	%r536, %r25;
	mov.u32 	%r537, %r24;
	mov.u32 	%r538, %r29;
	mov.u32 	%r539, %r28;
	@%p31 bra 	$L__BB0_90;

	setp.eq.s32 	%p32, %r30, 1;
	@%p32 bra 	$L__BB0_56;
	bra.uni 	$L__BB0_21;

$L__BB0_56:
	setp.eq.s32 	%p9, %r24, %r540;
	setp.eq.s32 	%p10, %r24, %r28;
	or.pred  	%p65, %p10, %p9;
	setp.eq.s32 	%p11, %r24, %r29;
	or.pred  	%p66, %p11, %p65;
	@%p66 bra 	$L__BB0_58;
	bra.uni 	$L__BB0_57;

$L__BB0_58:
	st.local.u32 	[%rd18], %r24;
	mov.u32 	%r514, 0;
	mov.u32 	%r516, 1;
	bra.uni 	$L__BB0_59;

$L__BB0_21:
	ld.param.u32 	%r541, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_20];
	ld.param.u64 	%rd389, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_19];
	ld.param.u64 	%rd388, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_18];
	setp.ne.s32 	%p33, %r30, 2;
	mov.u32 	%r535, %r26;
	mov.u32 	%r536, %r25;
	mov.u32 	%r537, %r24;
	mov.u32 	%r538, %r29;
	mov.u32 	%r539, %r28;
	@%p33 bra 	$L__BB0_90;

	setp.eq.s32 	%p1, %r24, %r540;
	setp.eq.s32 	%p2, %r24, %r28;
	or.pred  	%p34, %p2, %p1;
	setp.eq.s32 	%p3, %r24, %r29;
	or.pred  	%p35, %p3, %p34;
	@%p35 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_23;

$L__BB0_24:
	st.local.u32 	[%rd18], %r24;
	mov.u32 	%r492, 0;
	mov.u32 	%r494, 1;
	bra.uni 	$L__BB0_25;

$L__BB0_57:
	st.local.u32 	[%rd19], %r24;
	mov.u32 	%r514, 1;
	mov.u32 	%r516, 0;

$L__BB0_59:
	setp.eq.s32 	%p12, %r25, %r540;
	setp.eq.s32 	%p13, %r26, %r540;
	or.pred  	%p67, %p12, %p9;
	or.pred  	%p68, %p13, %p67;
	mov.u32 	%r518, 0;
	@%p68 bra 	$L__BB0_61;

	st.local.u32 	[%rd20], %r540;
	mov.u32 	%r518, 1;

$L__BB0_61:
	setp.eq.s32 	%p69, %r25, %r28;
	setp.eq.s32 	%p70, %r25, %r29;
	setp.eq.s32 	%p71, %r26, %r28;
	setp.eq.s32 	%p72, %r26, %r29;
	or.pred  	%p73, %p69, %p12;
	or.pred  	%p74, %p70, %p73;
	or.pred  	%p75, %p69, %p10;
	or.pred  	%p14, %p71, %p75;
	or.pred  	%p76, %p71, %p13;
	or.pred  	%p15, %p72, %p76;
	or.pred  	%p77, %p70, %p11;
	or.pred  	%p16, %p72, %p77;
	@%p74 bra 	$L__BB0_63;
	bra.uni 	$L__BB0_62;

$L__BB0_63:
	add.s32 	%r70, %r516, 1;
	mul.wide.u32 	%rd187, %r516, 4;
	add.s64 	%rd188, %rd18, %rd187;
	st.local.u32 	[%rd188], %r25;
	mov.u32 	%r516, %r70;
	mov.u32 	%r517, %r514;
	bra.uni 	$L__BB0_64;

$L__BB0_62:
	add.s32 	%r517, %r514, 1;
	mul.wide.u32 	%rd185, %r514, 4;
	add.s64 	%rd186, %rd19, %rd185;
	st.local.u32 	[%rd186], %r25;

$L__BB0_64:
	@%p14 bra 	$L__BB0_66;

	add.s32 	%r73, %r518, 1;
	mul.wide.u32 	%rd189, %r518, 4;
	add.s64 	%rd190, %rd20, %rd189;
	st.local.u32 	[%rd190], %r28;
	mov.u32 	%r518, %r73;

$L__BB0_66:
	@%p15 bra 	$L__BB0_68;
	bra.uni 	$L__BB0_67;

$L__BB0_68:
	mul.wide.u32 	%rd193, %r516, 4;
	add.s64 	%rd194, %rd18, %rd193;
	st.local.u32 	[%rd194], %r26;
	bra.uni 	$L__BB0_69;

$L__BB0_67:
	mul.wide.u32 	%rd191, %r517, 4;
	add.s64 	%rd192, %rd19, %rd191;
	st.local.u32 	[%rd192], %r26;

$L__BB0_69:
	@%p16 bra 	$L__BB0_71;

	mul.wide.u32 	%rd195, %r518, 4;
	add.s64 	%rd196, %rd20, %rd195;
	st.local.u32 	[%rd196], %r29;

$L__BB0_71:
	ld.local.u32 	%r537, [%rd18];
	ld.local.u32 	%r536, [%rd19];
	ld.local.u32 	%r539, [%rd20];
	ld.local.u32 	%r535, [%rd19+4];
	ld.local.u32 	%r538, [%rd20+4];
	setp.eq.s32 	%p78, %r24, %r537;
	mov.u32 	%r528, 2;
	mov.u32 	%r526, 1;
	mov.u32 	%r519, %r526;
	mov.u32 	%r525, %r528;
	@%p78 bra 	$L__BB0_74;

	setp.eq.s32 	%p79, %r24, %r536;
	mov.u32 	%r519, 0;
	@%p79 bra 	$L__BB0_74;

	setp.eq.s32 	%p80, %r24, %r535;
	selp.b32 	%r525, 0, 2, %p80;
	mov.u32 	%r519, %r526;

$L__BB0_74:
	setp.eq.s32 	%p81, %r540, %r537;
	mov.u32 	%r521, %r526;
	@%p81 bra 	$L__BB0_77;

	setp.eq.s32 	%p82, %r540, %r539;
	mov.u32 	%r521, 0;
	@%p82 bra 	$L__BB0_77;

	setp.eq.s32 	%p83, %r540, %r538;
	selp.b32 	%r528, 0, 2, %p83;
	mov.u32 	%r521, %r526;

$L__BB0_77:
	setp.eq.s32 	%p84, %r25, %r537;
	mov.u32 	%r523, %r526;
	mov.u32 	%r524, %r519;
	@%p84 bra 	$L__BB0_80;

	setp.eq.s32 	%p85, %r25, %r536;
	mov.u32 	%r524, 1;
	mov.u32 	%r523, 0;
	@%p85 bra 	$L__BB0_80;

	setp.eq.s32 	%p86, %r25, %r535;
	selp.b32 	%r525, 1, %r525, %p86;
	mov.u32 	%r524, %r519;

$L__BB0_80:
	setp.eq.s32 	%p87, %r28, %r537;
	mov.u32 	%r527, %r521;
	@%p87 bra 	$L__BB0_83;

	setp.eq.s32 	%p88, %r28, %r539;
	mov.u32 	%r527, 1;
	mov.u32 	%r526, 0;
	@%p88 bra 	$L__BB0_83;

	setp.eq.s32 	%p89, %r28, %r538;
	selp.b32 	%r528, 1, %r528, %p89;
	mov.u32 	%r527, %r521;

$L__BB0_83:
	setp.eq.s32 	%p90, %r26, %r537;
	mov.u32 	%r532, 2;
	mov.u32 	%r529, %r532;
	mov.u32 	%r530, %r524;
	@%p90 bra 	$L__BB0_86;

	setp.eq.s32 	%p91, %r26, %r536;
	mov.u32 	%r530, 2;
	mov.u32 	%r529, %r523;
	@%p91 bra 	$L__BB0_86;

	setp.eq.s32 	%p92, %r26, %r535;
	selp.b32 	%r525, 2, %r525, %p92;
	mov.u32 	%r529, %r523;
	mov.u32 	%r530, %r524;

$L__BB0_86:
	setp.eq.s32 	%p93, %r29, %r537;
	mov.u32 	%r533, %r527;
	@%p93 bra 	$L__BB0_89;

	setp.eq.s32 	%p94, %r29, %r539;
	mov.u32 	%r533, 2;
	mov.u32 	%r532, %r526;
	@%p94 bra 	$L__BB0_89;

	setp.eq.s32 	%p95, %r29, %r538;
	selp.b32 	%r528, 2, %r528, %p95;
	mov.u32 	%r532, %r526;
	mov.u32 	%r533, %r527;

$L__BB0_89:
	ld.param.u32 	%r541, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_14];
	ld.param.u64 	%rd389, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_13];
	ld.param.u64 	%rd388, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_12];
	st.local.u32 	[%rd25+8], %r525;
	st.local.u32 	[%rd25+4], %r530;
	st.local.u32 	[%rd25], %r529;
	st.local.u32 	[%rd26+8], %r528;
	st.local.u32 	[%rd26+4], %r533;
	st.local.u32 	[%rd26], %r532;
	mov.u32 	%r540, %r537;
	bra.uni 	$L__BB0_90;

$L__BB0_23:
	st.local.u32 	[%rd19], %r24;
	mov.u32 	%r494, %r496;

$L__BB0_25:
	setp.eq.s32 	%p4, %r25, %r540;
	setp.eq.s32 	%p5, %r26, %r540;
	or.pred  	%p36, %p4, %p1;
	or.pred  	%p37, %p5, %p36;
	@%p37 bra 	$L__BB0_27;

	st.local.u32 	[%rd20], %r540;
	mov.u32 	%r496, 1;

$L__BB0_27:
	setp.eq.s32 	%p38, %r25, %r28;
	setp.eq.s32 	%p39, %r25, %r29;
	setp.eq.s32 	%p40, %r26, %r28;
	setp.eq.s32 	%p41, %r26, %r29;
	or.pred  	%p42, %p38, %p4;
	or.pred  	%p43, %p39, %p42;
	or.pred  	%p44, %p38, %p2;
	or.pred  	%p6, %p40, %p44;
	or.pred  	%p45, %p40, %p5;
	or.pred  	%p7, %p41, %p45;
	or.pred  	%p46, %p39, %p3;
	or.pred  	%p8, %p41, %p46;
	@%p43 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_28;

$L__BB0_29:
	add.s32 	%r35, %r494, 1;
	mul.wide.u32 	%rd175, %r494, 4;
	add.s64 	%rd176, %rd18, %rd175;
	st.local.u32 	[%rd176], %r25;
	mov.u32 	%r494, %r35;
	mov.u32 	%r495, %r492;
	bra.uni 	$L__BB0_30;

$L__BB0_28:
	add.s32 	%r495, %r492, 1;
	mul.wide.u32 	%rd173, %r492, 4;
	add.s64 	%rd174, %rd19, %rd173;
	st.local.u32 	[%rd174], %r25;

$L__BB0_30:
	@%p6 bra 	$L__BB0_32;

	add.s32 	%r38, %r496, 1;
	mul.wide.u32 	%rd177, %r496, 4;
	add.s64 	%rd178, %rd20, %rd177;
	st.local.u32 	[%rd178], %r28;
	mov.u32 	%r496, %r38;

$L__BB0_32:
	@%p7 bra 	$L__BB0_34;
	bra.uni 	$L__BB0_33;

$L__BB0_34:
	mul.wide.u32 	%rd181, %r494, 4;
	add.s64 	%rd182, %rd18, %rd181;
	st.local.u32 	[%rd182], %r26;
	bra.uni 	$L__BB0_35;

$L__BB0_33:
	mul.wide.u32 	%rd179, %r495, 4;
	add.s64 	%rd180, %rd19, %rd179;
	st.local.u32 	[%rd180], %r26;

$L__BB0_35:
	@%p8 bra 	$L__BB0_37;

	mul.wide.u32 	%rd183, %r496, 4;
	add.s64 	%rd184, %rd20, %rd183;
	st.local.u32 	[%rd184], %r29;

$L__BB0_37:
	ld.local.u32 	%r537, [%rd18];
	ld.local.u32 	%r536, [%rd18+4];
	ld.local.u32 	%r535, [%rd19];
	ld.local.u32 	%r538, [%rd20];
	setp.eq.s32 	%p47, %r24, %r537;
	mov.u32 	%r504, 1;
	mov.u32 	%r497, %r504;
	mov.u32 	%r503, %r506;
	@%p47 bra 	$L__BB0_40;

	setp.eq.s32 	%p48, %r24, %r536;
	mov.u32 	%r497, 0;
	mov.u32 	%r503, %r506;
	@%p48 bra 	$L__BB0_40;

	setp.eq.s32 	%p49, %r24, %r535;
	selp.b32 	%r503, 0, 2, %p49;
	mov.u32 	%r497, %r504;

$L__BB0_40:
	setp.eq.s32 	%p50, %r540, %r537;
	mov.u32 	%r499, %r504;
	@%p50 bra 	$L__BB0_43;

	setp.eq.s32 	%p51, %r540, %r536;
	mov.u32 	%r499, 0;
	@%p51 bra 	$L__BB0_43;

	setp.eq.s32 	%p52, %r540, %r538;
	selp.b32 	%r506, 0, 2, %p52;
	mov.u32 	%r499, %r504;

$L__BB0_43:
	setp.eq.s32 	%p53, %r25, %r537;
	mov.u32 	%r501, %r504;
	mov.u32 	%r502, %r497;
	@%p53 bra 	$L__BB0_46;

	setp.eq.s32 	%p54, %r25, %r536;
	mov.u32 	%r502, 1;
	mov.u32 	%r501, 0;
	@%p54 bra 	$L__BB0_46;

	setp.eq.s32 	%p55, %r25, %r535;
	selp.b32 	%r503, 1, %r503, %p55;
	mov.u32 	%r502, %r497;

$L__BB0_46:
	setp.eq.s32 	%p56, %r28, %r537;
	mov.u32 	%r505, %r499;
	@%p56 bra 	$L__BB0_49;

	setp.eq.s32 	%p57, %r28, %r536;
	mov.u32 	%r505, 1;
	mov.u32 	%r504, 0;
	@%p57 bra 	$L__BB0_49;

	setp.eq.s32 	%p58, %r28, %r538;
	selp.b32 	%r506, 1, %r506, %p58;
	mov.u32 	%r505, %r499;

$L__BB0_49:
	setp.eq.s32 	%p59, %r26, %r537;
	mov.u32 	%r510, 2;
	mov.u32 	%r507, %r510;
	mov.u32 	%r508, %r502;
	@%p59 bra 	$L__BB0_52;

	setp.eq.s32 	%p60, %r26, %r536;
	mov.u32 	%r508, 2;
	mov.u32 	%r507, %r501;
	@%p60 bra 	$L__BB0_52;

	setp.eq.s32 	%p61, %r26, %r535;
	selp.b32 	%r503, 2, %r503, %p61;
	mov.u32 	%r507, %r501;
	mov.u32 	%r508, %r502;

$L__BB0_52:
	setp.eq.s32 	%p62, %r29, %r537;
	mov.u32 	%r511, %r505;
	@%p62 bra 	$L__BB0_55;

	setp.eq.s32 	%p63, %r29, %r536;
	mov.u32 	%r511, 2;
	mov.u32 	%r510, %r504;
	@%p63 bra 	$L__BB0_55;

	setp.eq.s32 	%p64, %r29, %r538;
	selp.b32 	%r506, 2, %r506, %p64;
	mov.u32 	%r510, %r504;
	mov.u32 	%r511, %r505;

$L__BB0_55:
	ld.param.u32 	%r541, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_17];
	ld.param.u64 	%rd389, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_16];
	ld.param.u64 	%rd388, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_15];
	st.local.u32 	[%rd25+8], %r503;
	st.local.u32 	[%rd25+4], %r508;
	st.local.u32 	[%rd25], %r507;
	st.local.u32 	[%rd26+8], %r506;
	st.local.u32 	[%rd26+4], %r511;
	st.local.u32 	[%rd26], %r510;
	mov.u32 	%r539, %r536;
	mov.u32 	%r540, %r537;

$L__BB0_90:
	mul.lo.s32 	%r317, %r537, 3;
	mul.wide.s32 	%rd197, %r317, 8;
	add.s64 	%rd198, %rd30, %rd197;
	ld.global.f64 	%fd1, [%rd198+8];
	ld.global.f64 	%fd2, [%rd198+16];
	mul.lo.s32 	%r318, %r536, 3;
	mul.wide.s32 	%rd200, %r318, 8;
	add.s64 	%rd201, %rd30, %rd200;
	ld.global.f64 	%fd241, [%rd201+8];
	ld.global.f64 	%fd242, [%rd201+16];
	mul.lo.s32 	%r319, %r535, 3;
	mul.wide.s32 	%rd202, %r319, 8;
	add.s64 	%rd203, %rd30, %rd202;
	ld.global.f64 	%fd243, [%rd203];
	ld.global.f64 	%fd244, [%rd203+8];
	ld.global.f64 	%fd245, [%rd203+16];
	mul.lo.s32 	%r320, %r540, 3;
	mul.wide.s32 	%rd204, %r320, 8;
	add.s64 	%rd205, %rd30, %rd204;
	ld.global.f64 	%fd3, [%rd205];
	ld.global.f64 	%fd4, [%rd205+8];
	ld.global.f64 	%fd5, [%rd205+16];
	mul.lo.s32 	%r321, %r539, 3;
	mul.wide.s32 	%rd206, %r321, 8;
	add.s64 	%rd207, %rd30, %rd206;
	ld.global.f64 	%fd246, [%rd207];
	ld.global.f64 	%fd247, [%rd207+8];
	ld.global.f64 	%fd248, [%rd207+16];
	mul.lo.s32 	%r322, %r538, 3;
	mul.wide.s32 	%rd208, %r322, 8;
	add.s64 	%rd209, %rd30, %rd208;
	ld.global.f64 	%fd249, [%rd209];
	ld.global.f64 	%fd250, [%rd209+8];
	ld.global.f64 	%fd251, [%rd209+16];
	ld.global.f64 	%fd252, [%rd201];
	ld.global.f64 	%fd6, [%rd198];
	sub.f64 	%fd253, %fd252, %fd6;
	st.f64 	[%rd37], %fd253;
	sub.f64 	%fd254, %fd241, %fd1;
	st.f64 	[%rd37+8], %fd254;
	sub.f64 	%fd255, %fd242, %fd2;
	st.f64 	[%rd37+16], %fd255;
	sub.f64 	%fd256, %fd243, %fd6;
	st.f64 	[%rd37+24], %fd256;
	sub.f64 	%fd257, %fd244, %fd1;
	mov.u64 	%rd210, 32;
	st.f64 	[%rd37+32], %fd257;
	sub.f64 	%fd258, %fd245, %fd2;
	st.f64 	[%rd37+40], %fd258;
	sub.f64 	%fd259, %fd246, %fd3;
	st.f64 	[%rd38], %fd259;
	sub.f64 	%fd260, %fd247, %fd4;
	st.f64 	[%rd38+8], %fd260;
	sub.f64 	%fd261, %fd248, %fd5;
	st.f64 	[%rd38+16], %fd261;
	sub.f64 	%fd262, %fd249, %fd3;
	st.f64 	[%rd38+24], %fd262;
	sub.f64 	%fd263, %fd250, %fd4;
	st.f64 	[%rd38+32], %fd263;
	sub.f64 	%fd264, %fd251, %fd5;
	st.f64 	[%rd38+40], %fd264;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd155;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 12
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd210;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd48, [retval0+0];
	} // callseq 13
	setp.ne.s64 	%p96, %rd48, 0;
	@%p96 bra 	$L__BB0_92;

	mov.u64 	%rd211, -1;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd211;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd212, [retval0+0];
	} // callseq 14

$L__BB0_92:
	mov.u64 	%rd390, %rd155;

$L__BB0_93:
	shl.b64 	%rd52, %rd390, 1;
	mul.lo.s64 	%rd215, %rd390, 24;
	add.s64 	%rd53, %rd37, %rd215;
	mov.u64 	%rd391, %rd155;

$L__BB0_94:
	add.s64 	%rd216, %rd391, %rd52;
	shl.b64 	%rd217, %rd216, 3;
	add.s64 	%rd218, %rd48, %rd217;
	mul.lo.s64 	%rd219, %rd391, 24;
	add.s64 	%rd220, %rd37, %rd219;
	ld.f64 	%fd265, [%rd53];
	ld.f64 	%fd266, [%rd220];
	ld.f64 	%fd267, [%rd53+8];
	ld.f64 	%fd268, [%rd220+8];
	mul.f64 	%fd269, %fd268, %fd267;
	fma.rn.f64 	%fd270, %fd266, %fd265, %fd269;
	ld.f64 	%fd271, [%rd53+16];
	ld.f64 	%fd272, [%rd220+16];
	fma.rn.f64 	%fd273, %fd272, %fd271, %fd270;
	st.f64 	[%rd218], %fd273;
	add.s64 	%rd391, %rd391, 1;
	setp.lt.u64 	%p97, %rd391, 2;
	@%p97 bra 	$L__BB0_94;

	add.s64 	%rd390, %rd390, 1;
	setp.lt.u64 	%p98, %rd390, 2;
	@%p98 bra 	$L__BB0_93;

	mov.u64 	%rd221, 0;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd221;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 15
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd210;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd57, [retval0+0];
	} // callseq 16
	setp.ne.s64 	%p99, %rd57, 0;
	@%p99 bra 	$L__BB0_98;

	mov.u64 	%rd223, -1;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd223;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd224, [retval0+0];
	} // callseq 17

$L__BB0_98:
	mov.u64 	%rd392, %rd221;

$L__BB0_99:
	shl.b64 	%rd59, %rd392, 1;
	mul.lo.s64 	%rd227, %rd392, 24;
	add.s64 	%rd60, %rd38, %rd227;
	mov.u64 	%rd393, %rd221;

$L__BB0_100:
	add.s64 	%rd228, %rd393, %rd59;
	shl.b64 	%rd229, %rd228, 3;
	add.s64 	%rd230, %rd57, %rd229;
	mul.lo.s64 	%rd231, %rd393, 24;
	add.s64 	%rd232, %rd38, %rd231;
	ld.f64 	%fd274, [%rd60];
	ld.f64 	%fd275, [%rd232];
	ld.f64 	%fd276, [%rd60+8];
	ld.f64 	%fd277, [%rd232+8];
	mul.f64 	%fd278, %fd277, %fd276;
	fma.rn.f64 	%fd279, %fd275, %fd274, %fd278;
	ld.f64 	%fd280, [%rd60+16];
	ld.f64 	%fd281, [%rd232+16];
	fma.rn.f64 	%fd282, %fd281, %fd280, %fd279;
	st.f64 	[%rd230], %fd282;
	add.s64 	%rd393, %rd393, 1;
	setp.lt.u64 	%p100, %rd393, 2;
	@%p100 bra 	$L__BB0_100;

	add.s64 	%rd392, %rd392, 1;
	setp.lt.u64 	%p101, %rd392, 2;
	@%p101 bra 	$L__BB0_99;

	ld.f64 	%fd283, [%rd48+24];
	mov.u64 	%rd233, 0;
	ld.f64 	%fd284, [%rd48];
	mul.f64 	%fd285, %fd284, %fd283;
	ld.f64 	%fd286, [%rd48+8];
	ld.f64 	%fd287, [%rd48+16];
	mul.f64 	%fd288, %fd287, %fd286;
	sub.f64 	%fd7, %fd285, %fd288;
	ld.f64 	%fd289, [%rd57+24];
	ld.f64 	%fd290, [%rd57];
	mul.f64 	%fd291, %fd290, %fd289;
	ld.f64 	%fd292, [%rd57+8];
	ld.f64 	%fd293, [%rd57+16];
	mul.f64 	%fd294, %fd293, %fd292;
	sub.f64 	%fd8, %fd291, %fd294;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd233;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 18
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd210;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd66, [retval0+0];
	} // callseq 19
	setp.ne.s64 	%p102, %rd66, 0;
	@%p102 bra 	$L__BB0_104;

	mov.u64 	%rd235, -1;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd235;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd236, [retval0+0];
	} // callseq 20

$L__BB0_104:
	ld.f64 	%fd295, [%rd48];
	neg.f64 	%fd296, %fd295;
	st.f64 	[%rd66], %fd296;
	ld.f64 	%fd297, [%rd48+8];
	neg.f64 	%fd298, %fd297;
	st.f64 	[%rd66+8], %fd298;
	ld.f64 	%fd299, [%rd48+16];
	neg.f64 	%fd300, %fd299;
	st.f64 	[%rd66+16], %fd300;
	ld.f64 	%fd301, [%rd48+24];
	neg.f64 	%fd302, %fd301;
	st.f64 	[%rd66+24], %fd302;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd233;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 21
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd210;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd68, [retval0+0];
	} // callseq 22
	setp.ne.s64 	%p103, %rd68, 0;
	@%p103 bra 	$L__BB0_106;

	mov.u64 	%rd239, -1;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd239;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd240, [retval0+0];
	} // callseq 23

$L__BB0_106:
	ld.f64 	%fd303, [%rd57];
	neg.f64 	%fd304, %fd303;
	st.f64 	[%rd68], %fd304;
	ld.f64 	%fd305, [%rd57+8];
	neg.f64 	%fd306, %fd305;
	st.f64 	[%rd68+8], %fd306;
	ld.f64 	%fd307, [%rd57+16];
	neg.f64 	%fd308, %fd307;
	st.f64 	[%rd68+16], %fd308;
	ld.f64 	%fd309, [%rd57+24];
	neg.f64 	%fd310, %fd309;
	st.f64 	[%rd68+24], %fd310;
	ld.f64 	%fd311, [%rd48+24];
	st.f64 	[%rd66], %fd311;
	ld.f64 	%fd312, [%rd48];
	st.f64 	[%rd66+24], %fd312;
	ld.f64 	%fd313, [%rd57+24];
	st.f64 	[%rd68], %fd313;
	ld.f64 	%fd314, [%rd57];
	st.f64 	[%rd68+24], %fd314;
	ld.f64 	%fd315, [%rd66];
	div.rn.f64 	%fd316, %fd315, %fd7;
	st.f64 	[%rd66], %fd316;
	ld.f64 	%fd317, [%rd66+8];
	div.rn.f64 	%fd318, %fd317, %fd7;
	st.f64 	[%rd66+8], %fd318;
	ld.f64 	%fd319, [%rd66+16];
	div.rn.f64 	%fd320, %fd319, %fd7;
	st.f64 	[%rd66+16], %fd320;
	ld.f64 	%fd321, [%rd66+24];
	div.rn.f64 	%fd322, %fd321, %fd7;
	st.f64 	[%rd66+24], %fd322;
	ld.f64 	%fd323, [%rd68];
	div.rn.f64 	%fd324, %fd323, %fd8;
	st.f64 	[%rd68], %fd324;
	ld.f64 	%fd325, [%rd68+8];
	div.rn.f64 	%fd326, %fd325, %fd8;
	st.f64 	[%rd68+8], %fd326;
	ld.f64 	%fd327, [%rd68+16];
	div.rn.f64 	%fd328, %fd327, %fd8;
	st.f64 	[%rd68+16], %fd328;
	ld.f64 	%fd329, [%rd68+24];
	div.rn.f64 	%fd330, %fd329, %fd8;
	st.f64 	[%rd68+24], %fd330;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd233;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 24
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd156;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd69, [retval0+0];
	} // callseq 25
	setp.ne.s64 	%p104, %rd69, 0;
	@%p104 bra 	$L__BB0_108;

	mov.u64 	%rd243, -1;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd243;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd244, [retval0+0];
	} // callseq 26

$L__BB0_108:
	mov.u64 	%rd394, %rd233;

$L__BB0_109:
	mul.lo.s64 	%rd71, %rd394, 3;
	shl.b64 	%rd247, %rd394, 4;
	add.s64 	%rd72, %rd66, %rd247;
	mov.u64 	%rd395, %rd233;

$L__BB0_110:
	add.s64 	%rd248, %rd395, %rd71;
	shl.b64 	%rd249, %rd248, 3;
	add.s64 	%rd250, %rd69, %rd249;
	shl.b64 	%rd251, %rd395, 3;
	add.s64 	%rd252, %rd37, %rd251;
	ld.f64 	%fd331, [%rd72];
	ld.f64 	%fd332, [%rd252];
	ld.f64 	%fd333, [%rd72+8];
	ld.f64 	%fd334, [%rd252+24];
	mul.f64 	%fd335, %fd334, %fd333;
	fma.rn.f64 	%fd336, %fd332, %fd331, %fd335;
	st.f64 	[%rd250], %fd336;
	add.s64 	%rd395, %rd395, 1;
	setp.lt.u64 	%p105, %rd395, 3;
	@%p105 bra 	$L__BB0_110;

	add.s64 	%rd394, %rd394, 1;
	setp.lt.u64 	%p106, %rd394, 2;
	@%p106 bra 	$L__BB0_109;

	mov.u64 	%rd253, 0;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd253;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 27
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd156;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd76, [retval0+0];
	} // callseq 28
	setp.ne.s64 	%p107, %rd76, 0;
	@%p107 bra 	$L__BB0_114;

	mov.u64 	%rd255, -1;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd255;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd256, [retval0+0];
	} // callseq 29

$L__BB0_114:
	mov.u64 	%rd396, %rd253;

$L__BB0_115:
	mul.lo.s64 	%rd78, %rd396, 3;
	shl.b64 	%rd259, %rd396, 4;
	add.s64 	%rd79, %rd68, %rd259;
	mov.u64 	%rd397, %rd253;

$L__BB0_116:
	add.s64 	%rd260, %rd397, %rd78;
	shl.b64 	%rd261, %rd260, 3;
	add.s64 	%rd262, %rd76, %rd261;
	shl.b64 	%rd263, %rd397, 3;
	add.s64 	%rd264, %rd38, %rd263;
	ld.f64 	%fd337, [%rd79];
	ld.f64 	%fd338, [%rd264];
	ld.f64 	%fd339, [%rd79+8];
	ld.f64 	%fd340, [%rd264+24];
	mul.f64 	%fd341, %fd340, %fd339;
	fma.rn.f64 	%fd342, %fd338, %fd337, %fd341;
	st.f64 	[%rd262], %fd342;
	add.s64 	%rd397, %rd397, 1;
	setp.lt.u64 	%p108, %rd397, 3;
	@%p108 bra 	$L__BB0_116;

	add.s64 	%rd396, %rd396, 1;
	setp.lt.u64 	%p109, %rd396, 2;
	@%p109 bra 	$L__BB0_115;

	setp.lt.s32 	%p110, %r541, 1;
	@%p110 bra 	$L__BB0_248;

	mov.u32 	%r542, 0;

$L__BB0_120:
	cvta.to.global.u64 	%rd378, %rd388;
	cvta.to.global.u64 	%rd377, %rd389;
	mov.u32 	%r543, 0;
	shl.b32 	%r325, %r542, 2;
	mul.wide.s32 	%rd265, %r325, 8;
	add.s64 	%rd83, %rd377, %rd265;
	mul.wide.s32 	%rd266, %r542, 8;
	add.s64 	%rd84, %rd378, %rd266;

$L__BB0_121:
	mov.u32 	%r544, 0;
	mul.wide.s32 	%rd267, %r543, 4;
	add.s64 	%rd268, %rd25, %rd267;
	ld.local.u32 	%r327, [%rd268];
	add.s32 	%r328, %r327, 1;
	mul.hi.s32 	%r329, %r328, 1431655766;
	shr.u32 	%r330, %r329, 31;
	add.s32 	%r331, %r329, %r330;
	mul.lo.s32 	%r332, %r331, 3;
	sub.s32 	%r333, %r328, %r332;
	add.s32 	%r334, %r333, 1;
	mul.hi.s32 	%r335, %r334, 1431655766;
	shr.u32 	%r336, %r335, 31;
	add.s32 	%r337, %r335, %r336;
	mul.lo.s32 	%r338, %r337, 3;
	sub.s32 	%r339, %r334, %r338;
	mul.wide.s32 	%rd269, %r333, 4;
	add.s64 	%rd270, %rd21, %rd269;
	mul.wide.s32 	%rd271, %r339, 4;
	add.s64 	%rd272, %rd21, %rd271;
	ld.local.u32 	%r340, [%rd272];
	ld.local.u32 	%r341, [%rd270];
	setp.lt.s32 	%p111, %r341, %r340;
	selp.f64 	%fd9, 0d3FF0000000000000, 0dBFF0000000000000, %p111;
	mul.wide.s32 	%rd273, %r327, 4;
	add.s64 	%rd85, %rd23, %rd273;

$L__BB0_122:
	shr.u32 	%r483, %r543, 1;
	cvt.rn.f64.s32 	%fd809, %r483;
	and.b32  	%r482, %r543, 1;
	cvt.rn.f64.s32 	%fd808, %r482;
	mul.wide.s32 	%rd274, %r544, 4;
	add.s64 	%rd275, %rd26, %rd274;
	ld.local.u32 	%r112, [%rd275];
	add.s32 	%r344, %r112, 1;
	mul.hi.s32 	%r345, %r344, 1431655766;
	shr.u32 	%r346, %r345, 31;
	add.s32 	%r347, %r345, %r346;
	mul.lo.s32 	%r348, %r347, 3;
	sub.s32 	%r349, %r344, %r348;
	add.s32 	%r350, %r349, 1;
	mul.hi.s32 	%r351, %r350, 1431655766;
	shr.u32 	%r352, %r351, 31;
	add.s32 	%r353, %r351, %r352;
	mul.lo.s32 	%r354, %r353, 3;
	sub.s32 	%r355, %r350, %r354;
	mul.wide.s32 	%rd276, %r349, 4;
	add.s64 	%rd277, %rd22, %rd276;
	mul.wide.s32 	%rd278, %r355, 4;
	add.s64 	%rd279, %rd22, %rd278;
	ld.local.u32 	%r356, [%rd279];
	ld.local.u32 	%r357, [%rd277];
	setp.lt.s32 	%p112, %r357, %r356;
	selp.f64 	%fd343, 0d3FF0000000000000, 0dBFF0000000000000, %p112;
	ld.global.f64 	%fd344, [%rd83];
	sub.f64 	%fd345, %fd344, %fd808;
	ld.global.f64 	%fd346, [%rd83+8];
	sub.f64 	%fd347, %fd346, %fd809;
	and.b32  	%r358, %r544, 1;
	cvt.rn.f64.s32 	%fd348, %r358;
	ld.global.f64 	%fd349, [%rd83+16];
	sub.f64 	%fd350, %fd349, %fd348;
	shr.u32 	%r359, %r544, 1;
	cvt.rn.f64.s32 	%fd351, %r359;
	ld.global.f64 	%fd352, [%rd83+24];
	sub.f64 	%fd353, %fd352, %fd351;
	ld.f64 	%fd354, [%rd37];
	ld.f64 	%fd355, [%rd37+24];
	mul.f64 	%fd356, %fd347, %fd355;
	fma.rn.f64 	%fd357, %fd345, %fd354, %fd356;
	mul.f64 	%fd12, %fd9, %fd357;
	ld.f64 	%fd358, [%rd37+8];
	ld.f64 	%fd359, [%rd37+32];
	mul.f64 	%fd360, %fd347, %fd359;
	fma.rn.f64 	%fd361, %fd345, %fd358, %fd360;
	mul.f64 	%fd13, %fd9, %fd361;
	ld.f64 	%fd362, [%rd37+16];
	ld.f64 	%fd363, [%rd37+40];
	mul.f64 	%fd364, %fd347, %fd363;
	fma.rn.f64 	%fd365, %fd345, %fd362, %fd364;
	mul.f64 	%fd14, %fd9, %fd365;
	ld.f64 	%fd366, [%rd38];
	ld.f64 	%fd367, [%rd38+24];
	mul.f64 	%fd368, %fd353, %fd367;
	fma.rn.f64 	%fd369, %fd350, %fd366, %fd368;
	mul.f64 	%fd15, %fd343, %fd369;
	ld.f64 	%fd370, [%rd38+8];
	ld.f64 	%fd371, [%rd38+32];
	mul.f64 	%fd372, %fd353, %fd371;
	fma.rn.f64 	%fd373, %fd350, %fd370, %fd372;
	mul.f64 	%fd16, %fd343, %fd373;
	ld.f64 	%fd374, [%rd38+16];
	ld.f64 	%fd375, [%rd38+40];
	mul.f64 	%fd376, %fd353, %fd375;
	fma.rn.f64 	%fd377, %fd350, %fd374, %fd376;
	mul.f64 	%fd17, %fd343, %fd377;
	fma.rn.f64 	%fd378, %fd344, %fd354, %fd6;
	fma.rn.f64 	%fd18, %fd346, %fd355, %fd378;
	fma.rn.f64 	%fd379, %fd344, %fd358, %fd1;
	fma.rn.f64 	%fd19, %fd346, %fd359, %fd379;
	fma.rn.f64 	%fd380, %fd344, %fd362, %fd2;
	fma.rn.f64 	%fd20, %fd346, %fd363, %fd380;
	fma.rn.f64 	%fd381, %fd349, %fd366, %fd3;
	fma.rn.f64 	%fd21, %fd352, %fd367, %fd381;
	fma.rn.f64 	%fd382, %fd349, %fd370, %fd4;
	fma.rn.f64 	%fd22, %fd352, %fd371, %fd382;
	fma.rn.f64 	%fd383, %fd349, %fd374, %fd5;
	fma.rn.f64 	%fd23, %fd352, %fd375, %fd383;
	@%p20 bra 	$L__BB0_245;

	sub.f64 	%fd24, %fd21, %fd18;
	sub.f64 	%fd25, %fd22, %fd19;
	sub.f64 	%fd26, %fd23, %fd20;
	mul.f64 	%fd384, %fd26, %fd26;
	fma.rn.f64 	%fd385, %fd25, %fd25, %fd384;
	fma.rn.f64 	%fd27, %fd24, %fd24, %fd385;
	mul.wide.s32 	%rd280, %r112, 4;
	add.s64 	%rd86, %rd24, %rd280;
	mov.u32 	%r545, 0;

$L__BB0_124:
	ld.param.u64 	%rd379, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_37];
	ld.global.f64 	%fd28, [%rd84];
	shl.b32 	%r365, %r545, 2;
	mul.wide.s32 	%rd285, %r365, 4;
	add.s64 	%rd281, %rd379, %rd285;
	// begin inline asm
	ld.global.nc.s32 %r361, [%rd281];
	// end inline asm
	add.s64 	%rd282, %rd281, 4;
	// begin inline asm
	ld.global.nc.s32 %r362, [%rd282];
	// end inline asm
	add.s64 	%rd283, %rd281, 8;
	// begin inline asm
	ld.global.nc.s32 %r363, [%rd283];
	// end inline asm
	add.s64 	%rd284, %rd281, 12;
	// begin inline asm
	ld.global.nc.s32 %r364, [%rd284];
	// end inline asm
	mov.u64 	%rd286, 0;
	st.local.u64 	[%rd1], %rd286;
	st.local.u64 	[%rd1+8], %rd286;
	st.local.u64 	[%rd1+16], %rd286;
	cvt.rn.f64.s32 	%fd29, %r361;
	mul.f64 	%fd814, %fd18, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r366, %temp}, %fd814;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r546}, %fd814;
	}
	and.b32  	%r367, %r546, 2147483647;
	setp.ne.s32 	%p114, %r367, 2146435072;
	setp.ne.s32 	%p115, %r366, 0;
	or.pred  	%p116, %p115, %p114;
	@%p116 bra 	$L__BB0_126;

	mov.f64 	%fd386, 0d0000000000000000;
	mul.rn.f64 	%fd814, %fd814, %fd386;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r546}, %fd814;
	}

$L__BB0_126:
	mul.f64 	%fd387, %fd814, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r547, %fd387;
	st.local.u32 	[%rd10], %r547;
	cvt.rn.f64.s32 	%fd388, %r547;
	neg.f64 	%fd389, %fd388;
	mov.f64 	%fd390, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd391, %fd389, %fd390, %fd814;
	mov.f64 	%fd392, 0d3C91A62633145C00;
	fma.rn.f64 	%fd393, %fd389, %fd392, %fd391;
	mov.f64 	%fd394, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd389, %fd394, %fd393;
	and.b32  	%r368, %r546, 2145386496;
	setp.lt.u32 	%p117, %r368, 1105199104;
	@%p117 bra 	$L__BB0_128;

	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd814;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 30
	ld.local.u32 	%r547, [%rd10];

$L__BB0_128:
	add.s32 	%r123, %r547, 1;
	and.b32  	%r369, %r123, 1;
	shl.b32 	%r370, %r123, 3;
	and.b32  	%r371, %r370, 8;
	setp.eq.s32 	%p118, %r369, 0;
	selp.f64 	%fd395, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd288, %r371, 8;
	mov.u64 	%rd289, __cudart_sin_cos_coeffs;
	add.s64 	%rd290, %rd289, %rd288;
	ld.global.nc.f64 	%fd396, [%rd290+8];
	mul.rn.f64 	%fd36, %fd815, %fd815;
	fma.rn.f64 	%fd397, %fd395, %fd36, %fd396;
	ld.global.nc.f64 	%fd398, [%rd290+16];
	fma.rn.f64 	%fd399, %fd397, %fd36, %fd398;
	ld.global.nc.f64 	%fd400, [%rd290+24];
	fma.rn.f64 	%fd401, %fd399, %fd36, %fd400;
	ld.global.nc.f64 	%fd402, [%rd290+32];
	fma.rn.f64 	%fd403, %fd401, %fd36, %fd402;
	ld.global.nc.f64 	%fd404, [%rd290+40];
	fma.rn.f64 	%fd405, %fd403, %fd36, %fd404;
	ld.global.nc.f64 	%fd406, [%rd290+48];
	fma.rn.f64 	%fd37, %fd405, %fd36, %fd406;
	fma.rn.f64 	%fd817, %fd37, %fd815, %fd815;
	@%p118 bra 	$L__BB0_130;

	mov.f64 	%fd407, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd37, %fd36, %fd407;

$L__BB0_130:
	and.b32  	%r372, %r123, 2;
	setp.eq.s32 	%p119, %r372, 0;
	@%p119 bra 	$L__BB0_132;

	mov.f64 	%fd408, 0d0000000000000000;
	mov.f64 	%fd409, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd409, %fd408;

$L__BB0_132:
	cvt.rn.f64.s32 	%fd43, %r362;
	mul.f64 	%fd818, %fd19, %fd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r373, %temp}, %fd818;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r548}, %fd818;
	}
	and.b32  	%r374, %r548, 2147483647;
	setp.ne.s32 	%p120, %r374, 2146435072;
	setp.ne.s32 	%p121, %r373, 0;
	or.pred  	%p122, %p121, %p120;
	@%p122 bra 	$L__BB0_134;

	mov.f64 	%fd410, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd818, %fd410;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r548}, %fd818;
	}

$L__BB0_134:
	mul.f64 	%fd411, %fd818, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r549, %fd411;
	st.local.u32 	[%rd10], %r549;
	cvt.rn.f64.s32 	%fd412, %r549;
	neg.f64 	%fd413, %fd412;
	fma.rn.f64 	%fd415, %fd413, %fd390, %fd818;
	fma.rn.f64 	%fd417, %fd413, %fd392, %fd415;
	fma.rn.f64 	%fd819, %fd413, %fd394, %fd417;
	and.b32  	%r375, %r548, 2145386496;
	setp.lt.u32 	%p123, %r375, 1105199104;
	@%p123 bra 	$L__BB0_136;

	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd818;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd819, [retval0+0];
	} // callseq 31
	ld.local.u32 	%r549, [%rd10];

$L__BB0_136:
	add.s32 	%r130, %r549, 1;
	and.b32  	%r376, %r130, 1;
	shl.b32 	%r377, %r130, 3;
	and.b32  	%r378, %r377, 8;
	setp.eq.s32 	%p124, %r376, 0;
	selp.f64 	%fd419, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p124;
	mul.wide.s32 	%rd292, %r378, 8;
	add.s64 	%rd294, %rd289, %rd292;
	ld.global.nc.f64 	%fd420, [%rd294+8];
	mul.rn.f64 	%fd50, %fd819, %fd819;
	fma.rn.f64 	%fd421, %fd419, %fd50, %fd420;
	ld.global.nc.f64 	%fd422, [%rd294+16];
	fma.rn.f64 	%fd423, %fd421, %fd50, %fd422;
	ld.global.nc.f64 	%fd424, [%rd294+24];
	fma.rn.f64 	%fd425, %fd423, %fd50, %fd424;
	ld.global.nc.f64 	%fd426, [%rd294+32];
	fma.rn.f64 	%fd427, %fd425, %fd50, %fd426;
	ld.global.nc.f64 	%fd428, [%rd294+40];
	fma.rn.f64 	%fd429, %fd427, %fd50, %fd428;
	ld.global.nc.f64 	%fd430, [%rd294+48];
	fma.rn.f64 	%fd51, %fd429, %fd50, %fd430;
	fma.rn.f64 	%fd821, %fd51, %fd819, %fd819;
	@%p124 bra 	$L__BB0_138;

	mov.f64 	%fd431, 0d3FF0000000000000;
	fma.rn.f64 	%fd821, %fd51, %fd50, %fd431;

$L__BB0_138:
	and.b32  	%r379, %r130, 2;
	setp.eq.s32 	%p125, %r379, 0;
	@%p125 bra 	$L__BB0_140;

	mov.f64 	%fd432, 0d0000000000000000;
	mov.f64 	%fd433, 0dBFF0000000000000;
	fma.rn.f64 	%fd821, %fd821, %fd433, %fd432;

$L__BB0_140:
	cvt.rn.f64.s32 	%fd57, %r363;
	mul.f64 	%fd822, %fd20, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r380, %temp}, %fd822;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r550}, %fd822;
	}
	and.b32  	%r381, %r550, 2147483647;
	setp.ne.s32 	%p126, %r381, 2146435072;
	setp.ne.s32 	%p127, %r380, 0;
	or.pred  	%p128, %p127, %p126;
	@%p128 bra 	$L__BB0_142;

	mov.f64 	%fd434, 0d0000000000000000;
	mul.rn.f64 	%fd822, %fd822, %fd434;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r550}, %fd822;
	}

$L__BB0_142:
	mul.f64 	%fd435, %fd822, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r551, %fd435;
	st.local.u32 	[%rd10], %r551;
	cvt.rn.f64.s32 	%fd436, %r551;
	neg.f64 	%fd437, %fd436;
	fma.rn.f64 	%fd439, %fd437, %fd390, %fd822;
	fma.rn.f64 	%fd441, %fd437, %fd392, %fd439;
	fma.rn.f64 	%fd823, %fd437, %fd394, %fd441;
	and.b32  	%r382, %r550, 2145386496;
	setp.lt.u32 	%p129, %r382, 1105199104;
	mul.f64 	%fd62, %fd817, %fd821;
	@%p129 bra 	$L__BB0_144;

	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd822;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 32
	ld.local.u32 	%r551, [%rd10];

$L__BB0_144:
	add.s32 	%r137, %r551, 1;
	and.b32  	%r383, %r137, 1;
	shl.b32 	%r384, %r137, 3;
	and.b32  	%r385, %r384, 8;
	setp.eq.s32 	%p130, %r383, 0;
	selp.f64 	%fd443, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p130;
	mul.wide.s32 	%rd296, %r385, 8;
	add.s64 	%rd298, %rd289, %rd296;
	ld.global.nc.f64 	%fd444, [%rd298+8];
	mul.rn.f64 	%fd65, %fd823, %fd823;
	fma.rn.f64 	%fd445, %fd443, %fd65, %fd444;
	ld.global.nc.f64 	%fd446, [%rd298+16];
	fma.rn.f64 	%fd447, %fd445, %fd65, %fd446;
	ld.global.nc.f64 	%fd448, [%rd298+24];
	fma.rn.f64 	%fd449, %fd447, %fd65, %fd448;
	ld.global.nc.f64 	%fd450, [%rd298+32];
	fma.rn.f64 	%fd451, %fd449, %fd65, %fd450;
	ld.global.nc.f64 	%fd452, [%rd298+40];
	fma.rn.f64 	%fd453, %fd451, %fd65, %fd452;
	ld.global.nc.f64 	%fd454, [%rd298+48];
	fma.rn.f64 	%fd66, %fd453, %fd65, %fd454;
	fma.rn.f64 	%fd825, %fd66, %fd823, %fd823;
	@%p130 bra 	$L__BB0_146;

	mov.f64 	%fd455, 0d3FF0000000000000;
	fma.rn.f64 	%fd825, %fd66, %fd65, %fd455;

$L__BB0_146:
	and.b32  	%r386, %r137, 2;
	setp.eq.s32 	%p131, %r386, 0;
	@%p131 bra 	$L__BB0_148;

	mov.f64 	%fd456, 0d0000000000000000;
	mov.f64 	%fd457, 0dBFF0000000000000;
	fma.rn.f64 	%fd825, %fd825, %fd457, %fd456;

$L__BB0_148:
	mov.u64 	%rd380, 0;
	cvt.s64.s32 	%rd89, %r364;
	mul.wide.s32 	%rd299, %r364, 8;
	add.s64 	%rd300, %rd1, %rd299;
	mul.f64 	%fd458, %fd62, %fd825;
	st.local.f64 	[%rd300], %fd458;
	st.local.u64 	[%rd17], %rd380;
	st.local.u64 	[%rd17+8], %rd380;
	st.local.u64 	[%rd17+16], %rd380;
	mul.f64 	%fd826, %fd21, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r387, %temp}, %fd826;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r552}, %fd826;
	}
	and.b32  	%r388, %r552, 2147483647;
	setp.ne.s32 	%p132, %r388, 2146435072;
	setp.ne.s32 	%p133, %r387, 0;
	or.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB0_150;

	mov.f64 	%fd459, 0d0000000000000000;
	mul.rn.f64 	%fd826, %fd826, %fd459;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r552}, %fd826;
	}

$L__BB0_150:
	mul.f64 	%fd460, %fd826, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r553, %fd460;
	st.local.u32 	[%rd10], %r553;
	cvt.rn.f64.s32 	%fd461, %r553;
	neg.f64 	%fd462, %fd461;
	fma.rn.f64 	%fd464, %fd462, %fd390, %fd826;
	fma.rn.f64 	%fd466, %fd462, %fd392, %fd464;
	fma.rn.f64 	%fd827, %fd462, %fd394, %fd466;
	and.b32  	%r389, %r552, 2145386496;
	setp.lt.u32 	%p135, %r389, 1105199104;
	@%p135 bra 	$L__BB0_152;

	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd826;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd827, [retval0+0];
	} // callseq 33
	ld.local.u32 	%r553, [%rd10];

$L__BB0_152:
	add.s32 	%r144, %r553, 1;
	and.b32  	%r390, %r144, 1;
	shl.b32 	%r391, %r144, 3;
	and.b32  	%r392, %r391, 8;
	setp.eq.s32 	%p136, %r390, 0;
	selp.f64 	%fd468, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd303, %r392, 8;
	add.s64 	%rd305, %rd289, %rd303;
	ld.global.nc.f64 	%fd469, [%rd305+8];
	mul.rn.f64 	%fd78, %fd827, %fd827;
	fma.rn.f64 	%fd470, %fd468, %fd78, %fd469;
	ld.global.nc.f64 	%fd471, [%rd305+16];
	fma.rn.f64 	%fd472, %fd470, %fd78, %fd471;
	ld.global.nc.f64 	%fd473, [%rd305+24];
	fma.rn.f64 	%fd474, %fd472, %fd78, %fd473;
	ld.global.nc.f64 	%fd475, [%rd305+32];
	fma.rn.f64 	%fd476, %fd474, %fd78, %fd475;
	ld.global.nc.f64 	%fd477, [%rd305+40];
	fma.rn.f64 	%fd478, %fd476, %fd78, %fd477;
	ld.global.nc.f64 	%fd479, [%rd305+48];
	fma.rn.f64 	%fd79, %fd478, %fd78, %fd479;
	fma.rn.f64 	%fd829, %fd79, %fd827, %fd827;
	@%p136 bra 	$L__BB0_154;

	mov.f64 	%fd480, 0d3FF0000000000000;
	fma.rn.f64 	%fd829, %fd79, %fd78, %fd480;

$L__BB0_154:
	and.b32  	%r393, %r144, 2;
	setp.eq.s32 	%p137, %r393, 0;
	@%p137 bra 	$L__BB0_156;

	mov.f64 	%fd481, 0d0000000000000000;
	mov.f64 	%fd482, 0dBFF0000000000000;
	fma.rn.f64 	%fd829, %fd829, %fd482, %fd481;

$L__BB0_156:
	mul.f64 	%fd830, %fd22, %fd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r394, %temp}, %fd830;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r554}, %fd830;
	}
	and.b32  	%r395, %r554, 2147483647;
	setp.ne.s32 	%p138, %r395, 2146435072;
	setp.ne.s32 	%p139, %r394, 0;
	or.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB0_158;

	mov.f64 	%fd483, 0d0000000000000000;
	mul.rn.f64 	%fd830, %fd830, %fd483;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r554}, %fd830;
	}

$L__BB0_158:
	mul.f64 	%fd484, %fd830, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r555, %fd484;
	st.local.u32 	[%rd10], %r555;
	cvt.rn.f64.s32 	%fd485, %r555;
	neg.f64 	%fd486, %fd485;
	fma.rn.f64 	%fd488, %fd486, %fd390, %fd830;
	fma.rn.f64 	%fd490, %fd486, %fd392, %fd488;
	fma.rn.f64 	%fd831, %fd486, %fd394, %fd490;
	and.b32  	%r396, %r554, 2145386496;
	setp.lt.u32 	%p141, %r396, 1105199104;
	@%p141 bra 	$L__BB0_160;

	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd830;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd831, [retval0+0];
	} // callseq 34
	ld.local.u32 	%r555, [%rd10];

$L__BB0_160:
	add.s32 	%r151, %r555, 1;
	and.b32  	%r397, %r151, 1;
	shl.b32 	%r398, %r151, 3;
	and.b32  	%r399, %r398, 8;
	setp.eq.s32 	%p142, %r397, 0;
	selp.f64 	%fd492, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd307, %r399, 8;
	add.s64 	%rd309, %rd289, %rd307;
	ld.global.nc.f64 	%fd493, [%rd309+8];
	mul.rn.f64 	%fd91, %fd831, %fd831;
	fma.rn.f64 	%fd494, %fd492, %fd91, %fd493;
	ld.global.nc.f64 	%fd495, [%rd309+16];
	fma.rn.f64 	%fd496, %fd494, %fd91, %fd495;
	ld.global.nc.f64 	%fd497, [%rd309+24];
	fma.rn.f64 	%fd498, %fd496, %fd91, %fd497;
	ld.global.nc.f64 	%fd499, [%rd309+32];
	fma.rn.f64 	%fd500, %fd498, %fd91, %fd499;
	ld.global.nc.f64 	%fd501, [%rd309+40];
	fma.rn.f64 	%fd502, %fd500, %fd91, %fd501;
	ld.global.nc.f64 	%fd503, [%rd309+48];
	fma.rn.f64 	%fd92, %fd502, %fd91, %fd503;
	fma.rn.f64 	%fd833, %fd92, %fd831, %fd831;
	@%p142 bra 	$L__BB0_162;

	mov.f64 	%fd504, 0d3FF0000000000000;
	fma.rn.f64 	%fd833, %fd92, %fd91, %fd504;

$L__BB0_162:
	and.b32  	%r400, %r151, 2;
	setp.eq.s32 	%p143, %r400, 0;
	@%p143 bra 	$L__BB0_164;

	mov.f64 	%fd505, 0d0000000000000000;
	mov.f64 	%fd506, 0dBFF0000000000000;
	fma.rn.f64 	%fd833, %fd833, %fd506, %fd505;

$L__BB0_164:
	mul.f64 	%fd834, %fd23, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r401, %temp}, %fd834;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r556}, %fd834;
	}
	and.b32  	%r402, %r556, 2147483647;
	setp.ne.s32 	%p144, %r402, 2146435072;
	setp.ne.s32 	%p145, %r401, 0;
	or.pred  	%p146, %p145, %p144;
	@%p146 bra 	$L__BB0_166;

	mov.f64 	%fd507, 0d0000000000000000;
	mul.rn.f64 	%fd834, %fd834, %fd507;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r556}, %fd834;
	}

$L__BB0_166:
	mul.f64 	%fd508, %fd834, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r557, %fd508;
	st.local.u32 	[%rd10], %r557;
	cvt.rn.f64.s32 	%fd509, %r557;
	neg.f64 	%fd510, %fd509;
	fma.rn.f64 	%fd512, %fd510, %fd390, %fd834;
	fma.rn.f64 	%fd514, %fd510, %fd392, %fd512;
	fma.rn.f64 	%fd835, %fd510, %fd394, %fd514;
	and.b32  	%r403, %r556, 2145386496;
	setp.lt.u32 	%p147, %r403, 1105199104;
	mul.f64 	%fd102, %fd829, %fd833;
	@%p147 bra 	$L__BB0_168;

	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd834;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd835, [retval0+0];
	} // callseq 35
	ld.local.u32 	%r557, [%rd10];

$L__BB0_168:
	add.s32 	%r158, %r557, 1;
	and.b32  	%r404, %r158, 1;
	shl.b32 	%r405, %r158, 3;
	and.b32  	%r406, %r405, 8;
	setp.eq.s32 	%p148, %r404, 0;
	selp.f64 	%fd516, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p148;
	mul.wide.s32 	%rd311, %r406, 8;
	add.s64 	%rd313, %rd289, %rd311;
	ld.global.nc.f64 	%fd517, [%rd313+8];
	mul.rn.f64 	%fd105, %fd835, %fd835;
	fma.rn.f64 	%fd518, %fd516, %fd105, %fd517;
	ld.global.nc.f64 	%fd519, [%rd313+16];
	fma.rn.f64 	%fd520, %fd518, %fd105, %fd519;
	ld.global.nc.f64 	%fd521, [%rd313+24];
	fma.rn.f64 	%fd522, %fd520, %fd105, %fd521;
	ld.global.nc.f64 	%fd523, [%rd313+32];
	fma.rn.f64 	%fd524, %fd522, %fd105, %fd523;
	ld.global.nc.f64 	%fd525, [%rd313+40];
	fma.rn.f64 	%fd526, %fd524, %fd105, %fd525;
	ld.global.nc.f64 	%fd527, [%rd313+48];
	fma.rn.f64 	%fd106, %fd526, %fd105, %fd527;
	fma.rn.f64 	%fd837, %fd106, %fd835, %fd835;
	@%p148 bra 	$L__BB0_170;

	mov.f64 	%fd528, 0d3FF0000000000000;
	fma.rn.f64 	%fd837, %fd106, %fd105, %fd528;

$L__BB0_170:
	and.b32  	%r407, %r158, 2;
	setp.eq.s32 	%p149, %r407, 0;
	@%p149 bra 	$L__BB0_172;

	mov.f64 	%fd529, 0d0000000000000000;
	mov.f64 	%fd530, 0dBFF0000000000000;
	fma.rn.f64 	%fd837, %fd837, %fd530, %fd529;

$L__BB0_172:
	shl.b32 	%r484, %r545, 2;
	mul.wide.s32 	%rd387, %r484, 4;
	ld.param.u64 	%rd386, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_37];
	add.s64 	%rd385, %rd386, %rd387;
	add.s64 	%rd384, %rd385, 12;
	add.s64 	%rd383, %rd385, 8;
	add.s64 	%rd382, %rd385, 4;
	mov.u64 	%rd381, 0;
	sub.f64 	%fd812, %fd21, %fd18;
	sub.f64 	%fd811, %fd22, %fd19;
	sub.f64 	%fd810, %fd23, %fd20;
	sqrt.rn.f64 	%fd531, %fd27;
	shl.b64 	%rd318, %rd89, 3;
	add.s64 	%rd319, %rd17, %rd318;
	mul.f64 	%fd532, %fd102, %fd837;
	st.local.f64 	[%rd319], %fd532;
	ld.local.f64 	%fd533, [%rd17];
	ld.local.f64 	%fd534, [%rd1];
	sub.f64 	%fd535, %fd534, %fd533;
	ld.local.f64 	%fd536, [%rd17+8];
	ld.local.f64 	%fd537, [%rd1+8];
	sub.f64 	%fd538, %fd537, %fd536;
	ld.local.f64 	%fd539, [%rd17+16];
	ld.local.f64 	%fd540, [%rd1+16];
	sub.f64 	%fd541, %fd540, %fd539;
	mul.f64 	%fd542, %fd810, %fd541;
	fma.rn.f64 	%fd543, %fd811, %fd538, %fd542;
	fma.rn.f64 	%fd544, %fd812, %fd535, %fd543;
	div.rn.f64 	%fd545, %fd544, 0d402921FB54442D18;
	mul.f64 	%fd546, %fd531, %fd531;
	mul.f64 	%fd547, %fd531, %fd546;
	div.rn.f64 	%fd548, %fd545, %fd547;
	mul.f64 	%fd549, %fd28, %fd548;
	mul.f64 	%fd550, %fd17, %fd14;
	fma.rn.f64 	%fd551, %fd16, %fd13, %fd550;
	fma.rn.f64 	%fd552, %fd15, %fd12, %fd551;
	mul.f64 	%fd112, %fd549, %fd552;
	mov.f64 	%fd553, 0d3FB45F306DC9C883;
	div.rn.f64 	%fd554, %fd553, %fd531;
	ld.global.f64 	%fd555, [%rd84];
	mul.f64 	%fd113, %fd555, %fd554;
	// begin inline asm
	ld.global.nc.s32 %r408, [%rd385];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r409, [%rd382];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r410, [%rd383];
	// end inline asm
	// begin inline asm
	ld.global.nc.s32 %r411, [%rd384];
	// end inline asm
	st.local.u64 	[%rd27], %rd381;
	st.local.u64 	[%rd27+8], %rd381;
	st.local.u64 	[%rd27+16], %rd381;
	st.local.u64 	[%rd27+24], %rd381;
	st.local.u64 	[%rd27+32], %rd381;
	st.local.u64 	[%rd27+40], %rd381;
	st.local.u64 	[%rd27+48], %rd381;
	st.local.u64 	[%rd27+56], %rd381;
	st.local.u64 	[%rd27+64], %rd381;
	cvt.rn.f64.s32 	%fd114, %r408;
	mul.f64 	%fd862, %fd21, %fd114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r412, %temp}, %fd862;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r570}, %fd862;
	}
	and.b32  	%r413, %r570, 2147483647;
	setp.eq.s32 	%p150, %r413, 2146435072;
	setp.eq.s32 	%p151, %r412, 0;
	and.pred  	%p17, %p151, %p150;
	not.pred 	%p152, %p17;
	mov.u32 	%r558, %r570;
	mov.f64 	%fd838, %fd862;
	@%p152 bra 	$L__BB0_174;

	mov.f64 	%fd556, 0d0000000000000000;
	mul.rn.f64 	%fd838, %fd862, %fd556;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r558}, %fd838;
	}

$L__BB0_174:
	mul.f64 	%fd557, %fd838, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r559, %fd557;
	st.local.u32 	[%rd1], %r559;
	cvt.rn.f64.s32 	%fd558, %r559;
	neg.f64 	%fd559, %fd558;
	fma.rn.f64 	%fd561, %fd559, %fd390, %fd838;
	fma.rn.f64 	%fd563, %fd559, %fd392, %fd561;
	fma.rn.f64 	%fd839, %fd559, %fd394, %fd563;
	and.b32  	%r414, %r558, 2145386496;
	setp.lt.u32 	%p153, %r414, 1105199104;
	@%p153 bra 	$L__BB0_176;

	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd838;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd839, [retval0+0];
	} // callseq 36
	ld.local.u32 	%r559, [%rd1];

$L__BB0_176:
	and.b32  	%r415, %r559, 1;
	shl.b32 	%r416, %r559, 3;
	and.b32  	%r417, %r416, 8;
	setp.eq.s32 	%p154, %r415, 0;
	selp.f64 	%fd565, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p154;
	mul.wide.s32 	%rd322, %r417, 8;
	add.s64 	%rd324, %rd289, %rd322;
	ld.global.nc.f64 	%fd566, [%rd324+8];
	mul.rn.f64 	%fd121, %fd839, %fd839;
	fma.rn.f64 	%fd567, %fd565, %fd121, %fd566;
	ld.global.nc.f64 	%fd568, [%rd324+16];
	fma.rn.f64 	%fd569, %fd567, %fd121, %fd568;
	ld.global.nc.f64 	%fd570, [%rd324+24];
	fma.rn.f64 	%fd571, %fd569, %fd121, %fd570;
	ld.global.nc.f64 	%fd572, [%rd324+32];
	fma.rn.f64 	%fd573, %fd571, %fd121, %fd572;
	ld.global.nc.f64 	%fd574, [%rd324+40];
	fma.rn.f64 	%fd575, %fd573, %fd121, %fd574;
	ld.global.nc.f64 	%fd576, [%rd324+48];
	fma.rn.f64 	%fd122, %fd575, %fd121, %fd576;
	fma.rn.f64 	%fd841, %fd122, %fd839, %fd839;
	@%p154 bra 	$L__BB0_178;

	mov.f64 	%fd577, 0d3FF0000000000000;
	fma.rn.f64 	%fd841, %fd122, %fd121, %fd577;

$L__BB0_178:
	and.b32  	%r418, %r559, 2;
	setp.eq.s32 	%p155, %r418, 0;
	@%p155 bra 	$L__BB0_180;

	mov.f64 	%fd578, 0d0000000000000000;
	mov.f64 	%fd579, 0dBFF0000000000000;
	fma.rn.f64 	%fd841, %fd841, %fd579, %fd578;

$L__BB0_180:
	cvt.rn.f64.s32 	%fd813, %r408;
	mul.f64 	%fd128, %fd841, %fd813;
	cvt.rn.f64.s32 	%fd129, %r409;
	mul.f64 	%fd866, %fd22, %fd129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r419, %temp}, %fd866;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r572}, %fd866;
	}
	and.b32  	%r420, %r572, 2147483647;
	setp.eq.s32 	%p156, %r420, 2146435072;
	setp.eq.s32 	%p157, %r419, 0;
	and.pred  	%p18, %p157, %p156;
	not.pred 	%p158, %p18;
	mov.u32 	%r560, %r572;
	mov.f64 	%fd842, %fd866;
	@%p158 bra 	$L__BB0_182;

	mov.f64 	%fd580, 0d0000000000000000;
	mul.rn.f64 	%fd842, %fd866, %fd580;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r560}, %fd842;
	}

$L__BB0_182:
	mul.f64 	%fd581, %fd842, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r561, %fd581;
	st.local.u32 	[%rd1], %r561;
	cvt.rn.f64.s32 	%fd582, %r561;
	neg.f64 	%fd583, %fd582;
	fma.rn.f64 	%fd585, %fd583, %fd390, %fd842;
	fma.rn.f64 	%fd587, %fd583, %fd392, %fd585;
	fma.rn.f64 	%fd843, %fd583, %fd394, %fd587;
	and.b32  	%r421, %r560, 2145386496;
	setp.lt.u32 	%p159, %r421, 1105199104;
	@%p159 bra 	$L__BB0_184;

	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd842;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd843, [retval0+0];
	} // callseq 37
	ld.local.u32 	%r561, [%rd1];

$L__BB0_184:
	add.s32 	%r174, %r561, 1;
	and.b32  	%r422, %r174, 1;
	shl.b32 	%r423, %r174, 3;
	and.b32  	%r424, %r423, 8;
	setp.eq.s32 	%p160, %r422, 0;
	selp.f64 	%fd589, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p160;
	mul.wide.s32 	%rd326, %r424, 8;
	add.s64 	%rd328, %rd289, %rd326;
	ld.global.nc.f64 	%fd590, [%rd328+8];
	mul.rn.f64 	%fd136, %fd843, %fd843;
	fma.rn.f64 	%fd591, %fd589, %fd136, %fd590;
	ld.global.nc.f64 	%fd592, [%rd328+16];
	fma.rn.f64 	%fd593, %fd591, %fd136, %fd592;
	ld.global.nc.f64 	%fd594, [%rd328+24];
	fma.rn.f64 	%fd595, %fd593, %fd136, %fd594;
	ld.global.nc.f64 	%fd596, [%rd328+32];
	fma.rn.f64 	%fd597, %fd595, %fd136, %fd596;
	ld.global.nc.f64 	%fd598, [%rd328+40];
	fma.rn.f64 	%fd599, %fd597, %fd136, %fd598;
	ld.global.nc.f64 	%fd600, [%rd328+48];
	fma.rn.f64 	%fd137, %fd599, %fd136, %fd600;
	fma.rn.f64 	%fd845, %fd137, %fd843, %fd843;
	@%p160 bra 	$L__BB0_186;

	mov.f64 	%fd601, 0d3FF0000000000000;
	fma.rn.f64 	%fd845, %fd137, %fd136, %fd601;

$L__BB0_186:
	and.b32  	%r425, %r174, 2;
	setp.eq.s32 	%p161, %r425, 0;
	@%p161 bra 	$L__BB0_188;

	mov.f64 	%fd602, 0d0000000000000000;
	mov.f64 	%fd603, 0dBFF0000000000000;
	fma.rn.f64 	%fd845, %fd845, %fd603, %fd602;

$L__BB0_188:
	mul.f64 	%fd143, %fd128, %fd845;
	cvt.rn.f64.s32 	%fd144, %r410;
	mul.f64 	%fd870, %fd23, %fd144;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r426, %temp}, %fd870;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r574}, %fd870;
	}
	and.b32  	%r427, %r574, 2147483647;
	setp.eq.s32 	%p162, %r427, 2146435072;
	setp.eq.s32 	%p163, %r426, 0;
	and.pred  	%p19, %p163, %p162;
	not.pred 	%p164, %p19;
	mov.u32 	%r562, %r574;
	mov.f64 	%fd846, %fd870;
	@%p164 bra 	$L__BB0_190;

	mov.f64 	%fd604, 0d0000000000000000;
	mul.rn.f64 	%fd846, %fd870, %fd604;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r562}, %fd846;
	}

$L__BB0_190:
	mul.f64 	%fd605, %fd846, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r563, %fd605;
	st.local.u32 	[%rd1], %r563;
	cvt.rn.f64.s32 	%fd606, %r563;
	neg.f64 	%fd607, %fd606;
	fma.rn.f64 	%fd609, %fd607, %fd390, %fd846;
	fma.rn.f64 	%fd611, %fd607, %fd392, %fd609;
	fma.rn.f64 	%fd847, %fd607, %fd394, %fd611;
	and.b32  	%r428, %r562, 2145386496;
	setp.lt.u32 	%p165, %r428, 1105199104;
	@%p165 bra 	$L__BB0_192;

	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd846;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd847, [retval0+0];
	} // callseq 38
	ld.local.u32 	%r563, [%rd1];

$L__BB0_192:
	add.s32 	%r181, %r563, 1;
	and.b32  	%r429, %r181, 1;
	shl.b32 	%r430, %r181, 3;
	and.b32  	%r431, %r430, 8;
	setp.eq.s32 	%p166, %r429, 0;
	selp.f64 	%fd613, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p166;
	mul.wide.s32 	%rd330, %r431, 8;
	add.s64 	%rd332, %rd289, %rd330;
	ld.global.nc.f64 	%fd614, [%rd332+8];
	mul.rn.f64 	%fd151, %fd847, %fd847;
	fma.rn.f64 	%fd615, %fd613, %fd151, %fd614;
	ld.global.nc.f64 	%fd616, [%rd332+16];
	fma.rn.f64 	%fd617, %fd615, %fd151, %fd616;
	ld.global.nc.f64 	%fd618, [%rd332+24];
	fma.rn.f64 	%fd619, %fd617, %fd151, %fd618;
	ld.global.nc.f64 	%fd620, [%rd332+32];
	fma.rn.f64 	%fd621, %fd619, %fd151, %fd620;
	ld.global.nc.f64 	%fd622, [%rd332+40];
	fma.rn.f64 	%fd623, %fd621, %fd151, %fd622;
	ld.global.nc.f64 	%fd624, [%rd332+48];
	fma.rn.f64 	%fd152, %fd623, %fd151, %fd624;
	fma.rn.f64 	%fd849, %fd152, %fd847, %fd847;
	@%p166 bra 	$L__BB0_194;

	mov.f64 	%fd625, 0d3FF0000000000000;
	fma.rn.f64 	%fd849, %fd152, %fd151, %fd625;

$L__BB0_194:
	and.b32  	%r432, %r181, 2;
	setp.eq.s32 	%p167, %r432, 0;
	@%p167 bra 	$L__BB0_196;

	mov.f64 	%fd626, 0d0000000000000000;
	mov.f64 	%fd627, 0dBFF0000000000000;
	fma.rn.f64 	%fd849, %fd849, %fd627, %fd626;

$L__BB0_196:
	mul.f64 	%fd158, %fd143, %fd849;
	mov.u32 	%r564, %r570;
	mov.f64 	%fd850, %fd862;
	@%p152 bra 	$L__BB0_198;

	mov.f64 	%fd628, 0d0000000000000000;
	mul.rn.f64 	%fd850, %fd862, %fd628;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r564}, %fd850;
	}

$L__BB0_198:
	mul.f64 	%fd629, %fd850, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r565, %fd629;
	st.local.u32 	[%rd1], %r565;
	cvt.rn.f64.s32 	%fd630, %r565;
	neg.f64 	%fd631, %fd630;
	fma.rn.f64 	%fd633, %fd631, %fd390, %fd850;
	fma.rn.f64 	%fd635, %fd631, %fd392, %fd633;
	fma.rn.f64 	%fd851, %fd631, %fd394, %fd635;
	and.b32  	%r433, %r564, 2145386496;
	setp.lt.u32 	%p169, %r433, 1105199104;
	@%p169 bra 	$L__BB0_200;

	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd850;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd851, [retval0+0];
	} // callseq 39
	ld.local.u32 	%r565, [%rd1];

$L__BB0_200:
	add.s32 	%r187, %r565, 1;
	and.b32  	%r434, %r187, 1;
	shl.b32 	%r435, %r187, 3;
	and.b32  	%r436, %r435, 8;
	setp.eq.s32 	%p170, %r434, 0;
	selp.f64 	%fd637, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p170;
	mul.wide.s32 	%rd334, %r436, 8;
	add.s64 	%rd336, %rd289, %rd334;
	ld.global.nc.f64 	%fd638, [%rd336+8];
	mul.rn.f64 	%fd164, %fd851, %fd851;
	fma.rn.f64 	%fd639, %fd637, %fd164, %fd638;
	ld.global.nc.f64 	%fd640, [%rd336+16];
	fma.rn.f64 	%fd641, %fd639, %fd164, %fd640;
	ld.global.nc.f64 	%fd642, [%rd336+24];
	fma.rn.f64 	%fd643, %fd641, %fd164, %fd642;
	ld.global.nc.f64 	%fd644, [%rd336+32];
	fma.rn.f64 	%fd645, %fd643, %fd164, %fd644;
	ld.global.nc.f64 	%fd646, [%rd336+40];
	fma.rn.f64 	%fd647, %fd645, %fd164, %fd646;
	ld.global.nc.f64 	%fd648, [%rd336+48];
	fma.rn.f64 	%fd165, %fd647, %fd164, %fd648;
	fma.rn.f64 	%fd853, %fd165, %fd851, %fd851;
	@%p170 bra 	$L__BB0_202;

	mov.f64 	%fd649, 0d3FF0000000000000;
	fma.rn.f64 	%fd853, %fd165, %fd164, %fd649;

$L__BB0_202:
	and.b32  	%r437, %r187, 2;
	setp.eq.s32 	%p171, %r437, 0;
	@%p171 bra 	$L__BB0_204;

	mov.f64 	%fd650, 0d0000000000000000;
	mov.f64 	%fd651, 0dBFF0000000000000;
	fma.rn.f64 	%fd853, %fd853, %fd651, %fd650;

$L__BB0_204:
	cvt.rn.f64.s32 	%fd806, %r409;
	mul.f64 	%fd171, %fd853, %fd806;
	mov.u32 	%r566, %r572;
	mov.f64 	%fd854, %fd866;
	@%p158 bra 	$L__BB0_206;

	mov.f64 	%fd652, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd866, %fd652;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r566}, %fd854;
	}

$L__BB0_206:
	mul.f64 	%fd653, %fd854, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r567, %fd653;
	st.local.u32 	[%rd1], %r567;
	cvt.rn.f64.s32 	%fd654, %r567;
	neg.f64 	%fd655, %fd654;
	fma.rn.f64 	%fd657, %fd655, %fd390, %fd854;
	fma.rn.f64 	%fd659, %fd655, %fd392, %fd657;
	fma.rn.f64 	%fd855, %fd655, %fd394, %fd659;
	and.b32  	%r438, %r566, 2145386496;
	setp.lt.u32 	%p173, %r438, 1105199104;
	@%p173 bra 	$L__BB0_208;

	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd854;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd855, [retval0+0];
	} // callseq 40
	ld.local.u32 	%r567, [%rd1];

$L__BB0_208:
	and.b32  	%r439, %r567, 1;
	shl.b32 	%r440, %r567, 3;
	and.b32  	%r441, %r440, 8;
	setp.eq.s32 	%p174, %r439, 0;
	selp.f64 	%fd661, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p174;
	mul.wide.s32 	%rd338, %r441, 8;
	add.s64 	%rd340, %rd289, %rd338;
	ld.global.nc.f64 	%fd662, [%rd340+8];
	mul.rn.f64 	%fd177, %fd855, %fd855;
	fma.rn.f64 	%fd663, %fd661, %fd177, %fd662;
	ld.global.nc.f64 	%fd664, [%rd340+16];
	fma.rn.f64 	%fd665, %fd663, %fd177, %fd664;
	ld.global.nc.f64 	%fd666, [%rd340+24];
	fma.rn.f64 	%fd667, %fd665, %fd177, %fd666;
	ld.global.nc.f64 	%fd668, [%rd340+32];
	fma.rn.f64 	%fd669, %fd667, %fd177, %fd668;
	ld.global.nc.f64 	%fd670, [%rd340+40];
	fma.rn.f64 	%fd671, %fd669, %fd177, %fd670;
	ld.global.nc.f64 	%fd672, [%rd340+48];
	fma.rn.f64 	%fd178, %fd671, %fd177, %fd672;
	fma.rn.f64 	%fd857, %fd178, %fd855, %fd855;
	@%p174 bra 	$L__BB0_210;

	mov.f64 	%fd673, 0d3FF0000000000000;
	fma.rn.f64 	%fd857, %fd178, %fd177, %fd673;

$L__BB0_210:
	and.b32  	%r442, %r567, 2;
	setp.eq.s32 	%p175, %r442, 0;
	@%p175 bra 	$L__BB0_212;

	mov.f64 	%fd674, 0d0000000000000000;
	mov.f64 	%fd675, 0dBFF0000000000000;
	fma.rn.f64 	%fd857, %fd857, %fd675, %fd674;

$L__BB0_212:
	mul.f64 	%fd184, %fd171, %fd857;
	mov.u32 	%r568, %r574;
	mov.f64 	%fd858, %fd870;
	@%p164 bra 	$L__BB0_214;

	mov.f64 	%fd676, 0d0000000000000000;
	mul.rn.f64 	%fd858, %fd870, %fd676;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r568}, %fd858;
	}

$L__BB0_214:
	mul.f64 	%fd677, %fd858, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r569, %fd677;
	st.local.u32 	[%rd1], %r569;
	cvt.rn.f64.s32 	%fd678, %r569;
	neg.f64 	%fd679, %fd678;
	fma.rn.f64 	%fd681, %fd679, %fd390, %fd858;
	fma.rn.f64 	%fd683, %fd679, %fd392, %fd681;
	fma.rn.f64 	%fd859, %fd679, %fd394, %fd683;
	and.b32  	%r443, %r568, 2145386496;
	setp.lt.u32 	%p177, %r443, 1105199104;
	@%p177 bra 	$L__BB0_216;

	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd858;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd859, [retval0+0];
	} // callseq 41
	ld.local.u32 	%r569, [%rd1];

$L__BB0_216:
	add.s32 	%r198, %r569, 1;
	and.b32  	%r444, %r198, 1;
	shl.b32 	%r445, %r198, 3;
	and.b32  	%r446, %r445, 8;
	setp.eq.s32 	%p178, %r444, 0;
	selp.f64 	%fd685, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p178;
	mul.wide.s32 	%rd342, %r446, 8;
	add.s64 	%rd344, %rd289, %rd342;
	ld.global.nc.f64 	%fd686, [%rd344+8];
	mul.rn.f64 	%fd190, %fd859, %fd859;
	fma.rn.f64 	%fd687, %fd685, %fd190, %fd686;
	ld.global.nc.f64 	%fd688, [%rd344+16];
	fma.rn.f64 	%fd689, %fd687, %fd190, %fd688;
	ld.global.nc.f64 	%fd690, [%rd344+24];
	fma.rn.f64 	%fd691, %fd689, %fd190, %fd690;
	ld.global.nc.f64 	%fd692, [%rd344+32];
	fma.rn.f64 	%fd693, %fd691, %fd190, %fd692;
	ld.global.nc.f64 	%fd694, [%rd344+40];
	fma.rn.f64 	%fd695, %fd693, %fd190, %fd694;
	ld.global.nc.f64 	%fd696, [%rd344+48];
	fma.rn.f64 	%fd191, %fd695, %fd190, %fd696;
	fma.rn.f64 	%fd861, %fd191, %fd859, %fd859;
	@%p178 bra 	$L__BB0_218;

	mov.f64 	%fd697, 0d3FF0000000000000;
	fma.rn.f64 	%fd861, %fd191, %fd190, %fd697;

$L__BB0_218:
	and.b32  	%r447, %r198, 2;
	setp.eq.s32 	%p179, %r447, 0;
	@%p179 bra 	$L__BB0_220;

	mov.f64 	%fd698, 0d0000000000000000;
	mov.f64 	%fd699, 0dBFF0000000000000;
	fma.rn.f64 	%fd861, %fd861, %fd699, %fd698;

$L__BB0_220:
	mul.f64 	%fd197, %fd184, %fd861;
	@%p152 bra 	$L__BB0_222;

	mov.f64 	%fd700, 0d0000000000000000;
	mul.rn.f64 	%fd862, %fd862, %fd700;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r570}, %fd862;
	}

$L__BB0_222:
	mul.f64 	%fd701, %fd862, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r571, %fd701;
	st.local.u32 	[%rd1], %r571;
	cvt.rn.f64.s32 	%fd702, %r571;
	neg.f64 	%fd703, %fd702;
	fma.rn.f64 	%fd705, %fd703, %fd390, %fd862;
	fma.rn.f64 	%fd707, %fd703, %fd392, %fd705;
	fma.rn.f64 	%fd863, %fd703, %fd394, %fd707;
	and.b32  	%r448, %r570, 2145386496;
	setp.lt.u32 	%p181, %r448, 1105199104;
	@%p181 bra 	$L__BB0_224;

	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd862;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd863, [retval0+0];
	} // callseq 42
	ld.local.u32 	%r571, [%rd1];

$L__BB0_224:
	add.s32 	%r204, %r571, 1;
	and.b32  	%r449, %r204, 1;
	shl.b32 	%r450, %r204, 3;
	and.b32  	%r451, %r450, 8;
	setp.eq.s32 	%p182, %r449, 0;
	selp.f64 	%fd709, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p182;
	mul.wide.s32 	%rd346, %r451, 8;
	add.s64 	%rd348, %rd289, %rd346;
	ld.global.nc.f64 	%fd710, [%rd348+8];
	mul.rn.f64 	%fd203, %fd863, %fd863;
	fma.rn.f64 	%fd711, %fd709, %fd203, %fd710;
	ld.global.nc.f64 	%fd712, [%rd348+16];
	fma.rn.f64 	%fd713, %fd711, %fd203, %fd712;
	ld.global.nc.f64 	%fd714, [%rd348+24];
	fma.rn.f64 	%fd715, %fd713, %fd203, %fd714;
	ld.global.nc.f64 	%fd716, [%rd348+32];
	fma.rn.f64 	%fd717, %fd715, %fd203, %fd716;
	ld.global.nc.f64 	%fd718, [%rd348+40];
	fma.rn.f64 	%fd719, %fd717, %fd203, %fd718;
	ld.global.nc.f64 	%fd720, [%rd348+48];
	fma.rn.f64 	%fd204, %fd719, %fd203, %fd720;
	fma.rn.f64 	%fd865, %fd204, %fd863, %fd863;
	@%p182 bra 	$L__BB0_226;

	mov.f64 	%fd721, 0d3FF0000000000000;
	fma.rn.f64 	%fd865, %fd204, %fd203, %fd721;

$L__BB0_226:
	and.b32  	%r452, %r204, 2;
	setp.eq.s32 	%p183, %r452, 0;
	@%p183 bra 	$L__BB0_228;

	mov.f64 	%fd722, 0d0000000000000000;
	mov.f64 	%fd723, 0dBFF0000000000000;
	fma.rn.f64 	%fd865, %fd865, %fd723, %fd722;

$L__BB0_228:
	cvt.rn.f64.s32 	%fd807, %r410;
	mul.f64 	%fd210, %fd865, %fd807;
	@%p158 bra 	$L__BB0_230;

	mov.f64 	%fd724, 0d0000000000000000;
	mul.rn.f64 	%fd866, %fd866, %fd724;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r572}, %fd866;
	}

$L__BB0_230:
	mul.f64 	%fd725, %fd866, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r573, %fd725;
	st.local.u32 	[%rd1], %r573;
	cvt.rn.f64.s32 	%fd726, %r573;
	neg.f64 	%fd727, %fd726;
	fma.rn.f64 	%fd729, %fd727, %fd390, %fd866;
	fma.rn.f64 	%fd731, %fd727, %fd392, %fd729;
	fma.rn.f64 	%fd867, %fd727, %fd394, %fd731;
	and.b32  	%r453, %r572, 2145386496;
	setp.lt.u32 	%p185, %r453, 1105199104;
	@%p185 bra 	$L__BB0_232;

	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd866;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd867, [retval0+0];
	} // callseq 43
	ld.local.u32 	%r573, [%rd1];

$L__BB0_232:
	add.s32 	%r210, %r573, 1;
	and.b32  	%r454, %r210, 1;
	shl.b32 	%r455, %r210, 3;
	and.b32  	%r456, %r455, 8;
	setp.eq.s32 	%p186, %r454, 0;
	selp.f64 	%fd733, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p186;
	mul.wide.s32 	%rd350, %r456, 8;
	add.s64 	%rd352, %rd289, %rd350;
	ld.global.nc.f64 	%fd734, [%rd352+8];
	mul.rn.f64 	%fd216, %fd867, %fd867;
	fma.rn.f64 	%fd735, %fd733, %fd216, %fd734;
	ld.global.nc.f64 	%fd736, [%rd352+16];
	fma.rn.f64 	%fd737, %fd735, %fd216, %fd736;
	ld.global.nc.f64 	%fd738, [%rd352+24];
	fma.rn.f64 	%fd739, %fd737, %fd216, %fd738;
	ld.global.nc.f64 	%fd740, [%rd352+32];
	fma.rn.f64 	%fd741, %fd739, %fd216, %fd740;
	ld.global.nc.f64 	%fd742, [%rd352+40];
	fma.rn.f64 	%fd743, %fd741, %fd216, %fd742;
	ld.global.nc.f64 	%fd744, [%rd352+48];
	fma.rn.f64 	%fd217, %fd743, %fd216, %fd744;
	fma.rn.f64 	%fd869, %fd217, %fd867, %fd867;
	@%p186 bra 	$L__BB0_234;

	mov.f64 	%fd745, 0d3FF0000000000000;
	fma.rn.f64 	%fd869, %fd217, %fd216, %fd745;

$L__BB0_234:
	and.b32  	%r457, %r210, 2;
	setp.eq.s32 	%p187, %r457, 0;
	@%p187 bra 	$L__BB0_236;

	mov.f64 	%fd746, 0d0000000000000000;
	mov.f64 	%fd747, 0dBFF0000000000000;
	fma.rn.f64 	%fd869, %fd869, %fd747, %fd746;

$L__BB0_236:
	mul.f64 	%fd223, %fd210, %fd869;
	@%p164 bra 	$L__BB0_238;

	mov.f64 	%fd748, 0d0000000000000000;
	mul.rn.f64 	%fd870, %fd870, %fd748;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r574}, %fd870;
	}

$L__BB0_238:
	mul.f64 	%fd749, %fd870, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r575, %fd749;
	st.local.u32 	[%rd1], %r575;
	cvt.rn.f64.s32 	%fd750, %r575;
	neg.f64 	%fd751, %fd750;
	fma.rn.f64 	%fd753, %fd751, %fd390, %fd870;
	fma.rn.f64 	%fd755, %fd751, %fd392, %fd753;
	fma.rn.f64 	%fd871, %fd751, %fd394, %fd755;
	and.b32  	%r458, %r574, 2145386496;
	setp.lt.u32 	%p189, %r458, 1105199104;
	@%p189 bra 	$L__BB0_240;

	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd870;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd871, [retval0+0];
	} // callseq 44
	ld.local.u32 	%r575, [%rd1];

$L__BB0_240:
	and.b32  	%r459, %r575, 1;
	shl.b32 	%r460, %r575, 3;
	and.b32  	%r461, %r460, 8;
	setp.eq.s32 	%p190, %r459, 0;
	selp.f64 	%fd757, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p190;
	mul.wide.s32 	%rd354, %r461, 8;
	add.s64 	%rd356, %rd289, %rd354;
	ld.global.nc.f64 	%fd758, [%rd356+8];
	mul.rn.f64 	%fd229, %fd871, %fd871;
	fma.rn.f64 	%fd759, %fd757, %fd229, %fd758;
	ld.global.nc.f64 	%fd760, [%rd356+16];
	fma.rn.f64 	%fd761, %fd759, %fd229, %fd760;
	ld.global.nc.f64 	%fd762, [%rd356+24];
	fma.rn.f64 	%fd763, %fd761, %fd229, %fd762;
	ld.global.nc.f64 	%fd764, [%rd356+32];
	fma.rn.f64 	%fd765, %fd763, %fd229, %fd764;
	ld.global.nc.f64 	%fd766, [%rd356+40];
	fma.rn.f64 	%fd767, %fd765, %fd229, %fd766;
	ld.global.nc.f64 	%fd768, [%rd356+48];
	fma.rn.f64 	%fd230, %fd767, %fd229, %fd768;
	fma.rn.f64 	%fd873, %fd230, %fd871, %fd871;
	@%p190 bra 	$L__BB0_242;

	mov.f64 	%fd769, 0d3FF0000000000000;
	fma.rn.f64 	%fd873, %fd230, %fd229, %fd769;

$L__BB0_242:
	and.b32  	%r462, %r575, 2;
	setp.eq.s32 	%p191, %r462, 0;
	@%p191 bra 	$L__BB0_244;

	mov.f64 	%fd770, 0d0000000000000000;
	mov.f64 	%fd771, 0dBFF0000000000000;
	fma.rn.f64 	%fd873, %fd873, %fd771, %fd770;

$L__BB0_244:
	mul.wide.s32 	%rd357, %r411, 8;
	add.s64 	%rd358, %rd27, %rd357;
	neg.f64 	%fd772, %fd158;
	st.local.f64 	[%rd358], %fd772;
	neg.f64 	%fd773, %fd197;
	st.local.f64 	[%rd358+24], %fd773;
	mul.f64 	%fd774, %fd223, %fd873;
	neg.f64 	%fd775, %fd774;
	st.local.f64 	[%rd358+48], %fd775;
	ld.local.f64 	%fd776, [%rd27];
	ld.local.f64 	%fd777, [%rd27+24];
	ld.local.f64 	%fd778, [%rd27+48];
	mul.f64 	%fd779, %fd778, %fd17;
	fma.rn.f64 	%fd780, %fd777, %fd16, %fd779;
	fma.rn.f64 	%fd781, %fd776, %fd15, %fd780;
	ld.local.f64 	%fd782, [%rd27+8];
	ld.local.f64 	%fd783, [%rd27+32];
	ld.local.f64 	%fd784, [%rd27+56];
	mul.f64 	%fd785, %fd784, %fd17;
	fma.rn.f64 	%fd786, %fd783, %fd16, %fd785;
	fma.rn.f64 	%fd787, %fd782, %fd15, %fd786;
	ld.local.f64 	%fd788, [%rd27+16];
	ld.local.f64 	%fd789, [%rd27+40];
	ld.local.f64 	%fd790, [%rd27+64];
	mul.f64 	%fd791, %fd790, %fd17;
	fma.rn.f64 	%fd792, %fd789, %fd16, %fd791;
	fma.rn.f64 	%fd793, %fd788, %fd15, %fd792;
	mul.f64 	%fd794, %fd793, %fd14;
	fma.rn.f64 	%fd795, %fd787, %fd13, %fd794;
	fma.rn.f64 	%fd796, %fd781, %fd12, %fd795;
	mul.f64 	%fd797, %fd113, %fd796;
	ld.local.u32 	%r463, [%rd85];
	mul.wide.s32 	%rd359, %r463, 8;
	add.s64 	%rd360, %rd29, %rd359;
	fma.rn.f64 	%fd798, %fd112, 0d3FE0000000000000, %fd797;
	ld.global.f64 	%fd799, [%rd360];
	mul.f64 	%fd800, %fd799, %fd798;
	ld.local.u32 	%r464, [%rd86];
	mul.wide.s32 	%rd361, %r464, 8;
	add.s64 	%rd362, %rd29, %rd361;
	ld.global.f64 	%fd801, [%rd362];
	add.s32 	%r465, %r545, %r21;
	shl.b32 	%r466, %r465, 3;
	mov.u32 	%r467, _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives;
	add.s32 	%r468, %r467, %r466;
	ld.shared.f64 	%fd802, [%r468];
	fma.rn.f64 	%fd803, %fd800, %fd801, %fd802;
	st.shared.f64 	[%r468], %fd803;
	add.s32 	%r545, %r545, 1;
	setp.lt.s32 	%p192, %r545, %r230;
	@%p192 bra 	$L__BB0_124;

$L__BB0_245:
	add.s32 	%r544, %r544, 1;
	setp.lt.u32 	%p193, %r544, 3;
	@%p193 bra 	$L__BB0_122;

	add.s32 	%r543, %r543, 1;
	setp.lt.u32 	%p194, %r543, 3;
	@%p194 bra 	$L__BB0_121;

	add.s32 	%r542, %r542, 1;
	setp.lt.s32 	%p195, %r542, %r541;
	@%p195 bra 	$L__BB0_120;

$L__BB0_248:
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd76;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 45
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd69;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 46
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd68;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 47
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd66;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 48
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd57;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 49
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd48;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 50
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 51
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 52
	add.s32 	%r490, %r490, 1;
	setp.lt.s32 	%p196, %r490, %r17;
	@%p196 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_249;

$L__BB0_18:
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 10
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 11

$L__BB0_249:
	@%p20 bra 	$L__BB0_254;

	ld.param.u64 	%rd365, [_Z22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_i_param_23];
	mov.u32 	%r474, %tid.x;
	mul.lo.s32 	%r221, %r474, %r230;
	cvta.to.global.u64 	%rd92, %rd365;
	mov.u32 	%r576, 0;

$L__BB0_251:
	mul.wide.s32 	%rd363, %r576, 8;
	add.s64 	%rd93, %rd92, %rd363;
	add.s32 	%r470, %r576, %r221;
	shl.b32 	%r471, %r470, 3;
	mov.u32 	%r472, _ZZ22computeShapeDerivativeiiiiiiPKiS0_S0_PKdS2_iS2_S2_iS2_S2_iS2_S2_iPdS3_S3_S2_S0_S2_S2_S2_S0_S0_iiiiiiS0_iE21localShapeDerivatives;
	add.s32 	%r473, %r472, %r471;
	ld.shared.f64 	%fd236, [%r473];
	ld.global.u64 	%rd398, [%rd93];

$L__BB0_252:
	mov.b64 	%fd804, %rd398;
	add.f64 	%fd805, %fd236, %fd804;
	mov.b64 	%rd364, %fd805;
	atom.global.cas.b64 	%rd96, [%rd93], %rd398, %rd364;
	setp.ne.s64 	%p198, %rd398, %rd96;
	mov.u64 	%rd398, %rd96;
	@%p198 bra 	$L__BB0_252;

	add.s32 	%r576, %r576, 1;
	setp.lt.s32 	%p199, %r576, %r230;
	@%p199 bra 	$L__BB0_251;

$L__BB0_254:
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot1[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB1_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r4, %r11, %r10;
	mov.u32 	%r12, 19;
	sub.s32 	%r13, %r12, %r10;
	setp.gt.s32 	%p2, %r4, 14;
	selp.b32 	%r5, 18, %r13, %p2;
	setp.gt.s32 	%p3, %r4, %r5;
	mov.u64 	%rd75, 0;
	mov.u64 	%rd76, %rd1;
	@%p3 bra 	$L__BB1_4;

	add.s32 	%r6, %r4, -1;
	mov.b64 	%rd22, %fd4;
	shl.b64 	%rd23, %rd22, 11;
	or.b64  	%rd4, %rd23, -9223372036854775808;
	mov.u64 	%rd25, __cudart_i2opi_d;
	mov.u64 	%rd76, %rd1;
	mov.u32 	%r28, %r6;

$L__BB1_3:
	.pragma "nounroll";
	mul.wide.s32 	%rd24, %r28, 8;
	add.s64 	%rd26, %rd25, %rd24;
	ld.global.nc.u64 	%rd27, [%rd26];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd27;
	mov.b64 	{%blo,%bhi}, %rd4;
	mov.b64 	{%clo,%chi}, %rd75;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd28, {%r0,%r1};
	mov.b64 	%rd75, {%r2,%r3};
	}
	st.local.u64 	[%rd76], %rd28;
	add.s32 	%r28, %r28, 1;
	sub.s32 	%r14, %r28, %r6;
	mul.wide.s32 	%rd29, %r14, 8;
	add.s64 	%rd76, %rd1, %rd29;
	setp.lt.s32 	%p4, %r28, %r5;
	@%p4 bra 	$L__BB1_3;

$L__BB1_4:
	st.local.u64 	[%rd76], %rd75;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB1_6;

	mov.u32 	%r15, 64;
	sub.s32 	%r16, %r15, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r16;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r16;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB1_6:
	and.b32  	%r17, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r18, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r19, %rd39;
	and.b32  	%r20, %r19, 1;
	add.s32 	%r21, %r20, %r18;
	neg.s32 	%r22, %r21;
	setp.eq.s32 	%p6, %r17, 0;
	selp.b32 	%r23, %r21, %r22, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r23;
	setp.eq.s32 	%p7, %r20, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r24, %r17, -2147483648;
	selp.b32 	%r25, %r17, %r24, %p7;
	clz.b64 	%r26, %rd45;
	cvt.u64.u32 	%rd47, %r26;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r26;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r27, %rd50;
	shr.u64 	%rd51, %rd46, %r27;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r25;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB1_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}

